{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Cap_Gap.ipynb","provenance":[{"file_id":"105ZGuMLhTWXMuM_yNj_jD9oRWiliXIAq","timestamp":1600462797370},{"file_id":"1Dx2DHUSJI2Z1jvcjswV1IunQYcY9eLM7","timestamp":1599901954343},{"file_id":"1Bj8jFjUU8LouuKbBCiu9vDYKdORi545Z","timestamp":1599861940699},{"file_id":"193MT4FSgDApeBZ8-jyrJuBArmXSEg9bX","timestamp":1599781793946}],"collapsed_sections":["zCqJTTUu4xuf"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"D415xY3P1PCN"},"source":["# Loose EEGNet\n","This notebook is a neural network that is based as much off of the EEGNet paper as I could understand."]},{"cell_type":"markdown","metadata":{"id":"Sdi7BvnG2eiJ"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9VIVsTD-24Dj"},"source":["# Import/Install all necessary packages and libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bve5YVmW4tUX","executionInfo":{"status":"ok","timestamp":1613859244390,"user_tz":480,"elapsed":286,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}},"outputId":"c11292c5-b360-469f-c362-3f457cba1424"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":112,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"anVJZVW0sUwY","cellView":"both","executionInfo":{"status":"ok","timestamp":1613859244661,"user_tz":480,"elapsed":540,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}}},"source":["import numpy as np\n","\n","from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score, classification_report\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.utils import shuffle\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable, gradcheck\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","import pandas as pd\n","\n","from matplotlib import pyplot\n","\n","import math\n","\n","from os import walk"],"execution_count":113,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X4ou4gyC4dQu"},"source":["# Check for GPU availability and set device"]},{"cell_type":"code","metadata":{"id":"A_rTCb13APF7","executionInfo":{"status":"ok","timestamp":1613859244662,"user_tz":480,"elapsed":536,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}}},"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")"],"execution_count":114,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w6t-hO2E4mHe"},"source":["# Load and format the data"]},{"cell_type":"markdown","metadata":{"id":"CWKPU90EkmGY"},"source":["Here is a brief rundown of the data:\n","\n","> Each data segment (chunk) is a two second recording in which a subject subvocalized either \"yes\" or \"no\" at any point in the recording\n","\n","> The data is taken with a sampling frequency of 250hz, so in the end there are 500 timepoints for each chunk\n","\n","> The hardware we are using has 7 channels\n","\n","> After all these data cells are run the data is in the shape (# of chunks, 1, # of channels, # of timepoints)\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"SjQFfpM8BPYt","executionInfo":{"status":"ok","timestamp":1613859244662,"user_tz":480,"elapsed":531,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}}},"source":["master_data, master_label = [], []\n","datafix, labelfix = \".pkl\", \".csv\"\n","# paste path below\n","for (dirpath, dirnames, filenames) in walk('/content/drive/Shareddrives/NeuroTech ML/Processed Data Files'):\n","    new_data = [dirpath + '/' + name for name in filenames if datafix in name]\n","    master_data.extend(new_data)\n","\n","    new_labels = [dirpath + '/' + name for name in filenames if labelfix in name]\n","    master_label.extend(new_labels)\n","assert len(master_data) == len(master_label)\n","master_data.sort()\n","master_label.sort()\n","for index in range(len(master_data)):\n","    try: \n","        assert master_data[index][:-4] == master_label[index][:-11]\n","    except:\n","        print(index)\n","        print(master_data[index][:-4])\n","        print(master_label[index][:-11])"],"execution_count":115,"outputs":[]},{"cell_type":"code","metadata":{"id":"YbANnf64NV4B","executionInfo":{"status":"ok","timestamp":1613859244787,"user_tz":480,"elapsed":651,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}}},"source":["pkllabels = np.zeros((1, 1))\n","pkldata = np.zeros((1, 7, 500))\n","pkllabels2 = np.zeros((1, 1))\n","pkldata2 = np.zeros((1, 7, 500))\n","\n","for i in range(len(master_data)):\n","\n","    # To train no ICA data change data type to ICA\n","    # To train no ICA and weaker filter change data type to Weaker\n","    # To train unprocessed data change data type to Unprocessed\n","\n","    data_type = \"Cap_Gap\"\n","\n","    if data_type in master_data[i]:\n","        new_data = pd.read_pickle(master_data[i])\n","\n","        new_labels = pd.read_csv(master_label[i], delimiter=',', header=None)\n","        if new_labels.shape[0] == 1 and new_labels.shape[1] > new_labels.shape[0]:\n","            new_labels = new_labels.T\n","        new_labels = np.array(new_labels)\n","        new_labels = new_labels.reshape((new_labels.shape[0], 1))\n","\n","        pkldata = np.concatenate((pkldata, new_data), axis = 0)\n","        pkllabels = np.concatenate((pkllabels, new_labels), axis = 0)\n","    # elif data_type in master_data[i] and 'YESNO' in master_data[i]:\n","    #     new_data = pd.read_pickle(master_data[i])\n","\n","    #     new_labels = pd.read_csv(master_label[i], delimiter=',', header=None)\n","    #     if new_labels.shape[0] == 1 and new_labels.shape[1] > new_labels.shape[0]:\n","    #         new_labels = new_labels.T\n","    #     new_labels = np.array(new_labels)\n","    #     new_labels = new_labels.reshape((new_labels.shape[0], 1))\n","\n","    #     pkldata2 = np.concatenate((pkldata2, new_data), axis = 0)\n","    #     pkllabels2 = np.concatenate((pkllabels2, new_labels), axis = 0)\n","\n","pkllabels = pkllabels[1:, :]\n","pkldata = pkldata[1:, :, :]\n","pkllabels2 = pkllabels2[1:, :]\n","pkldata2 = pkldata2[1:, :, :]"],"execution_count":116,"outputs":[]},{"cell_type":"code","metadata":{"id":"RIWYzAbfmLm4","executionInfo":{"status":"ok","timestamp":1613859244788,"user_tz":480,"elapsed":647,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}}},"source":["# # Uncomment below if u wanna see a bunch of graphs of the data\n","# print(pkldata.shape, pkllabels.shape)\n","# print(pkllabels.shape)\n","# x = pkldata[0]\n","# only_no = [pkldata[i] for i in range(pkldata.shape[0]) if pkllabels[i][0] == 0]\n","# only_no = np.array(only_no)\n","# only_yes = [pkldata[i] for i in range(pkldata.shape[0]) if pkllabels[i][0] == 1]\n","# only_yes = np.array(only_yes)\n","# print(only_no.shape, only_yes.shape)\n","# for i in range(pkldata.shape[1]):\n","#     g = i + 1\n","#     pyplot.plot(only_yes[0:, i, :].T, color=\"red\")\n","#     pyplot.plot(only_no[0:, i, :].T, alpha = .3, color=\"blue\")\n","#     pyplot.title(\"Value for channel {} over all {} chunks\".format(i, pkldata.shape[0]))\n","#     #pyplot.savefig(f\"/content/drive/My Drive/Extra/processed_data_Riley_channel_{g}.png\")\n","#     pyplot.show()"],"execution_count":117,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PzcJwNMv4QU","executionInfo":{"status":"ok","timestamp":1613859244788,"user_tz":480,"elapsed":642,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}}},"source":["torch.manual_seed(4)\n","torch.cuda.manual_seed(4)"],"execution_count":118,"outputs":[]},{"cell_type":"code","metadata":{"id":"lnIbNDuBv917","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613859244789,"user_tz":480,"elapsed":637,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}},"outputId":"6b2432d7-d806-41cc-b384-b2dcae6230c4"},"source":["channels = pkldata.shape[1]\n","timepoints = pkldata.shape[2]\n","print(channels, timepoints)"],"execution_count":119,"outputs":[{"output_type":"stream","text":["7 500\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0f6NOpVZwDwQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613859244789,"user_tz":480,"elapsed":629,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}},"outputId":"8e3d4b52-5ffa-4228-b197-3f7f53b02cf4"},"source":["BATCH_SIZE = 32\n","\n","pkllabels = pkllabels.astype(np.float32)\n","X_actual = torch.from_numpy(pkllabels)\n","\n","scaler = StandardScaler()\n","X_train = pkldata\n","# for i in range(len(X_train)):\n","#     X_train[i] = scaler.fit_transform(X_train[i])\n","X_train = torch.from_numpy(X_train)\n","X_train = X_train.unsqueeze(1)\n","\n","# pkllabels2 = pkllabels2.astype(np.float32)\n","# X_test_labels = torch.from_numpy(pkllabels2)\n","\n","# X_test = pkldata2\n","# X_test = torch.from_numpy(X_test)\n","# X_test = X_test.unsqueeze(1)\n","\n","# splits the data into a train and dev set, and loads them into dataloaders\n","train_data, test_data, labels_train, labels_test = train_test_split(X_train, X_actual, test_size=0.2, random_state=4)\n","\n","# test_data = X_test\n","# labels_test = X_test_labels\n","\n","trainset = torch.utils.data.TensorDataset(train_data, labels_train)\n","testset = torch.utils.data.TensorDataset(test_data, labels_test)\n","\n","train_loader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True, drop_last=True)\n","test_loader = torch.utils.data.DataLoader(testset, batch_size = test_data.shape[0], shuffle = True, drop_last=True)\n","\n","print(train_data.shape, test_data.shape, labels_train.shape, labels_test.shape)"],"execution_count":120,"outputs":[{"output_type":"stream","text":["torch.Size([137, 1, 7, 500]) torch.Size([35, 1, 7, 500]) torch.Size([137, 1]) torch.Size([35, 1])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zCqJTTUu4xuf"},"source":["# Build the model and train\n","A short breakdown of the paper:\n","> EEGNet is a CNN for classification and interpretation of EEG-based BCI's\n","\n","> Benefits of EEGNet:\n","> 1. Can be applied to different BCI paradagims (MI, ERP, SSVEP)\n","> 2. Can be trained with very limited data\n","> 3. Can produce neurophysiologically interpretable features\n","\n","> The model architecture:\n","> 1. Fit 2D convolutional filters of size (1, sampling rate//2)\n","> 2. Use a depthwise convolution of size (# of channels, 1)\n","> 3. Add a separable convolution of size (1, 16)\n","> 4. Flatten the data and feed it through a classification layer\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"yQpyCFRxx24X","executionInfo":{"status":"ok","timestamp":1613859244790,"user_tz":480,"elapsed":621,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}}},"source":["# hyperparameters\n","freq, avg1stride, avg2stride = 250, (1, 4), (1, 8)\n","convstride = 1 # stride for each conv2D\n","conv1_neurons = 8\n","conv2_neurons = 16\n","conv3_neurons = 32\n","conv4_neurons = 16\n","kern1size = freq // 2\n","kern3size = 32"],"execution_count":121,"outputs":[]},{"cell_type":"code","metadata":{"id":"OpvKD47DQ8FS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613859244790,"user_tz":480,"elapsed":615,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}},"outputId":"e2a34c0a-869f-41ea-ecc0-49f90b0159da"},"source":["padding_needed = (kern1size - 1) / 2\n","conv1outx, conv1outy = (channels, (timepoints + (2 * padding_needed) - kern1size)/convstride + 1)\n","\n","print(\"1st layer output size:\", conv1outx, conv1outy)\n","\n","conv2outx, conv2outy = ((conv1outx - channels)/convstride + 1, conv1outy)\n","conv2outx, conv2outy = conv2outx // avg1stride[0], conv2outy // avg1stride[1]\n","\n","print(\"2nd layer output size:\", conv2outx, conv2outy)\n","\n","# conv3outx, conv3outy = (conv2outx, (conv2outy - kern3size)/convstride + 1)\n","\n","# print(\"3rd layer output size:\", conv3outx, conv3outy)\n","\n","# conv4outx, conv4outy = (conv3outx, conv3outy)\n","# conv4outx, conv4outy = (conv4outx // avg2stride[0], conv4outy // avg2stride[1])\n","\n","# print(\"4th layer output size:\", conv4outx, conv4outy)\n","\n","# flat1_in = int(conv4outx * conv4outy * conv4_neurons)\n","\n","flat1_in = int(conv2outx * conv2outy * conv2_neurons)"],"execution_count":122,"outputs":[{"output_type":"stream","text":["1st layer output size: 7 500.0\n","2nd layer output size: 1.0 125.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wgHA3ZVMfyhn"},"source":["Model description, layer by layer\n","\n","1. Temporal convolution\n","> * - Uses filters of (1, sampling frequency // 2)\n","> * - Learns frequency filters at 2Hz and above\n","2. Depthwise convolution\n","> * - Learns spatial filters\n","3. Separable Convolution\n","> * - Conists of a deptwise convolution followed by a pointwise convolution\n","> * - First learnes a kernel summarizing each feature map, then merges the outputs\n","4. Fully connected layer\n","> * - Consists of a linear layer that reduces the channels, followed by a sigmoid classification"]},{"cell_type":"markdown","metadata":{"id":"Y23MOt6UkuO8"},"source":["3.5k research grant at school\r\n","\r\n","https://science.ucsc.edu/research-opportunities/undergraduate-research-in-science-and-technology-award/\r\n","\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"9Ug1Ios06j1_","executionInfo":{"status":"ok","timestamp":1613859244790,"user_tz":480,"elapsed":608,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}}},"source":["class ConstrainedConv2d(nn.Conv2d):\n","    def forward(self, input):\n","        return F.conv2d(input, self.weight.clamp(min=-1.0, max=1.0), self.bias, self.stride,\n","                        self.padding, self.dilation, self.groups)"],"execution_count":123,"outputs":[]},{"cell_type":"code","metadata":{"id":"5_oIWWxaAZB5","executionInfo":{"status":"ok","timestamp":1613859244917,"user_tz":480,"elapsed":730,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}}},"source":["class EEGNet(nn.Module):\r\n","    def __init__(self):\r\n","        super(EEGNet, self).__init__()\r\n","        self.pad = nn.ZeroPad2d((math.floor(padding_needed), math.ceil(padding_needed), 0, 0))\r\n","        self.conv1 = nn.Conv2d(1, conv1_neurons, (1, kern1size), bias=False)\r\n","        self.norm1 = nn.BatchNorm2d(conv1_neurons)\r\n","        self.conv2 = ConstrainedConv2d(conv1_neurons, conv2_neurons, (channels, 1), bias=False)\r\n","        self.norm2 = nn.BatchNorm2d(conv2_neurons)\r\n","        self.pool = nn.MaxPool2d(avg1stride)\r\n","        self.flatten = nn.Flatten()\r\n","        self.fc1 = nn.Linear(flat1_in, 1)\r\n","        self.dropout = nn.Dropout()\r\n","\r\n","        self.activation = nn.ELU()\r\n","        self.activation2 = nn.Sigmoid()\r\n","\r\n","    def forward(self, x):\r\n","        out = self.pad(x)\r\n","        out = self.conv1(out)\r\n","        print(\"1: \", out.shape)\r\n","        out = self.activation(out)\r\n","        out = self.norm1(out)\r\n","        print(out.shape)\r\n","\r\n","        out = self.conv2(out)\r\n","        print(\"2: \", out.shape)\r\n","        out = self.activation(out)\r\n","        out = self.pool(self.norm2(out))\r\n","        out = self.dropout(out)\r\n","        print(\"3: \", out.shape)\r\n","\r\n","        out = self.activation2(self.fc1(self.flatten(out)))\r\n","        return out\r\n","\r\n","CNNPoor = EEGNet()"],"execution_count":124,"outputs":[]},{"cell_type":"code","metadata":{"id":"jCNgBinI_3Oq","executionInfo":{"status":"ok","timestamp":1613859244918,"user_tz":480,"elapsed":726,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}}},"source":["# CNNPoor = nn.Sequential(\n","#     nn.ZeroPad2d((math.floor(padding_needed), math.ceil(padding_needed), 0, 0)),\n","#     nn.Conv2d(1, conv1_neurons, (1, kern1size), bias=False),\n","#     nn.ELU(),\n","#     nn.BatchNorm2d(conv1_neurons),\n","    \n","#     ConstrainedConv2d(conv1_neurons, conv2_neurons, (channels, 1), bias=False),\n","#     nn.ELU(),\n","#     nn.BatchNorm2d(conv2_neurons),\n","#     nn.MaxPool2d(avg1stride),\n","#     nn.Dropout(),\n","    \n","#     # nn.Conv2d(conv2_neurons, conv3_neurons, (1, kern3size), bias=False, groups=conv2_neurons),\n","#     # nn.Conv2d(conv3_neurons, conv4_neurons, kernel_size=1, bias=False),\n","#     # nn.ELU(),\n","#     # nn.BatchNorm2d(conv4_neurons),\n","#     # nn.MaxPool2d(avg2stride),\n","#     # nn.Dropout(),\n","    \n","#     nn.Flatten(),\n","\n","#     nn.Linear(flat1_in, 1),\n","#     nn.Sigmoid(),\n","# )\n","\n","CNNPoor = CNNPoor.to(device)"],"execution_count":125,"outputs":[]},{"cell_type":"code","metadata":{"id":"IRsayVFf_66T","executionInfo":{"status":"ok","timestamp":1613859244918,"user_tz":480,"elapsed":721,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}}},"source":["loss_function = nn.BCELoss()\n","optimizer = optim.Adam(CNNPoor.parameters(), lr = 0.001)"],"execution_count":126,"outputs":[]},{"cell_type":"code","metadata":{"id":"SFBd1M29CFmp","executionInfo":{"status":"ok","timestamp":1613859244919,"user_tz":480,"elapsed":717,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}}},"source":["def test(model, device, test_loader):\n","    \n","    model.eval()\n","    correct = 0\n","    tot_loss = 0\n","    acc_score, prec_score, rec_score = 0, 0, 0\n","    with torch.no_grad():\n","        for (data, labels) in test_loader:\n","            data, labels = data.to(device), labels.to(device)\n","            \n","            classification = model(data.float())\n","            loss = loss_function(classification, labels)\n","\n","            pred = torch.round(classification)\n","            correct += pred.eq(labels.view_as(pred)).sum().item()\n","            tot_loss += loss.item()\n","\n","            acc_score += accuracy_score(labels, pred)\n","            prec_score += precision_score(labels, pred)\n","            rec_score += recall_score(labels, pred)\n","\n","        print(\"\\nTest set: Total loss: {:.6f}, Accuracy: {:.6f}\".format(tot_loss, \n","                                                                          correct / len(test_loader.dataset)))\n","        # print(classification_report(labels, pred))\n","        return (tot_loss, acc_score, prec_score, rec_score)"],"execution_count":127,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fm36EBCCJ1G","executionInfo":{"status":"ok","timestamp":1613859244919,"user_tz":480,"elapsed":712,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}}},"source":["def train(model, device, train_loader, optimizer, epoch):\n","\n","    model.train()\n","    correct = 0\n","    tot_loss = 0\n","    for batch, (data, labels) in enumerate(train_loader):\n","        data, labels = data.to(device), labels.to(device)\n","        \n","        optimizer.zero_grad()\n","        \n","        classification = model(data.float())\n","        loss = loss_function(classification, labels)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        pred = torch.round(classification)\n","        correct += pred.eq(labels.view_as(pred)).sum().item()\n","        tot_loss += loss.item()\n","    print(\"Epoch: {}\".format(epoch))\n","    print(\"\\tAverage loss: {:.6f}\".format(tot_loss / (batch + 1)))\n","    print(\"\\tAccuracy: {:.6f}\".format(correct / len(train_loader.dataset)))\n","\n","    labels_detached = labels.detach()\n","    preds_detached = pred.detach()\n","    print(classification_report(labels_detached, preds_detached))\n","    return (tot_loss / (batch + 1), correct / len(train_loader.dataset))"],"execution_count":128,"outputs":[]},{"cell_type":"code","metadata":{"id":"nxLzxLHdCYKM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613859277702,"user_tz":480,"elapsed":33489,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}},"outputId":"469de671-8ee8-469b-a15c-ad820c77382c"},"source":["plots = {\"train loss\": [],\n","         \"train acc\": [],\n","         \"test loss\": [],\n","         \"test acc\": [],\n","         \"test prec\": [],\n","         \"test rec\": []}\n","\n","for epoch in range(120):\n","    trl, tra = train(CNNPoor, device, train_loader, optimizer, epoch)\n","    plots[\"train loss\"].append(trl)\n","    plots[\"train acc\"].append(tra)\n","    tl, ta, tp, tr = test(CNNPoor, device, test_loader)\n","    plots[\"test loss\"].append(tl)\n","    plots[\"test acc\"].append(ta)\n","    plots[\"test prec\"].append(tp)\n","    plots[\"test rec\"].append(tr)"],"execution_count":129,"outputs":[{"output_type":"stream","text":["1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 0\n","\tAverage loss: 0.877809\n","\tAccuracy: 0.416058\n","              precision    recall  f1-score   support\n","\n","         0.0       0.58      0.37      0.45        19\n","         1.0       0.40      0.62      0.48        13\n","\n","    accuracy                           0.47        32\n","   macro avg       0.49      0.49      0.47        32\n","weighted avg       0.51      0.47      0.47        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.690738, Accuracy: 0.571429\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 1\n","\tAverage loss: 0.719429\n","\tAccuracy: 0.459854\n","              precision    recall  f1-score   support\n","\n","         0.0       0.58      0.69      0.63        16\n","         1.0       0.62      0.50      0.55        16\n","\n","    accuracy                           0.59        32\n","   macro avg       0.60      0.59      0.59        32\n","weighted avg       0.60      0.59      0.59        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.693552, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 2\n","\tAverage loss: 0.739169\n","\tAccuracy: 0.430657\n","              precision    recall  f1-score   support\n","\n","         0.0       0.63      0.63      0.63        19\n","         1.0       0.46      0.46      0.46        13\n","\n","    accuracy                           0.56        32\n","   macro avg       0.55      0.55      0.55        32\n","weighted avg       0.56      0.56      0.56        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.688767, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 3\n","\tAverage loss: 0.734445\n","\tAccuracy: 0.445255\n","              precision    recall  f1-score   support\n","\n","         0.0       0.57      0.44      0.50        18\n","         1.0       0.44      0.57      0.50        14\n","\n","    accuracy                           0.50        32\n","   macro avg       0.51      0.51      0.50        32\n","weighted avg       0.52      0.50      0.50        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.690658, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 4\n","\tAverage loss: 0.751693\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.73      0.44      0.55        18\n","         1.0       0.52      0.79      0.63        14\n","\n","    accuracy                           0.59        32\n","   macro avg       0.63      0.62      0.59        32\n","weighted avg       0.64      0.59      0.59        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.688372, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 5\n","\tAverage loss: 0.714725\n","\tAccuracy: 0.510949\n","              precision    recall  f1-score   support\n","\n","         0.0       0.61      0.61      0.61        18\n","         1.0       0.50      0.50      0.50        14\n","\n","    accuracy                           0.56        32\n","   macro avg       0.56      0.56      0.56        32\n","weighted avg       0.56      0.56      0.56        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.709124, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 6\n","\tAverage loss: 0.745658\n","\tAccuracy: 0.430657\n","              precision    recall  f1-score   support\n","\n","         0.0       0.50      0.50      0.50        18\n","         1.0       0.36      0.36      0.36        14\n","\n","    accuracy                           0.44        32\n","   macro avg       0.43      0.43      0.43        32\n","weighted avg       0.44      0.44      0.44        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.724823, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 7\n","\tAverage loss: 0.733790\n","\tAccuracy: 0.423358\n","              precision    recall  f1-score   support\n","\n","         0.0       0.44      0.57      0.50        14\n","         1.0       0.57      0.44      0.50        18\n","\n","    accuracy                           0.50        32\n","   macro avg       0.51      0.51      0.50        32\n","weighted avg       0.52      0.50      0.50        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.724839, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 8\n","\tAverage loss: 0.736568\n","\tAccuracy: 0.518248\n","              precision    recall  f1-score   support\n","\n","         0.0       0.67      0.59      0.62        17\n","         1.0       0.59      0.67      0.62        15\n","\n","    accuracy                           0.62        32\n","   macro avg       0.63      0.63      0.62        32\n","weighted avg       0.63      0.62      0.62        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.705048, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 9\n","\tAverage loss: 0.728514\n","\tAccuracy: 0.423358\n","              precision    recall  f1-score   support\n","\n","         0.0       0.50      0.22      0.31        18\n","         1.0       0.42      0.71      0.53        14\n","\n","    accuracy                           0.44        32\n","   macro avg       0.46      0.47      0.42        32\n","weighted avg       0.46      0.44      0.40        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.716304, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 10\n","\tAverage loss: 0.795228\n","\tAccuracy: 0.401460\n","              precision    recall  f1-score   support\n","\n","         0.0       0.41      0.58      0.48        12\n","         1.0       0.67      0.50      0.57        20\n","\n","    accuracy                           0.53        32\n","   macro avg       0.54      0.54      0.53        32\n","weighted avg       0.57      0.53      0.54        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.695133, Accuracy: 0.457143\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 11\n","\tAverage loss: 0.746174\n","\tAccuracy: 0.452555\n","              precision    recall  f1-score   support\n","\n","         0.0       0.61      0.61      0.61        18\n","         1.0       0.50      0.50      0.50        14\n","\n","    accuracy                           0.56        32\n","   macro avg       0.56      0.56      0.56        32\n","weighted avg       0.56      0.56      0.56        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.711168, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 12\n","\tAverage loss: 0.772819\n","\tAccuracy: 0.437956\n","              precision    recall  f1-score   support\n","\n","         0.0       0.48      0.73      0.58        15\n","         1.0       0.56      0.29      0.38        17\n","\n","    accuracy                           0.50        32\n","   macro avg       0.52      0.51      0.48        32\n","weighted avg       0.52      0.50      0.48        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.748457, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 13\n","\tAverage loss: 0.764078\n","\tAccuracy: 0.423358\n","              precision    recall  f1-score   support\n","\n","         0.0       0.30      0.64      0.41        11\n","         1.0       0.56      0.24      0.33        21\n","\n","    accuracy                           0.38        32\n","   macro avg       0.43      0.44      0.37        32\n","weighted avg       0.47      0.38      0.36        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.693772, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 14\n","\tAverage loss: 0.803756\n","\tAccuracy: 0.459854\n","              precision    recall  f1-score   support\n","\n","         0.0       0.50      0.11      0.18        18\n","         1.0       0.43      0.86      0.57        14\n","\n","    accuracy                           0.44        32\n","   macro avg       0.46      0.48      0.38        32\n","weighted avg       0.47      0.44      0.35        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.684787, Accuracy: 0.571429\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 15\n","\tAverage loss: 0.718130\n","\tAccuracy: 0.547445\n","              precision    recall  f1-score   support\n","\n","         0.0       0.70      0.41      0.52        17\n","         1.0       0.55      0.80      0.65        15\n","\n","    accuracy                           0.59        32\n","   macro avg       0.62      0.61      0.58        32\n","weighted avg       0.63      0.59      0.58        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.708565, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 16\n","\tAverage loss: 0.718791\n","\tAccuracy: 0.467153\n","              precision    recall  f1-score   support\n","\n","         0.0       0.50      0.80      0.62        15\n","         1.0       0.62      0.29      0.40        17\n","\n","    accuracy                           0.53        32\n","   macro avg       0.56      0.55      0.51        32\n","weighted avg       0.57      0.53      0.50        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.756025, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 17\n","\tAverage loss: 0.768790\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.50      0.36        12\n","         1.0       0.45      0.25      0.32        20\n","\n","    accuracy                           0.34        32\n","   macro avg       0.37      0.38      0.34        32\n","weighted avg       0.39      0.34      0.34        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.735746, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 18\n","\tAverage loss: 0.714841\n","\tAccuracy: 0.489051\n","              precision    recall  f1-score   support\n","\n","         0.0       0.62      0.77      0.69        13\n","         1.0       0.81      0.68      0.74        19\n","\n","    accuracy                           0.72        32\n","   macro avg       0.72      0.73      0.72        32\n","weighted avg       0.74      0.72      0.72        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.711179, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 19\n","\tAverage loss: 0.793533\n","\tAccuracy: 0.408759\n","              precision    recall  f1-score   support\n","\n","         0.0       0.40      0.38      0.39        16\n","         1.0       0.41      0.44      0.42        16\n","\n","    accuracy                           0.41        32\n","   macro avg       0.41      0.41      0.41        32\n","weighted avg       0.41      0.41      0.41        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.705399, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 20\n","\tAverage loss: 0.776197\n","\tAccuracy: 0.437956\n","              precision    recall  f1-score   support\n","\n","         0.0       0.53      0.50      0.51        20\n","         1.0       0.23      0.25      0.24        12\n","\n","    accuracy                           0.41        32\n","   macro avg       0.38      0.38      0.38        32\n","weighted avg       0.42      0.41      0.41        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.712576, Accuracy: 0.400000\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 21\n","\tAverage loss: 0.726365\n","\tAccuracy: 0.496350\n","              precision    recall  f1-score   support\n","\n","         0.0       0.54      0.41      0.47        17\n","         1.0       0.47      0.60      0.53        15\n","\n","    accuracy                           0.50        32\n","   macro avg       0.51      0.51      0.50        32\n","weighted avg       0.51      0.50      0.50        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.732130, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 22\n","\tAverage loss: 0.708798\n","\tAccuracy: 0.525547\n","              precision    recall  f1-score   support\n","\n","         0.0       0.50      0.50      0.50        18\n","         1.0       0.36      0.36      0.36        14\n","\n","    accuracy                           0.44        32\n","   macro avg       0.43      0.43      0.43        32\n","weighted avg       0.44      0.44      0.44        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.757363, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 23\n","\tAverage loss: 0.771790\n","\tAccuracy: 0.379562\n","              precision    recall  f1-score   support\n","\n","         0.0       0.33      0.43      0.38        14\n","         1.0       0.43      0.33      0.38        18\n","\n","    accuracy                           0.38        32\n","   macro avg       0.38      0.38      0.38        32\n","weighted avg       0.39      0.38      0.38        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.711712, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 24\n","\tAverage loss: 0.767277\n","\tAccuracy: 0.430657\n","              precision    recall  f1-score   support\n","\n","         0.0       0.60      0.50      0.55        18\n","         1.0       0.47      0.57      0.52        14\n","\n","    accuracy                           0.53        32\n","   macro avg       0.54      0.54      0.53        32\n","weighted avg       0.54      0.53      0.53        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.696928, Accuracy: 0.571429\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 25\n","\tAverage loss: 0.748948\n","\tAccuracy: 0.437956\n","              precision    recall  f1-score   support\n","\n","         0.0       0.41      0.58      0.48        12\n","         1.0       0.67      0.50      0.57        20\n","\n","    accuracy                           0.53        32\n","   macro avg       0.54      0.54      0.53        32\n","weighted avg       0.57      0.53      0.54        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.719234, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 26\n","\tAverage loss: 0.713128\n","\tAccuracy: 0.532847\n","              precision    recall  f1-score   support\n","\n","         0.0       0.57      0.57      0.57        14\n","         1.0       0.67      0.67      0.67        18\n","\n","    accuracy                           0.62        32\n","   macro avg       0.62      0.62      0.62        32\n","weighted avg       0.62      0.62      0.62        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.696499, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 27\n","\tAverage loss: 0.721447\n","\tAccuracy: 0.459854\n","              precision    recall  f1-score   support\n","\n","         0.0       0.45      0.67      0.54        15\n","         1.0       0.50      0.29      0.37        17\n","\n","    accuracy                           0.47        32\n","   macro avg       0.48      0.48      0.46        32\n","weighted avg       0.48      0.47      0.45        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.711481, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 28\n","\tAverage loss: 0.702618\n","\tAccuracy: 0.525547\n","              precision    recall  f1-score   support\n","\n","         0.0       0.55      0.32      0.40        19\n","         1.0       0.38      0.62      0.47        13\n","\n","    accuracy                           0.44        32\n","   macro avg       0.46      0.47      0.44        32\n","weighted avg       0.48      0.44      0.43        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.701885, Accuracy: 0.457143\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 29\n","\tAverage loss: 0.694698\n","\tAccuracy: 0.496350\n","              precision    recall  f1-score   support\n","\n","         0.0       0.50      0.67      0.57        12\n","         1.0       0.75      0.60      0.67        20\n","\n","    accuracy                           0.62        32\n","   macro avg       0.62      0.63      0.62        32\n","weighted avg       0.66      0.62      0.63        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.702664, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 30\n","\tAverage loss: 0.787068\n","\tAccuracy: 0.372263\n","              precision    recall  f1-score   support\n","\n","         0.0       0.50      0.50      0.50        16\n","         1.0       0.50      0.50      0.50        16\n","\n","    accuracy                           0.50        32\n","   macro avg       0.50      0.50      0.50        32\n","weighted avg       0.50      0.50      0.50        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.741439, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 31\n","\tAverage loss: 0.721726\n","\tAccuracy: 0.452555\n","              precision    recall  f1-score   support\n","\n","         0.0       0.72      0.62      0.67        21\n","         1.0       0.43      0.55      0.48        11\n","\n","    accuracy                           0.59        32\n","   macro avg       0.58      0.58      0.57        32\n","weighted avg       0.62      0.59      0.60        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.723459, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 32\n","\tAverage loss: 0.755747\n","\tAccuracy: 0.489051\n","              precision    recall  f1-score   support\n","\n","         0.0       0.29      0.50      0.37        10\n","         1.0       0.67      0.45      0.54        22\n","\n","    accuracy                           0.47        32\n","   macro avg       0.48      0.48      0.46        32\n","weighted avg       0.55      0.47      0.49        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.736600, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 33\n","\tAverage loss: 0.734919\n","\tAccuracy: 0.481752\n","              precision    recall  f1-score   support\n","\n","         0.0       0.47      0.54      0.50        13\n","         1.0       0.65      0.58      0.61        19\n","\n","    accuracy                           0.56        32\n","   macro avg       0.56      0.56      0.56        32\n","weighted avg       0.57      0.56      0.57        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.719204, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 34\n","\tAverage loss: 0.738332\n","\tAccuracy: 0.467153\n","              precision    recall  f1-score   support\n","\n","         0.0       0.71      0.25      0.37        20\n","         1.0       0.40      0.83      0.54        12\n","\n","    accuracy                           0.47        32\n","   macro avg       0.56      0.54      0.46        32\n","weighted avg       0.60      0.47      0.43        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.694774, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 35\n","\tAverage loss: 0.740478\n","\tAccuracy: 0.481752\n","              precision    recall  f1-score   support\n","\n","         0.0       0.45      0.71      0.56        14\n","         1.0       0.60      0.33      0.43        18\n","\n","    accuracy                           0.50        32\n","   macro avg       0.53      0.52      0.49        32\n","weighted avg       0.54      0.50      0.48        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.726724, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 36\n","\tAverage loss: 0.793467\n","\tAccuracy: 0.401460\n","              precision    recall  f1-score   support\n","\n","         0.0       0.58      0.70      0.64        20\n","         1.0       0.25      0.17      0.20        12\n","\n","    accuracy                           0.50        32\n","   macro avg       0.42      0.43      0.42        32\n","weighted avg       0.46      0.50      0.47        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.739355, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 37\n","\tAverage loss: 0.772869\n","\tAccuracy: 0.445255\n","              precision    recall  f1-score   support\n","\n","         0.0       0.43      0.67      0.53        15\n","         1.0       0.44      0.24      0.31        17\n","\n","    accuracy                           0.44        32\n","   macro avg       0.44      0.45      0.42        32\n","weighted avg       0.44      0.44      0.41        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.726876, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 38\n","\tAverage loss: 0.709165\n","\tAccuracy: 0.437956\n","              precision    recall  f1-score   support\n","\n","         0.0       0.18      0.17      0.17        12\n","         1.0       0.52      0.55      0.54        20\n","\n","    accuracy                           0.41        32\n","   macro avg       0.35      0.36      0.36        32\n","weighted avg       0.40      0.41      0.40        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.734019, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 39\n","\tAverage loss: 0.747275\n","\tAccuracy: 0.401460\n","              precision    recall  f1-score   support\n","\n","         0.0       0.33      0.29      0.31        14\n","         1.0       0.50      0.56      0.53        18\n","\n","    accuracy                           0.44        32\n","   macro avg       0.42      0.42      0.42        32\n","weighted avg       0.43      0.44      0.43        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.703496, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 40\n","\tAverage loss: 0.716244\n","\tAccuracy: 0.459854\n","              precision    recall  f1-score   support\n","\n","         0.0       0.47      0.47      0.47        15\n","         1.0       0.53      0.53      0.53        17\n","\n","    accuracy                           0.50        32\n","   macro avg       0.50      0.50      0.50        32\n","weighted avg       0.50      0.50      0.50        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.697577, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 41\n","\tAverage loss: 0.720285\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.47      0.60      0.53        15\n","         1.0       0.54      0.41      0.47        17\n","\n","    accuracy                           0.50        32\n","   macro avg       0.51      0.51      0.50        32\n","weighted avg       0.51      0.50      0.50        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.696766, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 42\n","\tAverage loss: 0.722818\n","\tAccuracy: 0.525547\n","              precision    recall  f1-score   support\n","\n","         0.0       0.73      0.50      0.59        22\n","         1.0       0.35      0.60      0.44        10\n","\n","    accuracy                           0.53        32\n","   macro avg       0.54      0.55      0.52        32\n","weighted avg       0.61      0.53      0.55        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.691477, Accuracy: 0.571429\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 43\n","\tAverage loss: 0.717578\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.64      0.50      0.56        18\n","         1.0       0.50      0.64      0.56        14\n","\n","    accuracy                           0.56        32\n","   macro avg       0.57      0.57      0.56        32\n","weighted avg       0.58      0.56      0.56        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.694177, Accuracy: 0.571429\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 44\n","\tAverage loss: 0.757734\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.58      0.47      0.52        15\n","         1.0       0.60      0.71      0.65        17\n","\n","    accuracy                           0.59        32\n","   macro avg       0.59      0.59      0.58        32\n","weighted avg       0.59      0.59      0.59        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.703564, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 45\n","\tAverage loss: 0.758176\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.57      0.42      0.48        19\n","         1.0       0.39      0.54      0.45        13\n","\n","    accuracy                           0.47        32\n","   macro avg       0.48      0.48      0.47        32\n","weighted avg       0.50      0.47      0.47        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.704464, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 46\n","\tAverage loss: 0.723956\n","\tAccuracy: 0.459854\n","              precision    recall  f1-score   support\n","\n","         0.0       0.48      0.67      0.56        15\n","         1.0       0.55      0.35      0.43        17\n","\n","    accuracy                           0.50        32\n","   macro avg       0.51      0.51      0.49        32\n","weighted avg       0.51      0.50      0.49        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.741072, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 47\n","\tAverage loss: 0.737499\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.43      0.83      0.57        12\n","         1.0       0.78      0.35      0.48        20\n","\n","    accuracy                           0.53        32\n","   macro avg       0.61      0.59      0.53        32\n","weighted avg       0.65      0.53      0.52        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.777814, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 48\n","\tAverage loss: 0.735801\n","\tAccuracy: 0.430657\n","              precision    recall  f1-score   support\n","\n","         0.0       0.42      0.44      0.43        18\n","         1.0       0.23      0.21      0.22        14\n","\n","    accuracy                           0.34        32\n","   macro avg       0.33      0.33      0.33        32\n","weighted avg       0.34      0.34      0.34        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.761137, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 49\n","\tAverage loss: 0.729907\n","\tAccuracy: 0.467153\n","              precision    recall  f1-score   support\n","\n","         0.0       0.38      0.38      0.38        16\n","         1.0       0.38      0.38      0.38        16\n","\n","    accuracy                           0.38        32\n","   macro avg       0.38      0.38      0.38        32\n","weighted avg       0.38      0.38      0.38        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.718506, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 50\n","\tAverage loss: 0.730957\n","\tAccuracy: 0.481752\n","              precision    recall  f1-score   support\n","\n","         0.0       0.70      0.35      0.47        20\n","         1.0       0.41      0.75      0.53        12\n","\n","    accuracy                           0.50        32\n","   macro avg       0.55      0.55      0.50        32\n","weighted avg       0.59      0.50      0.49        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.727156, Accuracy: 0.400000\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 51\n","\tAverage loss: 0.711952\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.67      0.63      0.65        19\n","         1.0       0.50      0.54      0.52        13\n","\n","    accuracy                           0.59        32\n","   macro avg       0.58      0.59      0.58        32\n","weighted avg       0.60      0.59      0.60        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.730307, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 52\n","\tAverage loss: 0.736716\n","\tAccuracy: 0.452555\n","              precision    recall  f1-score   support\n","\n","         0.0       0.50      0.67      0.57        18\n","         1.0       0.25      0.14      0.18        14\n","\n","    accuracy                           0.44        32\n","   macro avg       0.38      0.40      0.38        32\n","weighted avg       0.39      0.44      0.40        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.717616, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 53\n","\tAverage loss: 0.738683\n","\tAccuracy: 0.445255\n","              precision    recall  f1-score   support\n","\n","         0.0       0.47      0.44      0.45        16\n","         1.0       0.47      0.50      0.48        16\n","\n","    accuracy                           0.47        32\n","   macro avg       0.47      0.47      0.47        32\n","weighted avg       0.47      0.47      0.47        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.713397, Accuracy: 0.371429\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 54\n","\tAverage loss: 0.767669\n","\tAccuracy: 0.445255\n","              precision    recall  f1-score   support\n","\n","         0.0       0.45      0.31      0.37        16\n","         1.0       0.48      0.62      0.54        16\n","\n","    accuracy                           0.47        32\n","   macro avg       0.47      0.47      0.46        32\n","weighted avg       0.47      0.47      0.46        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.798996, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 55\n","\tAverage loss: 0.758241\n","\tAccuracy: 0.467153\n","              precision    recall  f1-score   support\n","\n","         0.0       0.48      0.69      0.56        16\n","         1.0       0.44      0.25      0.32        16\n","\n","    accuracy                           0.47        32\n","   macro avg       0.46      0.47      0.44        32\n","weighted avg       0.46      0.47      0.44        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.723102, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 56\n","\tAverage loss: 0.722566\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.61      0.55      0.58        20\n","         1.0       0.36      0.42      0.38        12\n","\n","    accuracy                           0.50        32\n","   macro avg       0.48      0.48      0.48        32\n","weighted avg       0.52      0.50      0.51        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.721203, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 57\n","\tAverage loss: 0.734822\n","\tAccuracy: 0.452555\n","              precision    recall  f1-score   support\n","\n","         0.0       0.43      0.67      0.53        15\n","         1.0       0.44      0.24      0.31        17\n","\n","    accuracy                           0.44        32\n","   macro avg       0.44      0.45      0.42        32\n","weighted avg       0.44      0.44      0.41        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.724449, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 58\n","\tAverage loss: 0.748074\n","\tAccuracy: 0.445255\n","              precision    recall  f1-score   support\n","\n","         0.0       0.48      0.73      0.58        15\n","         1.0       0.56      0.29      0.38        17\n","\n","    accuracy                           0.50        32\n","   macro avg       0.52      0.51      0.48        32\n","weighted avg       0.52      0.50      0.48        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.712160, Accuracy: 0.400000\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 59\n","\tAverage loss: 0.695018\n","\tAccuracy: 0.510949\n","              precision    recall  f1-score   support\n","\n","         0.0       0.39      0.64      0.48        11\n","         1.0       0.71      0.48      0.57        21\n","\n","    accuracy                           0.53        32\n","   macro avg       0.55      0.56      0.53        32\n","weighted avg       0.60      0.53      0.54        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.695521, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 60\n","\tAverage loss: 0.736750\n","\tAccuracy: 0.430657\n","              precision    recall  f1-score   support\n","\n","         0.0       0.69      0.45      0.55        20\n","         1.0       0.42      0.67      0.52        12\n","\n","    accuracy                           0.53        32\n","   macro avg       0.56      0.56      0.53        32\n","weighted avg       0.59      0.53      0.53        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.696495, Accuracy: 0.457143\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 61\n","\tAverage loss: 0.729798\n","\tAccuracy: 0.430657\n","              precision    recall  f1-score   support\n","\n","         0.0       0.64      0.50      0.56        18\n","         1.0       0.50      0.64      0.56        14\n","\n","    accuracy                           0.56        32\n","   macro avg       0.57      0.57      0.56        32\n","weighted avg       0.58      0.56      0.56        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.712572, Accuracy: 0.457143\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 62\n","\tAverage loss: 0.722731\n","\tAccuracy: 0.452555\n","              precision    recall  f1-score   support\n","\n","         0.0       0.56      0.74      0.64        19\n","         1.0       0.29      0.15      0.20        13\n","\n","    accuracy                           0.50        32\n","   macro avg       0.42      0.45      0.42        32\n","weighted avg       0.45      0.50      0.46        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.712279, Accuracy: 0.371429\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 63\n","\tAverage loss: 0.718279\n","\tAccuracy: 0.467153\n","              precision    recall  f1-score   support\n","\n","         0.0       0.48      0.73      0.58        15\n","         1.0       0.56      0.29      0.38        17\n","\n","    accuracy                           0.50        32\n","   macro avg       0.52      0.51      0.48        32\n","weighted avg       0.52      0.50      0.48        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.706546, Accuracy: 0.400000\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 64\n","\tAverage loss: 0.700490\n","\tAccuracy: 0.496350\n","              precision    recall  f1-score   support\n","\n","         0.0       0.56      0.56      0.56        16\n","         1.0       0.56      0.56      0.56        16\n","\n","    accuracy                           0.56        32\n","   macro avg       0.56      0.56      0.56        32\n","weighted avg       0.56      0.56      0.56        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.705155, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 65\n","\tAverage loss: 0.751415\n","\tAccuracy: 0.423358\n","              precision    recall  f1-score   support\n","\n","         0.0       0.47      0.57      0.52        14\n","         1.0       0.60      0.50      0.55        18\n","\n","    accuracy                           0.53        32\n","   macro avg       0.54      0.54      0.53        32\n","weighted avg       0.54      0.53      0.53        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.732752, Accuracy: 0.457143\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 66\n","\tAverage loss: 0.718187\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.32      0.73      0.44        11\n","         1.0       0.57      0.19      0.29        21\n","\n","    accuracy                           0.38        32\n","   macro avg       0.45      0.46      0.37        32\n","weighted avg       0.48      0.38      0.34        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.727769, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 67\n","\tAverage loss: 0.704063\n","\tAccuracy: 0.518248\n","              precision    recall  f1-score   support\n","\n","         0.0       0.53      0.64      0.58        14\n","         1.0       0.67      0.56      0.61        18\n","\n","    accuracy                           0.59        32\n","   macro avg       0.60      0.60      0.59        32\n","weighted avg       0.61      0.59      0.59        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.707082, Accuracy: 0.400000\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 68\n","\tAverage loss: 0.732012\n","\tAccuracy: 0.459854\n","              precision    recall  f1-score   support\n","\n","         0.0       0.62      0.25      0.36        20\n","         1.0       0.38      0.75      0.50        12\n","\n","    accuracy                           0.44        32\n","   macro avg       0.50      0.50      0.43        32\n","weighted avg       0.53      0.44      0.41        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.707674, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 69\n","\tAverage loss: 0.715199\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.60      0.35      0.44        17\n","         1.0       0.50      0.73      0.59        15\n","\n","    accuracy                           0.53        32\n","   macro avg       0.55      0.54      0.52        32\n","weighted avg       0.55      0.53      0.51        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.708908, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 70\n","\tAverage loss: 0.699354\n","\tAccuracy: 0.503650\n","              precision    recall  f1-score   support\n","\n","         0.0       0.56      0.78      0.65        18\n","         1.0       0.43      0.21      0.29        14\n","\n","    accuracy                           0.53        32\n","   macro avg       0.49      0.50      0.47        32\n","weighted avg       0.50      0.53      0.49        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.737642, Accuracy: 0.400000\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 71\n","\tAverage loss: 0.748349\n","\tAccuracy: 0.416058\n","              precision    recall  f1-score   support\n","\n","         0.0       0.59      0.65      0.62        20\n","         1.0       0.30      0.25      0.27        12\n","\n","    accuracy                           0.50        32\n","   macro avg       0.45      0.45      0.45        32\n","weighted avg       0.48      0.50      0.49        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.726649, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 72\n","\tAverage loss: 0.730042\n","\tAccuracy: 0.496350\n","              precision    recall  f1-score   support\n","\n","         0.0       0.62      0.42      0.50        19\n","         1.0       0.42      0.62      0.50        13\n","\n","    accuracy                           0.50        32\n","   macro avg       0.52      0.52      0.50        32\n","weighted avg       0.54      0.50      0.50        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.704891, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 73\n","\tAverage loss: 0.754242\n","\tAccuracy: 0.423358\n","              precision    recall  f1-score   support\n","\n","         0.0       0.33      0.18      0.23        17\n","         1.0       0.39      0.60      0.47        15\n","\n","    accuracy                           0.38        32\n","   macro avg       0.36      0.39      0.35        32\n","weighted avg       0.36      0.38      0.34        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.707006, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 74\n","\tAverage loss: 0.734256\n","\tAccuracy: 0.437956\n","              precision    recall  f1-score   support\n","\n","         0.0       0.53      0.59      0.56        17\n","         1.0       0.46      0.40      0.43        15\n","\n","    accuracy                           0.50        32\n","   macro avg       0.49      0.49      0.49        32\n","weighted avg       0.50      0.50      0.50        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.723879, Accuracy: 0.400000\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 75\n","\tAverage loss: 0.726681\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.52      0.63      0.57        19\n","         1.0       0.22      0.15      0.18        13\n","\n","    accuracy                           0.44        32\n","   macro avg       0.37      0.39      0.38        32\n","weighted avg       0.40      0.44      0.41        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.746104, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 76\n","\tAverage loss: 0.726716\n","\tAccuracy: 0.459854\n","              precision    recall  f1-score   support\n","\n","         0.0       0.43      0.67      0.53        15\n","         1.0       0.44      0.24      0.31        17\n","\n","    accuracy                           0.44        32\n","   macro avg       0.44      0.45      0.42        32\n","weighted avg       0.44      0.44      0.41        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.747048, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 77\n","\tAverage loss: 0.778550\n","\tAccuracy: 0.423358\n","              precision    recall  f1-score   support\n","\n","         0.0       0.50      0.62      0.56        16\n","         1.0       0.50      0.38      0.43        16\n","\n","    accuracy                           0.50        32\n","   macro avg       0.50      0.50      0.49        32\n","weighted avg       0.50      0.50      0.49        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.710936, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 78\n","\tAverage loss: 0.713733\n","\tAccuracy: 0.532847\n","              precision    recall  f1-score   support\n","\n","         0.0       0.50      0.11      0.18        18\n","         1.0       0.43      0.86      0.57        14\n","\n","    accuracy                           0.44        32\n","   macro avg       0.46      0.48      0.38        32\n","weighted avg       0.47      0.44      0.35        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.701677, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 79\n","\tAverage loss: 0.726147\n","\tAccuracy: 0.416058\n","              precision    recall  f1-score   support\n","\n","         0.0       0.47      0.60      0.53        15\n","         1.0       0.54      0.41      0.47        17\n","\n","    accuracy                           0.50        32\n","   macro avg       0.51      0.51      0.50        32\n","weighted avg       0.51      0.50      0.50        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.708236, Accuracy: 0.371429\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 80\n","\tAverage loss: 0.737084\n","\tAccuracy: 0.459854\n","              precision    recall  f1-score   support\n","\n","         0.0       0.38      0.50      0.43        16\n","         1.0       0.27      0.19      0.22        16\n","\n","    accuracy                           0.34        32\n","   macro avg       0.33      0.34      0.33        32\n","weighted avg       0.33      0.34      0.33        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.727660, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 81\n","\tAverage loss: 0.747597\n","\tAccuracy: 0.437956\n","              precision    recall  f1-score   support\n","\n","         0.0       0.44      0.44      0.44        16\n","         1.0       0.44      0.44      0.44        16\n","\n","    accuracy                           0.44        32\n","   macro avg       0.44      0.44      0.44        32\n","weighted avg       0.44      0.44      0.44        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.780850, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 82\n","\tAverage loss: 0.713364\n","\tAccuracy: 0.518248\n","              precision    recall  f1-score   support\n","\n","         0.0       0.52      0.65      0.58        17\n","         1.0       0.45      0.33      0.38        15\n","\n","    accuracy                           0.50        32\n","   macro avg       0.49      0.49      0.48        32\n","weighted avg       0.49      0.50      0.49        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.712459, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 83\n","\tAverage loss: 0.709665\n","\tAccuracy: 0.503650\n","              precision    recall  f1-score   support\n","\n","         0.0       0.75      0.53      0.62        17\n","         1.0       0.60      0.80      0.69        15\n","\n","    accuracy                           0.66        32\n","   macro avg       0.68      0.66      0.65        32\n","weighted avg       0.68      0.66      0.65        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.698517, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 84\n","\tAverage loss: 0.725514\n","\tAccuracy: 0.445255\n","              precision    recall  f1-score   support\n","\n","         0.0       0.53      0.53      0.53        17\n","         1.0       0.47      0.47      0.47        15\n","\n","    accuracy                           0.50        32\n","   macro avg       0.50      0.50      0.50        32\n","weighted avg       0.50      0.50      0.50        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.694544, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 85\n","\tAverage loss: 0.729125\n","\tAccuracy: 0.430657\n","              precision    recall  f1-score   support\n","\n","         0.0       0.50      0.37      0.42        19\n","         1.0       0.33      0.46      0.39        13\n","\n","    accuracy                           0.41        32\n","   macro avg       0.42      0.41      0.41        32\n","weighted avg       0.43      0.41      0.41        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.715618, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 86\n","\tAverage loss: 0.712227\n","\tAccuracy: 0.423358\n","              precision    recall  f1-score   support\n","\n","         0.0       0.59      0.68      0.63        19\n","         1.0       0.40      0.31      0.35        13\n","\n","    accuracy                           0.53        32\n","   macro avg       0.50      0.50      0.49        32\n","weighted avg       0.51      0.53      0.52        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.709410, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 87\n","\tAverage loss: 0.698345\n","\tAccuracy: 0.510949\n","              precision    recall  f1-score   support\n","\n","         0.0       0.46      0.85      0.59        13\n","         1.0       0.75      0.32      0.44        19\n","\n","    accuracy                           0.53        32\n","   macro avg       0.60      0.58      0.52        32\n","weighted avg       0.63      0.53      0.51        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.708868, Accuracy: 0.400000\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 88\n","\tAverage loss: 0.689975\n","\tAccuracy: 0.532847\n","              precision    recall  f1-score   support\n","\n","         0.0       0.52      0.85      0.65        13\n","         1.0       0.82      0.47      0.60        19\n","\n","    accuracy                           0.62        32\n","   macro avg       0.67      0.66      0.62        32\n","weighted avg       0.70      0.62      0.62        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.708707, Accuracy: 0.457143\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 89\n","\tAverage loss: 0.728454\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.54      0.39      0.45        18\n","         1.0       0.42      0.57      0.48        14\n","\n","    accuracy                           0.47        32\n","   macro avg       0.48      0.48      0.47        32\n","weighted avg       0.49      0.47      0.47        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.704761, Accuracy: 0.542857\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 90\n","\tAverage loss: 0.740833\n","\tAccuracy: 0.467153\n","              precision    recall  f1-score   support\n","\n","         0.0       0.67      0.44      0.53        18\n","         1.0       0.50      0.71      0.59        14\n","\n","    accuracy                           0.56        32\n","   macro avg       0.58      0.58      0.56        32\n","weighted avg       0.59      0.56      0.56        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.698163, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 91\n","\tAverage loss: 0.703207\n","\tAccuracy: 0.467153\n","              precision    recall  f1-score   support\n","\n","         0.0       0.38      0.64      0.47        14\n","         1.0       0.38      0.17      0.23        18\n","\n","    accuracy                           0.38        32\n","   macro avg       0.38      0.40      0.35        32\n","weighted avg       0.38      0.38      0.34        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.724792, Accuracy: 0.400000\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 92\n","\tAverage loss: 0.729524\n","\tAccuracy: 0.467153\n","              precision    recall  f1-score   support\n","\n","         0.0       0.59      0.72      0.65        18\n","         1.0       0.50      0.36      0.42        14\n","\n","    accuracy                           0.56        32\n","   macro avg       0.55      0.54      0.53        32\n","weighted avg       0.55      0.56      0.55        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.731541, Accuracy: 0.400000\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 93\n","\tAverage loss: 0.725372\n","\tAccuracy: 0.452555\n","              precision    recall  f1-score   support\n","\n","         0.0       0.53      0.67      0.59        15\n","         1.0       0.62      0.47      0.53        17\n","\n","    accuracy                           0.56        32\n","   macro avg       0.57      0.57      0.56        32\n","weighted avg       0.57      0.56      0.56        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.722663, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 94\n","\tAverage loss: 0.737943\n","\tAccuracy: 0.459854\n","              precision    recall  f1-score   support\n","\n","         0.0       0.24      0.33      0.28        12\n","         1.0       0.47      0.35      0.40        20\n","\n","    accuracy                           0.34        32\n","   macro avg       0.35      0.34      0.34        32\n","weighted avg       0.38      0.34      0.35        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.710731, Accuracy: 0.457143\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 95\n","\tAverage loss: 0.694215\n","\tAccuracy: 0.481752\n","              precision    recall  f1-score   support\n","\n","         0.0       0.59      0.62      0.61        16\n","         1.0       0.60      0.56      0.58        16\n","\n","    accuracy                           0.59        32\n","   macro avg       0.59      0.59      0.59        32\n","weighted avg       0.59      0.59      0.59        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.700612, Accuracy: 0.542857\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 96\n","\tAverage loss: 0.707063\n","\tAccuracy: 0.496350\n","              precision    recall  f1-score   support\n","\n","         0.0       0.52      0.69      0.59        16\n","         1.0       0.55      0.38      0.44        16\n","\n","    accuracy                           0.53        32\n","   macro avg       0.53      0.53      0.52        32\n","weighted avg       0.53      0.53      0.52        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.701860, Accuracy: 0.400000\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 97\n","\tAverage loss: 0.729180\n","\tAccuracy: 0.459854\n","              precision    recall  f1-score   support\n","\n","         0.0       0.36      0.73      0.48        11\n","         1.0       0.70      0.33      0.45        21\n","\n","    accuracy                           0.47        32\n","   macro avg       0.53      0.53      0.47        32\n","weighted avg       0.58      0.47      0.46        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.724383, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 98\n","\tAverage loss: 0.733093\n","\tAccuracy: 0.459854\n","              precision    recall  f1-score   support\n","\n","         0.0       0.45      0.71      0.56        14\n","         1.0       0.60      0.33      0.43        18\n","\n","    accuracy                           0.50        32\n","   macro avg       0.53      0.52      0.49        32\n","weighted avg       0.54      0.50      0.48        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.701823, Accuracy: 0.542857\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 99\n","\tAverage loss: 0.709931\n","\tAccuracy: 0.496350\n","              precision    recall  f1-score   support\n","\n","         0.0       0.50      0.26      0.34        19\n","         1.0       0.36      0.62      0.46        13\n","\n","    accuracy                           0.41        32\n","   macro avg       0.43      0.44      0.40        32\n","weighted avg       0.44      0.41      0.39        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.694100, Accuracy: 0.571429\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 100\n","\tAverage loss: 0.748591\n","\tAccuracy: 0.445255\n","              precision    recall  f1-score   support\n","\n","         0.0       0.36      0.29      0.32        14\n","         1.0       0.52      0.61      0.56        18\n","\n","    accuracy                           0.47        32\n","   macro avg       0.44      0.45      0.44        32\n","weighted avg       0.45      0.47      0.46        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.710091, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 101\n","\tAverage loss: 0.699565\n","\tAccuracy: 0.445255\n","              precision    recall  f1-score   support\n","\n","         0.0       0.37      0.54      0.44        13\n","         1.0       0.54      0.37      0.44        19\n","\n","    accuracy                           0.44        32\n","   macro avg       0.45      0.45      0.44        32\n","weighted avg       0.47      0.44      0.44        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.717003, Accuracy: 0.400000\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 102\n","\tAverage loss: 0.728413\n","\tAccuracy: 0.445255\n","              precision    recall  f1-score   support\n","\n","         0.0       0.65      0.65      0.65        20\n","         1.0       0.42      0.42      0.42        12\n","\n","    accuracy                           0.56        32\n","   macro avg       0.53      0.53      0.53        32\n","weighted avg       0.56      0.56      0.56        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.731044, Accuracy: 0.400000\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 103\n","\tAverage loss: 0.713957\n","\tAccuracy: 0.467153\n","              precision    recall  f1-score   support\n","\n","         0.0       0.48      0.73      0.58        15\n","         1.0       0.56      0.29      0.38        17\n","\n","    accuracy                           0.50        32\n","   macro avg       0.52      0.51      0.48        32\n","weighted avg       0.52      0.50      0.48        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.731412, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 104\n","\tAverage loss: 0.749553\n","\tAccuracy: 0.437956\n","              precision    recall  f1-score   support\n","\n","         0.0       0.50      0.50      0.50        14\n","         1.0       0.61      0.61      0.61        18\n","\n","    accuracy                           0.56        32\n","   macro avg       0.56      0.56      0.56        32\n","weighted avg       0.56      0.56      0.56        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.726563, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 105\n","\tAverage loss: 0.725275\n","\tAccuracy: 0.430657\n","              precision    recall  f1-score   support\n","\n","         0.0       0.40      0.43      0.41        14\n","         1.0       0.53      0.50      0.51        18\n","\n","    accuracy                           0.47        32\n","   macro avg       0.46      0.46      0.46        32\n","weighted avg       0.47      0.47      0.47        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.704028, Accuracy: 0.400000\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 106\n","\tAverage loss: 0.710711\n","\tAccuracy: 0.452555\n","              precision    recall  f1-score   support\n","\n","         0.0       0.55      0.32      0.40        19\n","         1.0       0.38      0.62      0.47        13\n","\n","    accuracy                           0.44        32\n","   macro avg       0.46      0.47      0.44        32\n","weighted avg       0.48      0.44      0.43        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.696675, Accuracy: 0.457143\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 107\n","\tAverage loss: 0.758424\n","\tAccuracy: 0.416058\n","              precision    recall  f1-score   support\n","\n","         0.0       0.43      0.56      0.49        18\n","         1.0       0.11      0.07      0.09        14\n","\n","    accuracy                           0.34        32\n","   macro avg       0.27      0.31      0.29        32\n","weighted avg       0.29      0.34      0.31        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.710894, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 108\n","\tAverage loss: 0.717990\n","\tAccuracy: 0.423358\n","              precision    recall  f1-score   support\n","\n","         0.0       0.50      0.50      0.50        18\n","         1.0       0.36      0.36      0.36        14\n","\n","    accuracy                           0.44        32\n","   macro avg       0.43      0.43      0.43        32\n","weighted avg       0.44      0.44      0.44        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.705484, Accuracy: 0.428571\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 109\n","\tAverage loss: 0.715994\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.56      0.71      0.63        14\n","         1.0       0.71      0.56      0.63        18\n","\n","    accuracy                           0.62        32\n","   macro avg       0.63      0.63      0.63        32\n","weighted avg       0.64      0.62      0.63        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.707392, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 110\n","\tAverage loss: 0.699778\n","\tAccuracy: 0.510949\n","              precision    recall  f1-score   support\n","\n","         0.0       0.35      0.73      0.47        11\n","         1.0       0.67      0.29      0.40        21\n","\n","    accuracy                           0.44        32\n","   macro avg       0.51      0.51      0.44        32\n","weighted avg       0.56      0.44      0.42        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.718745, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 111\n","\tAverage loss: 0.729242\n","\tAccuracy: 0.503650\n","              precision    recall  f1-score   support\n","\n","         0.0       0.53      0.50      0.52        16\n","         1.0       0.53      0.56      0.55        16\n","\n","    accuracy                           0.53        32\n","   macro avg       0.53      0.53      0.53        32\n","weighted avg       0.53      0.53      0.53        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.698419, Accuracy: 0.457143\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 112\n","\tAverage loss: 0.737190\n","\tAccuracy: 0.452555\n","              precision    recall  f1-score   support\n","\n","         0.0       0.60      0.40      0.48        15\n","         1.0       0.59      0.76      0.67        17\n","\n","    accuracy                           0.59        32\n","   macro avg       0.60      0.58      0.57        32\n","weighted avg       0.60      0.59      0.58        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.693151, Accuracy: 0.571429\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 113\n","\tAverage loss: 0.728656\n","\tAccuracy: 0.452555\n","              precision    recall  f1-score   support\n","\n","         0.0       0.56      0.53      0.55        17\n","         1.0       0.50      0.53      0.52        15\n","\n","    accuracy                           0.53        32\n","   macro avg       0.53      0.53      0.53        32\n","weighted avg       0.53      0.53      0.53        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.711572, Accuracy: 0.514286\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 114\n","\tAverage loss: 0.713740\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.52      0.69      0.59        16\n","         1.0       0.55      0.38      0.44        16\n","\n","    accuracy                           0.53        32\n","   macro avg       0.53      0.53      0.52        32\n","weighted avg       0.53      0.53      0.52        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.717292, Accuracy: 0.400000\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 115\n","\tAverage loss: 0.722698\n","\tAccuracy: 0.401460\n","              precision    recall  f1-score   support\n","\n","         0.0       0.59      0.65      0.62        20\n","         1.0       0.30      0.25      0.27        12\n","\n","    accuracy                           0.50        32\n","   macro avg       0.45      0.45      0.45        32\n","weighted avg       0.48      0.50      0.49        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.714534, Accuracy: 0.371429\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 116\n","\tAverage loss: 0.727822\n","\tAccuracy: 0.481752\n","              precision    recall  f1-score   support\n","\n","         0.0       0.45      0.64      0.53        14\n","         1.0       0.58      0.39      0.47        18\n","\n","    accuracy                           0.50        32\n","   macro avg       0.52      0.52      0.50        32\n","weighted avg       0.53      0.50      0.49        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.761943, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 117\n","\tAverage loss: 0.693158\n","\tAccuracy: 0.467153\n","              precision    recall  f1-score   support\n","\n","         0.0       0.27      0.31      0.29        13\n","         1.0       0.47      0.42      0.44        19\n","\n","    accuracy                           0.38        32\n","   macro avg       0.37      0.36      0.37        32\n","weighted avg       0.39      0.38      0.38        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.722738, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 118\n","\tAverage loss: 0.704255\n","\tAccuracy: 0.503650\n","              precision    recall  f1-score   support\n","\n","         0.0       0.50      0.86      0.63        14\n","         1.0       0.75      0.33      0.46        18\n","\n","    accuracy                           0.56        32\n","   macro avg       0.62      0.60      0.55        32\n","weighted avg       0.64      0.56      0.54        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.725388, Accuracy: 0.485714\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","1:  torch.Size([32, 8, 7, 500])\n","torch.Size([32, 8, 7, 500])\n","2:  torch.Size([32, 16, 1, 500])\n","3:  torch.Size([32, 16, 1, 125])\n","Epoch: 119\n","\tAverage loss: 0.691714\n","\tAccuracy: 0.474453\n","              precision    recall  f1-score   support\n","\n","         0.0       0.47      0.54      0.50        13\n","         1.0       0.65      0.58      0.61        19\n","\n","    accuracy                           0.56        32\n","   macro avg       0.56      0.56      0.56        32\n","weighted avg       0.57      0.56      0.57        32\n","\n","1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.712696, Accuracy: 0.485714\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P13io3iMHLzz","colab":{"base_uri":"https://localhost:8080/","height":154},"executionInfo":{"status":"ok","timestamp":1613859278985,"user_tz":480,"elapsed":34765,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}},"outputId":"c6d79142-8da0-468b-eccb-da22e6824b48"},"source":["conv1 = list(CNNPoor.children())\r\n","print(conv1[1].weight.shape)\r\n","weight1 = conv1[1].weight.reshape((8,125)).data.numpy()\r\n","#weight2 = conv1[4].weight.reshape((16,7)).data.numpy()\r\n","# weight3 = conv1[9].weight.reshape((32,32)).data.numpy()\r\n","#weight4 = conv1[10].weight.reshape((16,32)).data.numpy()\r\n","# weight5 = conv1[16].weight.reshape((1,176)).data.numpy()\r\n","pyplot.figure(figsize=(20,10))\r\n","pyplot.imshow(weight1)\r\n","\r\n","#pyplot.imshow(weight2)\r\n","#pyplot.imshow(weight3)\r\n","#pyplot.imshow(weight4)\r\n","# pyplot.imshow(weight5)"],"execution_count":130,"outputs":[{"output_type":"stream","text":["torch.Size([8, 1, 1, 125])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f6b7a996710>"]},"metadata":{"tags":[]},"execution_count":130},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1440x720 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"sZSSbDW4hQwZ","colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"status":"ok","timestamp":1613859278986,"user_tz":480,"elapsed":34758,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}},"outputId":"664ec2b4-21b3-4016-dcfa-ed7f0f26d599"},"source":["pyplot.plot(plots[\"train acc\"], \"royalblue\", label = \"train\")\n","pyplot.plot(plots[\"test acc\"], \"darkorange\", label = \"test\")\n","pyplot.title(\"accuracy over training\")\n","pyplot.legend()\n","pyplot.show()"],"execution_count":131,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9eZgkV3Un+jsRGZFbLd3VVV2tbi0tYWwQliyDJGxssEGDH/jZAhvGgBcsBozfzPDheZ7nDzTzPYwxy3jegu3nFctsFljC2BhhBDIYsxgkpAa1hKSWkOgWknqpru7aMzP28/6490bciIyszKyqrMxSxe/76qvMyNjjxj3n/H7nnkvMjAIFChQosPtgDPsEChQoUKDAcFAYgAIFChTYpSgMQIECBQrsUhQGoECBAgV2KQoDUKBAgQK7FIUBKFCgQIFdisIAFCjwNAcRPUhEP73V6xbY+aBiHECBAqMJIjoM4AQAi5mD4Z5NgacjigigwI4ECTxt2i8RlbZzuwIFgMIAFNgEiOjtRPQ9IlolooeI6Bcyv/8GER3Tfn+uXH4REf0DEc0T0Xki+hO5/J1EdLO2/WEiYtXJEdGXieg9RPR1AE0AlxHRG7RjHCei38ycwyuI6CgRrchzfRkR/Xsi+lZmvd8mok93uM6DRHQbES0Q0WNE9Bva8hYRTWnr/igRnSMiS37/D/L8FonoDiK6RFuXieg/E9GjAB7NOfRX5f8lIlojoh8nohuI6OtE9H4iOg/gnUT0DCL6kryX54joY0S0RzvO40T077R7/Aki+qi8Zw8S0dUbXPe5RHSv/O3viOhWInp33j0sMJooDECBzeB7AF4IYBLA7wG4mYguAAAi+vcA3gng9QAmAFwP4DwRmQD+CcD3ARwGcAjALX0c89cAvBnAuNzHWQA/J4/xBgDv1wzNtQA+CuB3AOwB8CIAjwO4DcClRPTszH4/2uGYtwB4CsBBAK8G8F4iegkznwJwJ4BXaev+MoBPMrNPRK8A8N8A/CKAGQBfA/C3mX2/EsDzAVyec9wXyf97mHmMme+U358P4DiAWQDvAUAA3ifP79kALoK4951wvbymPRD34k/6XZeIbACfAvBhAFPyun4hfxcFRhbMXPwVf1vyB+AogFfIz3cA+K2cdX4cwDyAUs5v7wRws/b9MABW6wL4MoB3dTmHf1THBfCXAN7fYb0/B/Ae+fk5ABYBlHPWuwhACGBcW/Y+AB+Wn98E4EvyMwF4EsCL5PfPAXijtp0BEblcIr8zgJescy2p65fLbgDwRJd78EoA92rfHwfw77R7/EXtt8sBtPpdF8I4nYTUEeWyfwPw7mG3w+Kv978iAiiwYRDR6yW9skRESwB+GMC0/PkiiAghi4sAfJ83Lmo+mTmHlxPRXZKeWQLwsz2cAwB8BMAvExFBeP+fYGY3Z72DABaYeVVb9n2IyAUA/h7Aj8vI50UAIghPHwAuAfBH2v1ZgDASh7R9pa6nR2TvwSwR3UJEJ4loBcDNSO5BHs5on5sAKutoCZ3WPQjgJMueP++8Cow+CgNQYEOQXPZfAXgLgH3MvAfAAxAdHCA6g2fkbPokgIs7dDgNADXt+4GcdeIOh4jKEB3w/w1gVp7D7T2cA5j5LgAeBIX1ywD+Jm89AKcATBHRuLbsYgjvF8y8COCfAbxG7ucWrVN8EsBvMvMe7a/KzN/Iu571rrXL8vfKZVcw8wSAX0VyDwaF0wAOSQOqcNGAj1lgi1EYgAIbRR2i05kHACJ6A0QEoHATgP+DiJ5HAj8gjcbdEJ3H/yCiOhFViOgn5DZHAbyIiC4mokkAN3Y5BxtAWZ5DQEQvB/Az2u9/DeANRHQdERlEdIiInqX9/lEITttn5n/LOwAzPwngGwDeJ8/1SgBvhPCyFT4OoXW8Wn5W+AsANxLRc+Q9mpTaSK+Yh4goLuuy3jiANQDLRHQIQvMYNO6EoMbeQkQlqXdcuw3HLbCFKAxAgQ2BmR8C8P9AdARzAK4A8HXt97+DECg/DmAVgpufYuYQwM8D+AEAT0CIq6+R23wBwK0A7gfwLQixeL1zWAXwVgCfgODwfxlCqFS/3w0pDANYBvAVCFpG4W8gjJbemefhdRB8/CkI4fN3mfmL2u+3AXgmgDPMfJ92/E8B+AMAt0hq5gEAL+9yLP36mhD38OuSRvqxDqv+HoDnQlzjZwH8Q6/H2CiY2YMQt98IYAki6vgnAHk0WoERRTEQrMCuBRFVIbKInsvMeWmYBfoAEX0TwF8w84eGfS4FekMRARTYzfiPAO4pOv+NgYh+iogOSAro1wFcCeDzwz6vAr2jGEVYYFeCiB6HEEpfOeRT2cn4IQj6rQ4xLuHVzHx6uKdUoB8UFFCBAgUK7FIUFFCBAgUK7FLsKApoenqaDx8+POzTKFCgQIEdhW9961vnmHkmu3xHGYDDhw/jyJEjwz6NAgUKFNhRIKLv5y0vKKACBQoU2KUoDECBAgUK7FL0ZABI1FB/RNZCf3vO7zeQqO1+VP69SS5/sbbsKBE5RPRK+duHieiE9ttVW3tpBQoUKFBgPXTVAGT99j8F8FKIYfv3ENFtshSAjluZ+S36Amb+VwBXyf1MAXgMonCWwu8w8yc3cf4FChQoUGCD6CUCuBbAY8x8XNb/uAXAKzZwrFcD+Jysb1KgQIECBYaMXgzAIaTrfD+FdD1zhVcR0f1E9EkiyisL+1q0z4b0HrnN+2Vp3zYQ0ZuJ6AgRHZmfn+/hdAsUKFCgQC/YKhH4MwAOM/OVAL4AMdlGDDlZxhUQs0Qp3AjgWQCugZhS7m15O2bmDzDz1cx89cxMWxprgQIFChTYIHoxACeRnujhQrksBjOf12ZTugnA8zL7+CUAn2JmX9vmNAu4AD6EQdYSf+hm4L6/GNju+8b3vwgsDrj+WOAAD3wY2GmlPvwmcPcfAF9/h/h76qvdtylQIIu1U8Cj/zjcc4hC4DsfBKKNTn43ePRiAO4B8EwiulROBP1aaDXXgdjDV7gewLHMPl6HDP2jTR6uCnI90N+p94FHPgHc/4GB7b5vfP7XgXv+r8Ee48TtwB1vAM4N7rYOBE99Bfja24G7fl/8fTU3MCxQYH0c/TPgM68CQr/7uoPCqa8D//xG4KmvdV93SOiaBcTMARG9BYK+MQF8kJkfJKJ3ATjCzLcBeCsRXQ8ggJj39Aa1PREdhoggvpLZ9ceIaAaiIuNRAP/bpq+mE6w64DcGtvu+4a0B7vJgj6Gud9DH2Wqo8379/cCd7wQWHh7q6RTYoVg7BXAk2pO5ZzjnELTE/xF+B3sqBcHMt0PMtaove4f2+UZ0mL6PmR9HjmjMzC/p50Q3BXsM8Ne27XBdEbpAMGCDFEhGbtDH2WqE8rxLFcAaGy3DXWDnoDkn/vsNoDIkAxB64v8Iv4O7YySwVRde9yiAWXRygz6f0BH/R+W6e0Ugz9usjNZzK7CzEBuAIbYfZQBGuA3vEgMgPclREESVhztoz1Z1pDvNg1bnXSqL5zbC3lOBEUZDiwCGhcgf/jl0wS4xAHWAw6TzHSZiAzDoCGCbjrPVUOdtVgR1FzgjnUVRYATBPFoRwAi/g7vEAIyJ/6NgiYNtomZ2KgWkzrskKSBgNJ5bgZ0DZzHxvofZ/gsKaERgKwMwAg9CdXADF4F3MgVEgGGNluEusHOgvH9gyBSQigBGt/3uDgMwSp7kdkUAsQEYAaPXDwJH8P9EyXMbYQ+qwAgiZQBGIAIY4XdwlxgA6UmOQkeiOO7ITxrIII8zCkavH4Su4P+BIgIosDE0RiUCKETg0UAcAYyAAVCeOTDYhhHu0AggdAT/D4wWdVdg50CPAEZBAxjh9rs7DIA9Qp5kuE0GYLuopq1G4GgRwAhRdwV2DhpnADIBMkaEAhrd9rs7DMAoUUB6BDDI89mpInDoAqasDG4VEUCBDaA5B9Rnh18CJhr9LKCeSkHseIySJ6mPRRhkx7ZTxwEEGgVUiMAFNoLmHFCbFeMBRiICGN32u7sigFF4ENuuAYyA0esHuRrADruGAsNFQxqAoUcAhQg8GhglETilAWwHBTQC19wPAqeggApsDjEFNFaIwF2wOwyAaQGmPRqWeNsiAEkB7TT6RE8DLVUB0Gg8twI7A6oMRBwBjIIBGJE6ZDnYHQYAGJ3KkroGUIjA7dA1ADUYbIQ9qAIjBndJdLz1A7IM/AiIwBylHb8RQk8GgIheRkSPENFjRPT2nN9vIKJ5Ijoq/96k/RZqy2/Tll9KRN+U+7xVzjY2OIxKbfnt1gCCpmiAOwWhlgYKjI7hLrAzoAaB1SQFNAoRADAafU8OuhoAIjIB/CmAlwO4HMDriOjynFVvZear5N9N2vKWtvx6bfkfAHg/M/8AgEUAb9z4ZfSAYTcGhe3WAAAxz+5OQeiKUhAKw/biCuwsNHUDMCIiMDAafU8OeokArgXwGDMfZ2YPwC0AXrGZg8p5gF8C4JNy0Ucg5gUeHEaFSghdMUCFzMGngZoyqBqF6+4VQTYCGBHDXWBnQBmAURKBgZFtw70YgEMAntS+P4WcKR4BvIqI7ieiTxLRRdryChEdIaK7iEh18vsALDGzKvTeaZ8gojfL7Y/Mz8/3cLodMCqepOrgBu2dhA5Q2Sc+7yQKRU8DBYbvxRXYWWicEf9HSQQGRrYNb5UI/BkAh5n5SgBfgPDoFS5h5qsB/DKAPySiZ/SzY2b+ADNfzcxXz8zMbPwMR4VLViKnPUDvhFkcpzotvo9o48tFEQEU2AyacyK6ru4T71joDm9CocgT0T4wGn1PDnoxACcB6B79hXJZDGY+z8wqveUmAM/Tfjsp/x8H8GUAPwrgPIA9RKRGIrftc8sxKiJwKPPcrTpajTX83k3n4HpbLNIqz6MqI4Cd0oGq+ZJ1DaCIAAr0g8YcUNsvOt5hV5MNPaC8d7jn0AW9GIB7ADxTZu3YAF4L4DZ9BSK6QPt6PYBjcvleIirLz9MAfgLAQ8zMAP4VwKvlNr8O4NObuZCuGBVPMnTlbFdjWFtawVe+3cSpc1vsoahUU0UBjWjja0MUiIwlPQIYZKRU4OkHNQYAGH4JmMgHKsoAjGYb7loLiJkDInoLgDsAmAA+yMwPEtG7ABxh5tsAvJWIrgcQAFgAcIPc/NkA/pKIIghj8z+Y+SH529sA3EJE7wZwL4C/3sLraseoeJKxBjAGwxGNwvW2eJCIyjSKKaDRbHxt0KeDVBgVw11gZ0CNAgaSUiLDciBCD6hMic8j2oZ7KgbHzLcDuD2z7B3a5xsB3Jiz3TcAXNFhn8chMoy2B7bsSJjFAKNhQWkAVh1GcBYA4AVbbABUCmh1h4nAgZoQvqCACmwQjTPAPpmlXhpyCZjQA8ZkbsuItuHdNRI4CgY7C1cvUBqAPQYjFI3C8wdkAHYaBaQigKwIHLSAKBzOORXYeiyfAEK/+3p5aC0AzXP5v+llIIDhFxOMPKC8R3weUSdsFxmAEaksGWsAdZSiARkApQHsNBE4yKOApBcX7KDBbAU6w1sFPvRs4OGPb2z7L/4m8PnX5//mLgsHL9YAhlxMMPQAqyYcvmH3Ox2wiwzAiFQE1TQAc1ARgPKkY/5xNBtfG/I0gGHzuAW2Fu6ycFDWTm1s+8YZoNlhPJA+CAwYDRHYtIc/HmEd7CIDMCoRgEoDHUOJhVc7MAqoVB2d8Q+9IMzTAIqS0E8rxBMVbfA9XC+vXy8DAQzfeQg9wLBHJwU9B7tjRjBgdCYYDzQKiF2Y8OFt9TiVuCOtjLT30YYgTwMYodncCmwem52nInA6FzdsZAzAsKP+0BMRgD26mWy7xwCMyvSCoTYSGEDFaA4wAqiMtPfRhlwNoKCAnlZQNN9Gn2foAOiQxafKQNQPiP/DjvojDzCskY7CCwpou6HXAgJQpRbcQWkApR0WAeSOA1Ai8A4xYgXWx2bnqQic9SkgVQYC0CYUGkL7ZxbnaY42BbSLDMCIiMCaBgAAVaMxuAhAHWdEG18b8jSAYfO4BbYWsQaw0QjATZdZ1tGcA2ozSf2deEKhIbR/dY4jLgLvIgpoRCIArRQEAFRoABSQrgHspFIKuRrAiDy3AluDrYgAyMz/raGNAVAYVvtX441GXAQuIoDthKrSqVNARnNwI4F3GgW03jiAnXINBdZHuEkROHS6RAAZAzCs9q8MwIiLwLvHAIwClaAaRVYEHlQtoBwR+L7vOoii0ZyguqCAhoOj29Amzi+HePy0n5T72Mjz5Ei8Q+sZACUAKwzL+1bzASsRuIgAhgzTFg9jmA8i1Ll5JQIPMAJQx5Hex/ee8vC//+FZHP2uu87GQ0SeCFyqiv8j+gLtdBw/6eG3t6FN/NU/LuF3PzCvRQAbeJ7KgcoTgZlFFlBbBDAk71uPANTMZDx6jtfuMQDA8OkQ5eFqGsBARODQBUDS+0g8oLWWyJ9eaY7oJPF5GgAZw39uT2M0ZJtoOINtEyfnfaw0os2NA1Db5kUA3opo9/U8CmgERGAOk/d/hLDLDMCQxRi9gxukCKwqjhIlU2FyBF9GGt5WT0CzVYjvj51ePuzn9jSGL2vsBVsdhWYwtxDCcXmTEYDcNq+QXHYQmMKoiMDASLbhXWYAhjwgIxY5yykReCDjABSPHouoTfgycna2WnPYKoSuOO9sue4iAhgYlFMQDLDYahAyzi+HcH1G5KtO3O2/ImjsQXP7aOBsGQiFYUUAKQpodBMZdpcBsMeGO6BIL3dcqiBiY7ARAJDyPtTLvuUGZ6uQnRBeYSelsu4wBLEBGFybOLcUxvR36DnJD/12zIG2bdZ4ZAvBKQxLA9BF4GGXpV4HPRkAInoZET1CRI8R0dtzfr+BiOaJ6Kj8e5NcfhUR3UlEDxLR/UT0Gm2bDxPRCW2bq7busjrAGnJHomsARGhxfTBpoKGb8Oia9xFTQKNqALITwiuURjeLYqdDUUD+ACmguYVEtA3clnbwTRiArA6QLQOhMCoiMDCSTkzXgWBEZAL4UwAvBfAUgHuI6DZtakeFW5n5LZllTQCvZ+ZHiegggG8R0R3MvCR//x1m/uQmr6F3WPXEUxgGMiKnw9UtEYGjiOF6jGrFSI6jPGnN+/A6RABNJ0K1TKBhzpQGxIPkGq0I9armm9hjoo58gS1HsA0U0NxCsvPQ04TQfjvmUDcAmUyg5pxIGFCTIClYdVk+IgSMDgPIBgFdBFZ07A6lgK4F8BgzH2dmD8AtAF7Ry86Z+bvM/Kj8fArAWQAzGz3ZTWPYYqKengmgFdW3hAL60pEmfum/n0z2k9IAEu/Dl7/rcxA3nQivvvEkvna0haEjcOBFNl7xO0/h5FnNwxv2c3saww8HTwGd1SKA0N9EBKBn0bRFAHNAdaa9kx8W/aKLwDucAjoE4Ent+1NyWRavkjTPJ4noouyPRHQtABvA97TF75HbvJ+Iytlt5HZvJqIjRHRkfr7DRBC9YtgisEYBhRGjFVUFBbRJA/D4aR+NFqPlRslxSr1RQMtrERyXxSCdYSN04HEZUZT2GgsReHCII4ABUkBnF5NnGYvAQP/PNOgSAWT5f2B45cR1CkjNTTyCFNBWicCfAXCYma8E8AUAH9F/JKILAPwNgDcwx/L9jQCeBeAaAFMA3pa3Y2b+ADNfzcxXz8xsMngYFRG4VIEf8JZFAIsr4gUL1Xumc+kpEVh81CkgR6aEqn0MFYGDAOK8m3peul1EAIOCahP+AB//2YUgTuxKGYB+O8T1NIC8MhDA8CYUehqJwCcB6B79hXJZDGY+z8wqPrsJwPPUb0Q0AeCzAP47M9+lbXOaBVwAH4KgmgaLYUcAmgbg+YwW17ZEBF5cFW9vHMbnpoGu5WYBKTpI7WOoCF34EGMAmq52T0qjW099pyPYBgpobiHABdNCbuTATap19k0BrScCdzEA291+8kTgEYxiezEA9wB4JhFdSkQ2gNcCuE1fQXr4CtcDOCaX2wA+BeCjWbFXbUNCeXwlgAc2ehE9wxoTDUc9nO2GpgH4AeBENdTMZoqT3wgWV4W3HCinuYsIrNceSgzACAwOCxz4kPpINgIImp1ngiqwYQyaAmJmzC2GuHhW5psEjjZXdb8isK4BaBQQM9A8054BBAyPAsqOBB7GOfSArgaAmQMAbwFwB0TH/glmfpCI3kVE18vV3ipTPe8D8FYAN8jlvwTgRQBuyEn3/BgRfQfAdwBMA3j3ll1VJww7FNM0AM8XFFDNbCKMgHATHpjy3uN9pNJANRE4JwJw5OeRoICkBgBkIoDYg2oO4aSe3ojTQAf0+FebQmM6fIEFAODAAarT8qBblAbqrYrf8iKAYU0Fq4vApiUMwQhGAD3NB8DMtwO4PbPsHdrnGyE4/ex2NwO4ucM+X9LXmW4FdDGmsnfbD5/VAByuokriJfACRtXsPw2TmbGkIgBlAFIDwWrifxcKaGlEKCAvkgZAjwD0kZTqhS6wJVCe/2YckPVwVor5Fx8QBoBCB5iQBmAzGoA+EKzTIDBgNERgdR4jSGPuvpHAwKYbw/xSgDe9+zTmF/uczV2jgFQEUCaRFrdRIbjpcLxtpPpMXQMgAyjVUiKwTgE5MnNorcXDHyAWOHAj8cK0UUDASIbQW43jJz28+b2n48J9g4ZKA/V7MABv+5Oz+Ncj/T0DNQjsktgAuEB5UrTLzYwDYO3d61QHCBgNEVidxwi2391lALaoJsf3T/s4fsrvP3VSTWhtWPACIQJbcGAg3HDnq4u3uREAEKdR5lJAmjEYehQQOnCjPApodNPothoPP+7hsad8nDnXp3OxQSQawPrrRRHjnocc/Nt9/Y0XUem8F0yXYFsEipykGOJmxgHkRQDrUUDDFIGB4Y1I7oJdZgC2xhuIU+f6Fc4CNy4D4fsMJxL0zGZSQZc08TaMIwA3XVJB1tKJRwJr1UB1Y7C0NmSRNXDQCmUWUIoCGt0siq2GKsu8XQX74mqgXSIA1daPn+wvgeLsYgDbIkyOGajYBCNyNz5TXScNIKaARlQEVucxghHA7pkTGNgyKkG9DH6/TppW7MyT4wCALtNCqhmUyBBiUgYLK5kIQE07mYoAhLcVjwTuEAEsbJcQzFHiwRmlZPRm6MIJZBZQrgg8ei/QVkPV52+5kXiWsZhoinvVCaEn1idqL6e9DnotBufJtv7k2QCez7Ct3vSquYUQ+/eaICJUygSD3WSu6k2JwDoFdEa8H0pc1lGqAqDBOQ8d23KGAhrRaSF3ZwSg15UJfeCDzwK+23tJosQAMPDVtwGf/ZX8FaMQ+PBzgIdvEd+DhJv3pAgMrDMpzFffDvxRRf5Vgce/0LaKTgGFIaTnwelpFS1RS2c9ETi7r4Hio1cl1/Xns8nzCBy0QvHCtA0EAwZfD+jbfwR88mcGe4wuWGuJ59FyGbj9V5P79MdjwLkH8ze690+APyyL9f6wDDz4kfz1chBrAJ2cmftvAm6+JqUzPXEmh/qcvx/4iwuAtVOpxWcXAsxOCcNVLRsosSz5vZGxHZ1KQTTPihpAebV+yBCJEL10vl/5HeDzb+jvnP72Bckz+rNpwFmU5+qJzl+NgCtE4BFAVRaKap1LljXOAIuPAKe/2fNuPN0AnPw6MHckf8XWPHD+oWTfYTJC1/cZHovPNrn5JZrPPwSMHQSe/9/EjELL32tbZTEbAeRNrF7dB7TO5ZaCcDyGJR3Lpe0aC3D+IeCiFwPP/hXAOQ8sPy48Og7R8NU4AO1+VHKe2yAw/53Oz3KboCIAx2Ng4Rgw9SzgR/6T6PxWvp+/0fljQuj/yfeKDm/xuz0fT3H/HbOATt8JzB2B10q89Vwa6MwR8S5ljNTZxRCzU6JjrtgEk51kTuytKgYXtNbPDjMrvY39OXsvcPZof+d0/iHg4E+ItuwuAWtyjKwyAPo5REMaf7QOdpcBqOwTL4heEVR97qNKqKJSvIDFdp0aciOz78DVKCDEOe82ufkRQOgA4xcDz/tt+b29AbVpAPHE6poBqM0CzTlNuwDCKNEDJuomKmXanrEAsqPHRS8GrvgNsaw5F593M1AjgTVjVNufrDfQc/PTNMMQsKZTQKEH7LscuOJN4sdOnVjoiLTm598ovOs+Bjp2zQKS9zxcPRMvOn4qJwLIeY88X0wEs19FADahBKUBbJYC0s4h29lmYdq93ZPA6b+TDhzgwhcKAwAkXn7kpam4Xs9hm7G7DIBhioqBjaQxxw22ke5cPn7HMo5+N78zSFFAzbnODTn7UmjpmZ7PsQGwyOtgAOTLohpSTgNKU0CMbMVRACI/unkWvlbzVx3P9Rhlm7B3zNgeCkifE0FlbTTn4vNu+ooC0u6HaYnRo/pzGwQiX5xfH5N3/9O/reGr927dALU4AnBZdCKGnTz/Tp2TXvyvz47G75YFJN+LaC15P46f7M0AzC+Jne7fKyKAmh3CRCizgDYgAncqBZHtbLMwrN469tDtr5PmSJyHWcH5lqBzvdZqcn76ORlWYQBGAvXZdGef9dIlbv7cCr50JP/FVp505LUEL+2t5XcaWeOiibN+wPBYNBCb3FhkS0EVdTM6dwCLqxEmx8RjFBFADgVUmwU4hB0sxIuUAXA8RsUi7J0wt4cC0udEUAN3GokB8KIKDANJZVMFGcUMFFEgX+re1f1/+NdV3P6NreN2G9kIwLTXdQAApIv/GXZfXmxXEVjec5ZteGrCwIm8CKDR7kitNsS1TI4JAzBWVpkx5Q2KwG6S1aM/o9BL3pE89GoUQ6e/TjpInJkHnxRRzrHvLuSfk9nfc9ku7D4DUDvQlQLyfIbjdR4Ypbwm05HbcJgWqBSyxkVLz/R8hhclGkDuRO0qYlDZPzlzqC6thpjeI16wIOS0h60g0+Nq0dl4kRJ/XV9GAOPm9lBA+rzI5T3ixWjOxYbL4zKmJkz4QSbNtn6gLUrbciivMuydBnK9aEsH0DWcxDDHXmQcAXQYd6IP/DPtvubaTUpB5FwDc9v78azDZZxfDrG8lmkrOe+Ren4qY6huyQ6wVNmgCOwkiRxZCmi9CMC0O987HYHT23r6+QCAWcayKyKAY49qBkDP2jP6ey7bhd1nAOqzHQzAvMjaAbDSEP87vdhKBLbcpEPN9WYUZdE6Jx5+Jg3U1zWA3AhAjRswRIpZXgSwEmJ6UhkAtOOFxTAAACAASURBVM06BiCmWurRPAyZlOBqEUDZJuwZ32YKyBTjIVCbFfdJLve4jH3yelKZQNsSAcgXNMgx5h3g+Fs7gjpFASkv0ugWAWQooI1EAHntz12Kj2koA3CJOJc2GiiOdhOaTrVpWyYZjNmaAdiICBw4idird6ZZuiULo9cIoE8KSEu4WHSEATh9elkMqCwigBGF6nAUZaMaLIciIwWigBXQefJ05dlYntYh5TVmvcNqzafSQP2AEcjSx9Z6IrB6sXM4RM9nNByOI4Aw6qABSAMwxvMYqxnxtoAoBVGxBQW0vBbF4vDAkKWoVMcuz9tnOzZoqbEAWcM9CChaoa8IYOsMADPnUEBWInCuJwKv007Ww7ozgmkRl4p2f0gagDYaSL1HegQg74tVEl5HzRLbsCErZIZuX3SbiADGxWfOUkBDEIE1Z2ZRagBlNPDlbzcLEXhkUZsVD85bEd/1TkU2+BXJXXajgGyvSwSQ3bfG1Xo+g02NAso7ls7t5jQg5bFP7xEuVhgiXwOoJwZAzbXraiJwxTawd9xExMm1DwzZCEVpMkFCAe2LDUAmAvBWB1sRNI4AejMAzOtThf3C9Tmem1dQQD2KwF3ayXpQnn+uAWi2G4ALpkuYqBvpVNDQB5yFtm28DAVUK4kOM6TKxgb3hW6HCGCrROB+NYDkXVtoift/cNLFv9zTKETgkYUuPKr/agShbLxKvOo0OleJwJVAMwB5fGYzs28tW8MP0gYgN9rQud0ccU9x9jMqAuikAUiufRzzGKuKl1FpAE6sARipfQ4MugYAJBGApgHs26MoIO2e6BlDg0LYnwYQhGJg1GYn9FFotDIjtHsVgbu0k/UQrDcQTN3r6jQs6eyULcJlh6x0KmjzbLwemvPxvA1eNgIoJTTfhkblB5oG0BYBbIEIHPRpAHQNoGnARxk/eIGHB497cFtuOwXE4cjNabH7DEBN1gvRRauZH0ktUxRQtwigEmhzFOdRQI3MvnUNwE9G61ZLnSigbHpfOuxWk7jM7NVE4DwNQHLte4yEAkpHAEIE1vc5MGTHKdREiioCWRWVyzEFlNIAVJ2XQQrBMQXUmwagjOhWRQANrQKo48qMJNNO6I3Ix/ee8nBfNj25SztZD6ot5w4EU/d65kfiaNe2CJcdtPD4KR+RogubyXrgEGidT+1bRQCVkjgvl8sbK/DXSQPYChFYpXSCYy2wKzRna7UZwUMdl0wLA7K03GoXgbPn3QX3PNTCk3ODFY53nwGoa56kCl1nrhTLeqSAlMdXDdehgKJQ8P7xvs9kNACALPG5YvjtXqSq6WNq3G7Gs1uKKSClASDllaR2V5vFpDGPMUUBeYkBKEsNQN/nwJClqOoHRKchR1B6bGsUUEYDAAYbAfRJAan5lDtpRf1CGYCSCfiu7FwMW4xfIRMIPXzon5bxR7cupjfMUkB9RQDif24WUPOMOO7Us2H7wtmxS4QLZy04XjIPRWIAtLaO9gigaoprcsMNTpOoawDRFovAuvDfaxSgOVsrjQihUUPdbOKyQxacvAgA6OvZvO/D5/HxO1Z6Xn8j6MkAENHLiOgRInqMiN6e8/sNRDSvzfr1Ju23XyeiR+Xfr2vLn0dE35H7/GM5NeTgoaiExpkkdN37g+IByYbbNQKQy2vh2cQzzXoyrXPCq5i8THg7KgLQNACjZAFkoJIXAahGuM4AH0XX7JvMiQB0CggAV2cxZZ5LDIDPMYddkVlAwDYUhMtGKOp5rDwBAPDXywICBmwAFCHemwHY6ghAjQKemjQReKqcsJX8Dz2cXw5T1Vzj892oCLxeFlBjDqjNAGMHYUcrsMmBbRFqZfGqttR5KAF4WhoA+YyyGkBFGYBog9Mk6hpA2ziA9UTgHu5JapBZj/dPbsNmGSuNEIEpUlsnagaIc0Rgda49IIoYK41o4JRsVwNARCaAPwXwcgCXA3gdEV2es+qtzHyV/LtJbjsF4HcBPB9i0vffJSI1FdefA/gNAM+Ufy/b7MX0hOp0Ug4iriN+IJVmuNqjCFzneWDyGXJhpiHrNcprSuh0U2mgtmUAZgUVM88AZDz5HAOwsBqhViHUK/pAsBwNAEBY2Y+95rlUFpA6Ztk2MF4zUDK3gQLKZikpz17WufG4jKnJPA1AloMY5GjgPscBqEqqfiAE4c1CjQGY1g2A8iIlt7+4GranDIfuuu1kPaw7KXxzLnk3AExb8zBNQqUs2pCjIrRGJgKQbV85SraMAMqmuL9OWN5YBBA4oronGX2OBO4hKkrNNtZfBOCxDT8AopIY3FatGKAoaBeB+9h3w2FEDCwMOCLvJQK4FsBjzHycmT0AtwB4RY/7/18AfIGZF5h5EcAXALxMTgg/wcx3sXhzPgoxMfzgYZjCCDTmks6knjYAy2ocQEcRWCwf43lgz2VyYaYhq5dC7Xv1SehVOv2AxYtRqqBs+DkGINORG+085tJqiL3jJgz5FDuWggAQVPZjj3keY3J3rhfFHVjZIhAR9oyb20ABZa6rljYAhlWODVoqC8i0Rb2bgWoAygD0qAFoz6zv0uA5UBTQ9B4Toaeeox3/59DF0mrOwLNUGmh/FFCsAURIOH2F5pww0NJI7y8Lbr9iiw49LiXenBMd+qR8FxrpCEAVG6yQuK+tcAMiMHMykNKwcmoBbVIE7lRptIdtGp5e838NtQrB4JxxAEDPz0aNRRr06PxeDMAhAE9q35+Sy7J4FRHdT0SfJKKLumx7SH7utk8Q0ZuJ6AgRHZmfn89bpX+ozl6fS1QrEdF9HABgkYMqVnuLAOqzSSVHTQS2SgSY5fwIIEuVdEgD3TNugIhgGpk0UDMdAQT2fpQowF57Ob42RWGoF3rPuDH4LKC8cQBAfH9MuwLbIpTMTASg1h0hCsjRNIqt0AGUAdg3acIPMhOKmDYCTzgKqRHSrMYL9C8CM4u0U+VABNlH35hLIlgA07aoxlpVFJCraQD1WTHVo0aleoHo/BW7axuiw3QCq38RWKdEDaudAtqsCLyJCGBVGgCS5S1qZQMmZ0YCxxRQb89GsRBLq+GWRJedsFUi8GcAHGbmKyG8/N4LkncBM3+Ama9m5qtnZma2Zqf1A6KR6nOJaiUiulJAIWPKlKWJxy8UDTIbAejGpTYLrEl7p8pBB3JSjVIFZXLbo41sumSOCLy4EsXZO6ZJUgNQWTbpF8Ivi5d4rzkfX5sTU0DiBZ0aN7efAqrsFdcm749VFgNqahUjXREUEM9tBEVgYGt0gLVWBCJg77gJkzMGwLDhSWE4daz4eWsUUI9eZiTnnFEdeioTiFmIwJoB2FcSbb6NAmpKQ6FGdisNwOeY/gFEujMANIMNUEA6JWqUtl4EDjdgAOQ2a64lDyMigGqFYMJPRwDr1PPKg3JCgzD5PAj0YgBOArhI+36hXBaDmc8zs4qhbgLwvC7bnpSfO+5zoNAjAGtMTBghK2aCI6zIGx5F+elxfsDYqwxAbTaecjGFxhlZ9GpCZrrIh9gWAVRQNtzUxCwA2tMlcyKApdUwzt4pmVoWkJx2UodrCQ69Hp2FbRFcrz0CEAXhtokCUtelOg15f0plsbxapvScAMA2RAB9UkDaM+vHADw557cLuRARQK1CqFUMWFCzTCUisMoMilhrl/Jcl2Un1I8IrDJ/qrJDT2UCuctiP/XZWH/ZVxLOQxsF1DiTRHLaM4qdHAmLxHk1/A2IwHpyg6SAvveUhyiMckVgx4vw1FllRHu4J6lS0/1FAMuu6NzNyjjgraFWMWDCR2TkRQC9UkBJ+xgkDdSLAbgHwDOJ6FIisgG8FsBt+gqS01e4HsAx+fkOAD9DRHul+PszAO5g5tMAVojox2T2z+sBfHqT19I7dANQ1xquzGFebURx/5n3Yvs+Y0p60qgfEIWt8igg3StS0DUAS1BAtuG1RwBZqiRjAKKIsdxIKoGaBiVZQBn+H0gMQDWcR9miFAWkIoCJuoHlQc8LnI1sgPgZBLBRq8jSwRUjnQUEJGU8BoU+S0E4fv8GwPMZv/m+M/jMv7V7vo0WY6wq5s4tUbsI7Hteaj/6ud76r1rE0GMnozJ/VIeeygTS59ktldHEHkyVOlBADe090or2xU6ORBIB2P1P1ahTm6aF1TUPv/HeM7j7gQaEtpaOAP7xy2v4zfedEaVNetFFwg2kgcptVhxx7FJFisBlQon8uNQLgL5FYN3rHyQt29UAMHMA4C0QnfkxAJ9g5geJ6F1EdL1c7a1E9CAR3QfgrQBukNsuAPh9CCNyD4B3yWUA8J8gooXHAHwPwOe27Kq6oT4rOqLFR9OeCwB/5QxaLsdpkXncbm4EkCcCxy+FZgBSEYD4nlsLKKsBZERgkcYpOkpARgBKA8jw/wDglIQBqATzsC2C53P8AldssQ/bov4nuu8XoSNeVtKanrr3XI47l2qZ0uMAAHEfvVXAbw3m3PqkgPQIoFcNYGk1TOfQa2i0ItSrRtyBAEhpAKGXdFKxwyDPdamlIoDeKaAkApAGQI8AdA0LwBrNYNLIUEAey7E053uKAEyWlIlnC8eon4nStdLLoBJWVsW+zi80k+vWMLcYoOWyaEM9icAd5hpY95zS996uiX6gViZY5MOPtiYCGGSRxp4mhWfm2wHcnln2Du3zjQBu7LDtBwF8MGf5EQA/3M/JbhlUYz3/AHDpz4rPspNuLZ4GMIl9kyYWV/JL/XpBwqWjtj+/ITfnxGxe+vGAZBxAgFgDyK0FlOXKM41YdY5V6b0ZBglvRx8VqsGhPfDZQtk/i7KdHwGUTELEIrowDGrbx5YgL0KR98fjcmzQahUjNTJWXw/NOWDy8NafW9ivBtB/BKBe5jyDoQxApWygRNId1w2An3RMWQPgRTaCkFHqQwRWlUBzKSAVacl7vsLTsQFQbc5xWQx2BJLxMBqVmo0AKHThswXHl8vyqNNO0DUA00KjIa6x0cxkS0koHa/lRBgzbTnSN8yfNxjYmAgcOgCZWGkSrBJgVsYAjjBmeyiRj0akda/dSnpnsCJZCObBpmbvvpHAQNJYA0fzXMQyd0k0fFWOIC8V1A8Ye0vnsBZNCirDyokAsvSSglYLSGkAFvLGAWTTQNMisOp8KmXVeWvloHMiAD8EFsNpYQCUBuCnNYCSfDfaskG2EtqcCDHk8/AyEUCzLQLIlPHYavDGSkEAvdcDWlyRCQZZzQfAmhOhXiFUbIr5cl0EjrTRqgkFlNTXcT3uSwRWcwGoNpSigBpaEgOAZZ7BBERnb5qiw2u5UTqRQv2XVGqc6qwQuvC5DEdRR3nvTSfoGgCV0GzKFMxG5j5JKAql6bAmwK7T+W6EApID8FaaYlpVksJ2vdQQEQDnlILoVQRuhJjZY8KgwUYAu9MA6B1yLU3T+CvSAMgKm7kagKSAFkNZ6C3ryUSh8IJqGi+qoE0Jacs0UAs5U0J20QDUS6S8N9OkpBx0qV0D8ALGYjAN25uLKSDHyxqAHCpgq6GPWlWQ996L7FQE0MrTAIDBjQXosxicu4EsoMW19SIAoQFUy4RSjggcac8/HnegFdFzfU5E4B5SB9VALdWG2iggMsQ82gCWwhmMI0nDrpYNtDxuo4r0KM3LUEAIHPgoJ9RePxRQRgNwHXEvWk1VMiMtAisKpelGSTrmeh37RkRg6cysNiKM14x4bMOYIco3eNHGRwKvNoW+Nzng1OzdaQB0Tl59lhUzozVlAIQ73EkDmDLnsRBIA5AVgZ3zIuRUL4M9BpRqcl19JLCggEpYJw20QxaQeoniztuQnnsHDcAPRARQcs92FIGTCGCABiDMMQDyPjlRJgLoZACaAxCCOQKQplW6YUMU0EpvFJCV1QAyqYzx8WIKqCwLDCpPs/vItKCbBlCdiSmTxXAaVazEx6uUSVBA8WDKjN7VmEt0rviADkKyk/vWVwSQRMQBWwhluNLqRAE1FQWkRQDrdb4bSQOVzsxqI8J43Ygzm+qQY210CqhPEXilIaKKvWODnap1dxqA6jQA6ZmoToUIqO4HSe9S1aPJvthRJAbP7DXPYSGcEV53VgTOhM+pz2YFYciIIsQjgUtwOmoArHcAWgjbTgFRUg46RwPwfcZiOA3TFRqA43Gcx65E4CQCyL9tUcTto0X7xToagJ/RAJoupwfBxOUgBhABpKpL9i8C964ByEGGmTRQZsaaMgA2wVQGwEg0AIQe6rKcdyzWS+rCZ1ucTx9UQ1zV1lb71H5szKUi14UwXTK9apOggNoigISm8wOkI4DQRYCKRgFtJAIoww0MmOSjZEIUXQPaRGClATSdqDf+PRUB9DoSWLTllWaEiZoRj22oQhTr88KNi8CrTRFV7J0wCwpoy2GUkjr9Oh1UPwDDEQXiOhkA1TnuLZ3DYjAtXqJsQ86+FPpns5wMkZdpoCV2EYRIz8YlX+x3f0Qali4UkGFi3TRQP2AshjMwnbOwS+K6XI9FMoZ0VEolxQXnd2a//Ydn8Sd/t5j7W8/I1QCUCKxRQGUStfb1+6/mER6EBqC/9D1OCen4jLLs4Ho1AGqcRXZ9xxNOgaKA2iIA0wZFPmb3ZqjJIEMB9THiVLVl1YZSY16aZ1Lt97wv3xdpfCu2IZyQ5pyIblVphzgCONMmAiN0EJJGAfUjAmsaQCsooYQAzzpcTgyAFgGEEceF9ZquHhWtFwFsQgNoRJioJxRQhWUEEG5cBFZRxd6CAhoQ4qwFjZ+vz8LyzsIwgKmJfBHYCxgWORgzVrAYTguvSYWyylvVc6gV1MtUqsQvry1FYBM5Izylx/P9c7IRZUTgNgrIFB1mRxE4YCyEM6DIx2RpGa7UAMo2xUP1YwqoQ8T5+Gkfd9zVSI2A7RvrUEApEVgaglwheCAGQC8t0HsEMF6XxfV6FoHzKSCV8VSvEqploy0NNCQbBvvYPyUeUhIBJAYgTQH1HgGoe57OAppLRbDzXiYCUGm6mUhBUakiAmjXACKjolFAG9MAmp6JcinExQdKcJx2A7DWjOJXsaVHAL1qAP2MAzDbKaByKJwkJ8ibD6D7vpk5jir2jJtYHODYnN1rADLir1pW8c9ivGbEDTebrSEEYFEUazGcFkKaVRcdiHq4mRQ6cRz5kpQq6TK5pQrMqN0ABJ7IdW/4SgS0U+JelgIyDRkB5HWwkCKwDOP3mufikcAV7QVdTwSOIsZqM0LLZdz1nU3k4edFKJW9YLIyFJA4l/zBYIOOAHo3ABNqgp2crJ48xBRQmwEQ3+tVA1YJsCktAnuhCYt8zE7lRwC+LgIDPXU06jm3ZQExJwMZJc66mQigTCIKzaynqFQ053IjgMiwkwFkG9EAzDKarom6HWKibsJz2kVgfRBV0+3xnmykHHTgIDLEfdcpoJKfYwD6MMwNR0SDE2OCAnJcThdG3ELsXgNQnxUdtxqSDgC1WVSjc5ioJdxl1rPz/WQQ2GI4I37PVjZszIkHXp5M7RsAYJZjrtUqQUQA7ADg1LFWlluImNDyZQSgGhALD7KVoYBKJiXloDtRQFK0/oWVG/Ceif8V1y69JxaAAWB65Sv4j/velUsBNRyOvaov3qPNy3vfXwL3/UXb+h2Rp1GQAb88IyigWASWFUHzykHMHQE+di3w8RcAp+/OP87io8Dtv9qZCnngw8C3/zj5nqou2RsF1HIj/Fztr/DSsb/vOQJYWg3wX6b/Oy4K7kktr33rHfix2r+gXhXF/apWOgJwAwsl8rBfGoCsBuBxWURmfXDNfsCo0hpe8P0bsNecTwy/tyL2K9ssM2PeFdlAuPP3gI9di//svQxvM38WOHVn2okC4sKKbWmggQs2KkkNoX4MgOygQ6OMNddEzQ5F3f0oQ5Uh4f8B6UD04n2nIoCcNsMR8M9vBs5ozy10EJB41/QIgNwlAEAr7FEEZhZt9WPXAh+7Fvatz8efHboeL33sJXj5iZfgzw5dD/Nvnw8sP975/DeI3WsArngT8ILfSy+rTMFEgOm6A1s+uyxX6weMcUNwfKvRpNQAMoWt9DIQCs96DXDtjYA9kaaAZMqmBS8VbSwvN0VYr7yyTCN2MgPB4gjAb4raRhn4AfCIeyX4B1+DNetiTBrncEXr5phCAoD985/CL05+KNcAqPK0+yZN3P1gK/6OBz8i/npFB4rqiUvehs+tviamflQE0Ob5/PAbgIt+GqhMAafvBJ74Uv5xnvgX4NjHZBnuHBy7GXjww8l3nQLqNQLwGT+GW/DyiU/0pAGEEaPVaOH6yZvxI8bnU79NPfbH+Mn65+NS2JWSvL/yuTuhhRL5mJ3KUJOaBuDpInBPEQDwjPIxHFz4FJ5dPqoZgFXxvzwBQLQdH2U8NP1WYOYKoDoN19yHpXAvcNFPAT/8H9I7Lu8BvBVBl1qZCMDUKKBSVZx/L9Uu5XWeWS7Bi0qoWCHG6xpVponAK1oE0OpVBA5doQ0C+V56cx74zl8BJ7TnFjgIoAyAmfQDjih20PJ7FIFDV7RVdxmoTsO39mE53IuovA9cEZ/d0j4xO9sWY/cagIt+Grj6v6aXSU9+quqgbCcTp+jwAkbFEB5wM6onIjCQRADZsBgA9l0OvPC9ACXlFtRAMEAUytK9yLXVZvxSM3NbA2p5IsXONLUsoAjCCKmGqMEPGB6NgX7+Fnzp4r/DF1ZfiRqfR0VLnij7Z2FShCin1ILyqn7+hWMIQuCr98p1/LX+p/XLoaiOz7wRdzdfHHf8tU4awKUvA37xduAXPyfy1DsdW4mLnfh8fy39MkYbywKyyMFU6VxPBmB5LUJJ6j1jrJU299Zghk3Y5MZZPtVS2rNtBSWUKMD+rAicHQfQh9goIgDRZkvkaWML1OAq0bkpuurYRb8v7/3t+OzsrXjnuY+I78/4+fSOSxWR898WAQj6TwjenLSDXiIuuc7xMyZCNlE2A4zXjPYBc8hEAG77u5OLwAHs8c7rKd1Jb2+hKya4ByQFJPsBR1BALV/rsNd7Lup4V74Z+MXbcey5n8KNZz6Ckz/5acy/+DO48cxHcP8V/wBMXNS+7Saxew1AHuQD3FdtxhFAlqv1A6BKwgA4US0/AsgIaFnEEYDUAABRK13vRJprTfhsi8qPEbSJwaUBcKOYJgFETfcwDGUEoNFa8Xkn3phtERaDGZgIsddKsnpsX2RAhe5q2/aKV33uD1Vw8WwJX7y7kVxzvxN751BUatBXTV5TXHAsqwEoEK1PIajlnTJ6vLVMp9+/BuB4DAse9pi9GYCl1RCWLIg2QeeSH2TnYpEXT9lZyRiApm/BQhIBJJ21ooDsjAHoTQOoGsoABAhUFprqkKRXnWqvEnEWUB7MCjhwctNAlcPjev0aAAcA4fhpRgALthlism7ARKZkBpJBYJNjsqBg5t3puH97Qn7OWU/pTnpbDx34LI47UTfEgDPTBlzxTjX1CIBMAJS/7ygdxSgDNl43sVfWJBtUOYjCAOiQHflkxY3FqzwKSEUALa7JLKDM5BZqKr0O8HURWHaG2XpAraYTexep7A6NAtLpm5JJMEOhJeRFAJ7mjZUtwkIo5laYtpKOyHJFI2ev2ba9eqkm6gauu6aO+x9zMb8UiKjHb2B5LcRvv38Op851GYCUlwaKxNOvZiOArAagQ07AkQu1PHTw53+/iE98caX9d/1lVGUgzHJfpSBKcDFhLCHwum+zuBrFFTH30NnkB9m52OS2GwAZ9jc9EyXyMFZNt8vIbyFkExFKYlkfIrAfABVDRHIl8hPqL8Or5xmAapkQhJoWoUO7h9mBYGSJZ9/yOGkHvRhcmXJ54rQPuywyosbr2oA5TQRW9OT+vWZSDA7oHgFYdQDUgQKSBiBopLZxI00DAMS7JyOAhqddPFHHMh0snZTH59X5y3dNZgEBgysHURgADaEpuPM95SYMQ9Q7yc6/qofNcQSgi8AciTIQPUQAVkmLAMiNo43ltRAsU+bi9TMhpJrMXcE0CaVIGiA7nwJSRq1sG3FGUFzWGkDJlZ2S1x4B6AbgmsvFeT38uCeMnr+G7zzm4uijLr77RA9113MooKYTwaAkrTWhgNbxfKx65+hDRgDst/DZr6/h43espDsrfy39MqoIwB7vmQJyvAglWeHS8rvPVre4EiYGwDyXcO5yZHPZcOOMnLLhC+9S6kgNz4JBDNsU9yOeytFLHIW4FpD4oev5BGHSli34SVSh7ovKQMrM7QskmUO5UUBJRABANgJwQPLZt9woiQR7ud+y3ZyaD1CpWEDoSw0ghwJqRqhXCWM1o3cDoByTTsX0VGaf3t4CR0xvCcTZYLDqsQbQ9DO1NjvM1eDKeR4efkLcS6VhjNcNWCXCWJUGNhagMAAamqEwABO28IpUzRwdfsCoygjA5Wo7BdQ6LzJ1shqAhpRHpWsAcvmJUz5scmFIb0mk92U0gAwFVDIBM5Keex4FpA3Lty1KUkJljXf4DZih6Awir92rVhTQeM3A4YMWiIATJ10gaAJBC4+fdFLX1hEdNICWE6FaTsYk1GIKaJ39Wd0jgMWlJpoOY6UR4cgxJ/17XgRgjfXkkYYRww8AU86DZHtnu2whvDhlAPaa5+G68qVWqZWmF19/2QwQIvFq1zw58xt8GIYeAWgGIKedrAcRzaoIwEsGIobpTlU5JratRwBqVrAcA21W4ntoZTQAQyY9OK5GAfUSAcgO+uxiCLtsAxxgopZTMgOCQpmoGaiVjXQWULeRwKVK52J6sQagtbfQhROWUTITgygiAGEA1tyMAehQljqQBuDMkhGff7VM8b0To4ELCmjgWAvFdITjluhI8wyAEoEDo4YIZrsInDcKOIOUCKxFACraOH5SGAC7okcA6dDecTlpdBAUkM3SO8kVgZOXsWwRFiUFNKm4aD23PserXmmISpWmSajYBg5Ol/DUyaX49ydOLifn2glRKLJtcjSApstxBhAgIhrbyqkHpENOwp0LeQ1z8+KFJQK+eE8jOY+glX4Z4wigNwPgeQwSLQCAENC7YXE1QrUketQ/xwAAIABJREFUjmlSCG9NjCdRbaZsJOdjm+lqkquO4rF92CWKEwYiP+Gh8yLF9RCESCIA8rXU0rQByI0AbJWllR8BKAooqwEYtmjTzgY0gMgoY6URxRFA2TYSqiyTBTReN1GtUO8DwZRj0mlGtVwR2EErsDBeN2LDDasu2haAppdjAHKeiy/pw9OLRjzeJqaUIKYIHdRMfT0ZACJ6GRE9QkSPEdHb11nvVUTERHS1/P4rRHRU+4uI6Cr525flPtVv+7fmkjaOVU9EAHVTGoBSXgQgROBI0kVtEUBeHaAMvC4awPFTHqolD6YtDJKne3bSO2mjgAygtF4EoFNAFmEtmoDHNiZIUhfa6FrK6VRXG2GqUV52yMKp0wmvfuZMDwYgOx2khqYTxV6/Qi2vJLSOHkTgc+dEB3fd1TV8476WMCjKi8vOKwsA1nhPHZLjc5KBAqAS9GAAVkJM1ZJjhrLybGIAkuPaRhB37ACw6siMktATjolsQ+xvggIKEhHYpCCpAZURJVPtVWJdCsgsgyStExuNKAQiH4Zs0ykKqEcNQOXcVypJR1q35UlnI4C6jAD0gWDricAqOaHT5DGNTATAYirKpm8n9A+Qol9X3UzaZoe5idVMb03PwunzgSgtoe1zzwDLQXQ1AERkAvhTAC8HcDmA1xHR5TnrjQP4LQDfVMuY+WPMfBUzXwXg1wCcYOaj2ma/on5n5u5v0ICxIg1AzVyHAvJFBBCVxIP2siJwHAGsJwKL/2ogGJChgE76GLe9pHR0kJMGmqGATJNgs2ycHdJAlQEQoTxhMZhO0hG1qRbZbxeBVXEqhUsPWlhaSAzA0nlZAnc9A6DXdM/AyUQAgCgH0TELCOhJBF5YaOCCfSZ+/oVjcH3G1+9raQKxngYqH4o9Lii8LtU0XY9jOgcAamEPGsBqiKm6ZgBW5T1v5BkADwELDzIMOaETQg9WKUkl5iBLAfXQ2Un4IaMqKSCbvEST6BQBWO0UUO7zKVVAHMBAkFBA0qiaktZ0XE0E7lED8OV1Vqvl+PmMleVzyowEHq8bqFUoXQyuFw2g04xq2QhA7qsRlDFR1zp67d1zAjv9PphW7r6VAQhg4fhJvz0CGDIFdC2Ax5j5ODN7AG4B8Iqc9X4fwB8A6PQ0Xye3HVksu6JB1qRXVNY8LYVYBJadvq86Z6OUpoB6SQPNUkC+yI8+cdpHzfKS0tFee2ifpYBMA4kByBGBs1lAgChlUY/aIwAjyBeB9YZ+2SEbFUo637L8vO6IWH1WpwyaLsdjABRqlW4RQHcReGmpgUsP2XjOZWXMTpn4l3sayUvMofBMgcTrVfeui1fqeByndAJAvQf/ZWk1wmQ1MQCR8irjNNBkf2pCkTBiLK9FCR0UeXExP0AYgFwKqMcIoKaiXTNIsoDiNNC0CFzWDYCigHIjANWmvSQCkAagVM6hgHrUALzYAFhaBJCfBjpRM1CtGPAD0bGmrit3/5oG0IsILM+54VmpzlqPvgNY6YGMHSKA0JcGgC2cOOWLaFtztqbGTaw2o4FM19qLATgEQB9O+ZRcFoOIngvgImb+7Dr7eQ2Av80s+5Ckf/5PIqK8jbYTi45okEoYs+XMWTpiEVhaej/gdE56XAZiT8fjxCF1ygCIktCnzwfCGza9OGPCC9rFPcfjOFceEBqAhW4UkPisG4BaJDshTQOgoN2rXmmkI4DLDlnxeAgAcWpsTxRQhyygWjndHGtlA8dOuHjXTedSf5/8kow8pAh84pSHW76Qk+YJYG3NwWWHLBgG4bpr6jjysIOVJW1d1fHHFNBY6lxPnPLwN59bTpelhijnrEcAY1FvWUB7Klrnou657FwsJJ2DZQTw2YLrMRZXw8QAKAooNgBuOgLIMQC3f30N9z3a3sn6IVCTz61sePEMYbGXuk4E0C0LCBBRbbyN7DCVAWi5Ud8agBPaMAygWksooJqVTgONIsaaigDkOcbZON1EYEUBZb30KEymvtTSiwFg1bVT74UeAfhspdOYTRscevjr25awsJxQOmquZ58tHD/pYaURYVJzttT85EtrW08DbVoEJiIDwP8L4L+us87zATSZ+QFt8a8w8xUAXij/fq3Dtm8moiNEdGR+vvtLthksN4BWVI3FVF1sU/ACRoWaoLJmAICksmHzjCiGtY498/UXStcAAsbdD4qGVTaTmjl5InDLjeI6/oCMALAeBaSJwHZiAKpBEgGwLWoXUQ6tstqUJW8lLpguxdlSADBhtVCRcw13RHaSGwlmxvxiGFdgVXjBlVWM1wwcP+nFf/d+18FNn14WGStSBL7tq2v4wKeW0sZHemoWXFx2UNy75z+ngigCnnwqEa/jjlKngLRz/chnl/GhzyynJukGRMenGwB9tqw8MDOW1kJMaBEAtdIRQEkLni3yEbANx2WcOhcg4EQEFhQQ4vNMaQA5GS83fXoJt2YNJJQGIAyAZfjdKaBSDgWUmwWUtOnYAMgOs1qroVYhHHs8oTh71QCagS2mSVRz/HKEqhUgZDOeuKbhMCIW2WpxKrHfSwTgdhaB1QRP5cmk6q8851XPxlgtPwII2UonMZg2mk0XH/v8Cr75YPLuBJICqlTLOH7SF86W9q7NTpVwyYFSzwUH+0Evk8KfBKCPQb5QLlMYh5jc/cvSiT8A4DYiul5O/A4Ar0XG+2fmk/L/KhF9HIJq+mj24Mz8AQAfAICrr7566++AhsXVEC7qqMoO0LYJy5lSrCoCMG0RBKnOHJasbe6trEv/AMKIGIYs4yA7w4rpwfUYdz/YwGUHLVhI0kBTInAouNogRFsWEGINoLsIDIhidrY/L8cuzCGqH0LotmCEaVolijgpeSthGoSL9iUd4MVTLo6db9dMUuigAZxbDrHajHDpofS0fq956QRe89KJ1LLP37mG//k3Czg5H+BiawwIXTx+UrxMa60IU5Y0IpLmscnFZYfEvTswLZr7ytKydnGdIgAHa60Id8rKp3MLISbHEgOlG4AQpfTI3hw0WiJtdNwW2wRcEgZADqQLuBSXiQDkwCwWFMKJUz4CJM8/pU2FDrxoHPUK5UYAqrTw8ZM52SeaCGwbQeeBYHkisD4xfBYarRkPBFMRgF3FC6+q4Wv3NvFfXlYWV9WLBhA6aPpTohheXLMnQLUkIiX1ZNQgsIm6EZdziUsydBWBFQWUWU9FapPPAM5+WxgLGbWseTYO6ckLdjoCSGVJGTZ8Wb1Ud5QUBXToQA13HxOWXY8qrn1OFdc+p9r53DeBXiKAewA8k4guJSIbojO/Tf3IzMvMPM3Mh5n5MIC7AMSdv4wQfgka/09EJSKalp8tAD8HQI8OhoLFlQgekhrldomSDl5CjJ5swqgIT9FLRQBSBK53FoABbT5gIH5ZqiUP3z/j46ETHq67tp7Kmc4O8Y8LwekagAmUqZWcSwZ6KQgVASyEMzAQAq0FQUPUZ9GKajCCtAjcdIVXpUcAAHDRnqTDunCvmyuap9BBA1Cd06UHrewWbVCd+YmTfnydp04Lj17V1AdHoiQGgIrp4tCM6DCmJkyYBtBY0VP5VATQrgF87Wgz9rTPLqRFYVEHSAqB5kFM0voRwIJM4xu3xXHmgwMotebizmU+OCBSSllcQwlCBHY8xvGTHiYn1KCptAhMcqL1sZohZhnLiMBNWVr47GKItWa7M1NJRQCZeyKdjnjq0J6zgBJaM4kAknLO111TQ8NhfOtRuX4vE/AELtY8C7N7Te0aA1RKwlCqGdbiMgo1jQJykwyqjojTQHMoIKWP7blM/PfWtDLcdjp5QYu+g7YIwIq9fd2bVwbg4oPJe5t91waFrkdh5gDAWwDcAeAYgE8w84NE9C4iur6HY7wIwJPMfFxbVgZwBxHdD+AoRETxV32f/RZjcTVEaNQS79FqpzSECNyEYddRMrWaLCojJa8QXAapybJlZ1g1Xdz1gOjAX3J1TeRM6xGAJgKrsDtFAZmEqtEAl6pxONx2TJUFpCIANadxcw5ozoFqs3CiOsxMBKC/VDoOTiZh7AWTrVR6Yi46aAAnpAFQnft6uORACQYJbl511uwKgx0bgKAFNb/vvrEgLphnGoSZvSZaq7oGkKGANA3gX+5uYO+EuOazi2n+VY8A1qyLMWEu5ouHEiqNr26L450JLkTJOxt3LnPBhfLcpVgKHz6EB3n8pI+ZqWp8vvp9pkhoAOM1I1cE1mvjnziV7tjEOAApAlMOBaRE4JwIoGwRiNangCzykiwgLfr70R+qYGrCwJfvl/e0hwiAQwerri0iADOhwypmgABWPHpWXe9E3UwXFOyU3gnEKZ1JGmjmOSoBePIZ8loa0IvwpdKX20TgdAQQ+u1zf0TymR++MKnim33XBoWejsLMtzPzDzLzM5j5PXLZO5j5tpx1f1qjfsDMX2bmH8us02Dm5zHzlcz8HGb+LWYe3LxnPWJpNURYSlILO48EbgDWWMoTExTQqigD0cUA6HSM6gwrJQ9RBFz5A2Xh5QROnDOdTQNVmRfVTBZQhZpigvoux9RFYACiE2rMgcZm0eIqjDAdAaxqQ9N1zIwnntv+MRkBrMdTdtAAjp/yMLPH7KnRl20Dh/aX8L2TftxZKy+2oQQ3TcPYV0+/zLNTJTiNnAhALwUBYGlpDfd+18XP/cQYyhZhri0CSETgpi0YUl5noho1sXdNDgSb8y8Uo4cbygDIvArZsZgQGsDyWohT8wH2z1Tj801HAEIDGK8buRPC6NpFlgbyA0aZkgggbss5InBMWUoQESo2daWAkiygxACYBuHFV9fxzWPKYPdgAHxRd2d2ygRIpcT6KJsiAlBOil6yJC4o6HLbnNopxJpHpW3mPQBaBCANgBYBeNokRgDiNslUAsNIlzIx7djb70QBqXcz+64NCsVIYAlmxuJKBC7VYgExLw3U80NBtbQZgLqoPR8F3TUAn+Nqo+KFJVTkKNDrrqnJhsowbV0DSF5s9dJlNYCq0QTnCMBAuhSEqnMUG4Cl44C/BqodgMN1lDIRwLLMPpjIdNDT1SQC2FfrIQLooAEcP+m38f/r4dKDIl1OeVtqNGscAWipoXur6Zd+/14TXlNLc1WdAqcjgKPHlsEMXHdtHfunzDYDICIAKciXhfcerHY2AKqYV7XkgsnE+XAWZX8eaJwGAMz50gDIe2RAdGwPf99DxMAF++vx+eoDFI3IgcciE0UYAFMUkJPXFc/bAOD4qfS9CEJGRSYOiAhA/pAjAqdG9EpUyrRuFpBNbjIfQMb4X3d1DQ2/91pAKtspFQFwEI+YVgZAd1biaUXVWIBOEYDeLjtpAGYZGDsovvtrcTTrReW4gCGAJAKQ59hqywISz8BNRQDieHa5jMMXiO22iwLqRQTeFWi5DNdnkD0OBE8AyI8A4DdhkMhAaYsAVKpY1whAq5FCIhW0ErgomcBPPbcWVxw0La0aqCYCx7OBZbKAqtQAd4wA0nVZbIuw6IpyEDh3v/hfn4XLNUxG6Syg5KVKU0sVowWXK2AQqtTKHTmdQo4GEISMJ874fYlczzhk42tHW3BRQxnAmNUEPM0AaKODJyoZAzBVQvTYGqCi7bYIQBiA7zy8jB+82MbFsxb27y21UUCuNg7ArV4srmXlDKxUgnSCxZUQREDZFOM7FsNpGAiAhWMAgLOB7FxUBMAefLbw0AlxjAtmkwhAb5dG5MUaQBx9aZ3YquYRn8gaAD+ETfJ4OgUUjwROxgGUcwxAtWx0oIC0NNBSuwYAAD90iY0L9lcQsYGHH1vBg42ElpuaMHHdNZl2LEsv799rAueSCMA2AjTZxnImAhivGSDIieEdzvfsIWo6ffPeBbxAnVueAVC0bjziv5GOAPT0ZaUhyfc1pQFo4wD0SFkZAKtcxmWHLDzyhJceXDZAFAZAQnloRjkZXGSXctIa/WSwlV3KiMAKvYjA+gtlljFV93HdNXXx4JviZaFSVVQkzWgA2fmAAREBVIwWOEcABjK0E2RJ6NYk2LBA89IA1GbhogYzk9OudyLpna4hMMYAEOCvoWxTm9CYQo4G8OSc8Dwv60EAVrj0oAVm4NRyGZcCeOYBH/d+T2QBifNKDJji3BVmp0poauMX2kVgQQHNn2/ihddV5TYm7nogvR/XY1RM6QVWhAEI1zpHAGdlmqsRumCzjCUVfc3fj8CaQovlc5N8MLGMAB73ULYIM/t0CihJPzZZUkBVI2mrWmenuPEfeWYZ337YATPHdWt0qs8y/PRAMEpSK1NJCxo6UkBaGmieBgAICunnfnIc7r1lfOeRZfzlN5ZSu3jWJTYO7VeePsOMxHXOTpWARS0llnwEKMVOykojQq1CKJkUUzOi7ER+BHDkmIP/729P4wWXQBOBM1RRU87voTp3by021GIeaz0CEOuQacMqpSc0isgCcTsFxGESATzv2Ta+/YiDybEiAthWLK7I7IvKGNBIROAoEkPxFf8ZD5KKIwC5A330bT8agDgorr2McM1Lp8T3/5+9d4+y5Krvez+7XufV3TM9T2lmJGZGSCAhWRIaQBiEMYYgYSIgvnYI2E5WfCPnGpZ1HcIyZNncBNs3+DohwAq2r5MQO8vBXMcEWwngEGzwA/PQICY8hTR6gGakefdMd59XVZ3a94+9d9WuOnWe/ZgZzfmu1au7z6lTpx679m//vt/fw3pY0tWepQGURwEJaqJJ4ll9iDV6PRXFExQMAAhkbTfC9gBo4CdP5j6/bFUCzZ9Ik8bCPMoANMsNpo0SDeDxVACewADobZ84rQzAdbu68Fg5BeQXEtN3b3M5UWoADAWkDEAguuzTE9DubR7nlpOc4e5EkoanQzobSgNIVrNyGkU8fjxU7n2sSiKvOLr01Zmv0/WvIkzydIiThKmI+LxrA1wdEZaKwJFUE6PsEosKtapD3FMrWrfEA7j1+ip/daTNyXM9rtquHnunt5qSwD5RlgjWCzOahULQgoXaKArIscJAe/3030+8egH5cJW/c6vP6+9SNNrRYyG/8G9O8djxKDMA+lyEV1WTuhUF5IswpwHYWbS+pzzjVkcOLMR24kycUnlDw0Dn9+U9AL2vUFYKUUCGAgqUh2R5AO2el1Yv7YTZ61J7AK4f8KpDDV51qHwRtxGYaQAaxgPwavM5ERjyir0TZxU3fb9AARmMigLq8wBU9cQ0GdqiSpQOQS68rzwKSFEyids/eIyXkqOAzGfru9MGFtR3E1LHkwUKqFCeNtvxqhrwOgR2mjDQJ56OcB24Zvf4BuDq7R7ViuAL31HnsHdrSKMqWG3nReB2Uk/LNRvsWvRS0RiwooDyFFAgumn3rV369+mlTAfohjJt2yhq22kljXxFVfu0E8n3TsTKyOmaMy2h6bfOEh1vZ5rMZYykkFk10AN7/dwCIF146IkqEUE2Vk3ZECsKqFoR3HCtDp+1aCDX8gA8EdFLKaAwV11zoAYQDKCA9CRf90JrTJcXAhReFZ8ujZpDo+bwvOcEOEIZzOwCqs9W6toLcrLMXkeqHAk7CsgIqEIoL6DVTQaWYTh5Ls5KcHiDROATmgIyVX8tDUAGuYVYOg+4QVaLSKMd+mkPY/s5MQbAvuabhZkB0DDlViuNubSxS/pQxbYByCigPhEY1ACqLg79rr4VlVvJR0JYVIkqR5Focc9RHkAZBeSoMNAyA5CVn85eM5yumLOMVX0XoWjgFw1AoThVtmPdf1gnwY0WgfspoMePh1x7ld9vXIbAcQQHrvb52uPqhHbNt2nUnD4NYFUu9sWY71p00+xXoCQRTF0/X4RKcIS0D+9JSwfohFlpZ69SY6m3I8vsLeD46ZgwktoAqHjzlrszfb/lWgZA33vRC0mEMgAHbQOQROl1lrrscOJU0/uZ9gRIRWCVwb1fU2z2xGqL/R6hVQ46ytXW6Q4TgUspIJPcaF37uN/4qy/OSkeDMip7dnp5vUIvHKo1PW6cjAISSYgUPita7C6WUVAloXUmfZkBWMp6NJRqADJRDeEbV42nAVjzQFqNVKMZenhELC44pRRQatg2ETMDoGGq7VUbphRAOx30dtKGo5um4GkKKCp4APXhZSCgnALKRUJYVIkqR6Ff14NzUCJYTbTolRoAfYgFCsj3QBhvpboN3ICIuioqZ9W+ubDa64sAUjtuWh5Ak8DvT5zLocQDePzpaCL6x+DAXl+tuoHFarkBaIltfREmtarDvNfKZdYCigISDnhKHa65XbZqHtZ4AHYymPIAdMx+UGUp3oFolRuALNEtSGvORN5i2vBlVezMSj+b401CcNR1OrgnyAUB+J5ASuiFats+A2BNYqYw2lzNYfc2NxcJ5Bqx3w1UT2C7FpA72gOoVcTQPABjIIHBlWCLix+UwcuFrOr363NaubcoIBJlrFZsD8Aaq7mmMCUi8KlzcWYAyqKA7AZPOQ8gMwC1skxgN8j6EWisdj08EbFvl58v65Dku79tJmYGQGNpWXGHbiUTegxnbq9qTdcsJQKLfhF4hAAMJaKaV80/BGUaAKQru3Y3UREl1kOpROAWvZIooNQDsLYPfNXYJT1ebQhCMYdDkluVjfQAgrmUAhqpATh+Ki6uthNOneuNlQFcxME9AaGskEiB22spA9DJi8BtZ3tpjPmc36aFLtZni8COn05Qi/UIx1HXa+dW7QGcyzyAbiipuV0QLkHgs9Tbgdstrwj6xPEQR6gkNlNyoBI4rKpkeFbYSeIU6uL0QnDV9yoPwCoGp8dO1LE8gMBarFg0hn3vDuzx06Q7AM8YgOo2lXhmi8BFCqjEQ6sNagxvclus8tYDK8G61RIDEPD0mTg1Lq2m8tgaqQGwirtpvWJ5NROB7bFar4qsLWSJB3DqXC+vARRFYLu6r2n6buUBOEE1HSeA5QEEmn7Krs9K18UXEXM1J08B9cKsYukm44ozAKfOxX2VHUFpAIvzTq65i3mo7JuVGgC/kYvGSC3/CP4f8pU51U7zbrD9sOQMgPEAQkklyNonArhCFanrOeWloKG/o1MlEFnOgv4dCf2QWULqSqESaHYiTXXeuirnWGGg1gTwpF6NHtwzOfepvAZB5KiorUZV0DQagD720FssjTGfc1usJAMMgF75LtayySLwBdu3uDkPoBNK1cHLqxIEgnO9nXidwR7Avl2eqk2ji45VfMEySgi+kOzE8TW/bSbDJAInYHFBNwYveAAAcWgWCpkGUPQAbFH0ur0BT52Msp7UMjMALmGmAegJKdEtIgeJwNWKGFAOWjducQs8vmX8UxQoIMiivL73jBof55aUAZifL1JAMfRChFvh9Pke3zjaUUULrbFaMx5AiQgc9yRnL/SGewBG1zHPtWlD2uuS4FCtFCZuN0jHUa2S9wCWOx6eiKl4MrdQEklIMjMAG4/T52Pe8p6n+fI3+yeFpZWExQU31+A99QCsm5WumtJEMNL/gbEMQB+n6lbyE1VBA8gZgCSk3c2XggbwRQdHyLSxvQ1Dy9gU0LYFV1XfNMerf8eGQrJKQq+08rxqihIR2ESilCLu5iiA759QD+Rzrp7CA9jr43sgXUU/5SmgJl1ZRXj10jozVafFhUgXmbNLQTgeCIdIBizU8olfuxbdXC5AJ5RqgtM03VJvJ350trQcxONPRxzYa1E8+r4uS+UBLPV24FUsDUAmkMQE1QrPf45+vaABAERd5QFImwIyIrDRAFpZH4f9e3x6CRw/rd7zTQe5yqLyAPTpxWGXY2cEf35Yl/gOB+UBKA0gKd5vxyXGz7W4TMstF1GkP8lCgg0NdOKEMuhbtuaTrEgiSEI8P+D46Zj733+KJIEdW7OxmvaUKBGBz5zvkUhdeRfU8Tl+vk9ES0d2pQZA1/yKO8RU81nABsGcFoGdXDnoCy11XPUgzhuAi+gBXFFhoGfO91Q54FMRd5JPPFpa7vHcfUGuu1duVaWRGoBgDt/r9ovAI7KApTT1yq0J1avmGrLkNABfcMGsInSp2k6hFDSAn6iHJC7xAKKSKKB/9KatKmLkQsEAOFZ3M328Rbc627GmgBAQrqaTRBRL3KCEz+x1clEghrKZJu19oeHykV++msoD8xCt9mkA7aSuaimVUEAVmlyIn6sqUvUsEdjxiWJJV1aYr+Qni13bPB47lr3WDRMq9S54yktLs6rbp7OMUVQi0DNnYu6+0xjWThrddT7cAS6cjXfiGg+g10mP6RV3bOWld+jQYBMEkGQ19uNuRhWaa58mDfZCpJQ5721Rl9s2dEnmASzi8liaBxCGKgnNCLEDPQA9BrtR/4KkR5BNrOa8S/pA4FayKDSNq3d4VAOR6hVHHr7AIWDPVXpsizwFtP+aBv/Pq5So7jqCFxzMDE29qiOVSkRgk929Z1FN9tKtIOzGS45rtXjVVKnxAPwGMZW+8wZUORbH1y1N1bWWUnK+5UEFql5MGGZjXiQhidj8CCC4wgyASVI6X9JebWmlpxovWEp/WRho2nXLq+N74cQUUCdUZYFzomqRB7VipnM6g3ZP26FMOzJlx6VWa7FT4gGURAHN1RyoAXGeAopFXdVR00JquyvpJSU5AKbipt8ABMQtAk99TzeUVMvGc2ESMIWyiucyLvbu9NMIpEbNYbWdIKUk6ayoENCgCp1+A+DLJiuJzpewPQDX58z5HlUZqJacFnYtunzxG700kaoTSgInTI10agD+6t1Q2wHXvgoO/ihPPlPIc9BhoJVAcH55J7hwJtyOV7W6Y+ljqtWr1OyFgr7/gemjEupSHF5Ft/m0KKC4Q6eryoabBD4z5kzIZGAZAIc4zQROopBIBpzSYa/DSkGAaU6Ufy+iUtAAun0hoOqc+j0AxxHs3+PzxNMhK62Ex55cht1kRtLNi8B+UOHQjeWZ5IqGkaUisNF09m2LYQU6vQo1u5ieWZi5geoFAJYHsEBIZagHUPMc2h2ZLqI6sXoAa15MN7JW/ElEz5lRQBsOUyzMxPwbhJGk2ZZqhWQp/WVhoJ5sEaEqbgZ2GOj8tbDrdtizTvDNAAAgAElEQVT78qHHkFbWtFe9XiXPg1ohc5WgXwQutoME8HVNl8gZLwooxcIB2H0I9t4FQM+1Qt3IF9fKwVTcNCIwUNO9lAeGghY0gE43Uck67nQGAFD3K24yV1X0UxhJ4k6TjqzjVvonF5IebtJmpVeiAQiPU+diwqRCw+/PIA4jyXm9ek57AuvV99HuTXT83fDof4WHPgh//c8AKwLIUEBxRgF9I7wT9ryMk+FO/IqlARSqcabQHqAR801lSeEVw0CVCHyhcO/MmDP3NO0gV9mKS5hGASWxSq4yE2SudpWFXLG1AiJZzcRVgLhV7gF41VKa7uAeFQn0Fw+10gZN6bNpFYNTgvXgyVPRMAmyRAQ+lXoA6vf5ltffUKd9FqrbswidQPf96HVVKegyD+A5r4G9d1GvOiRS3ZOT53opzVPzohyr4MjoonkAV5YB0BSBKc1rYHIAFufdUg8gKngAZpXt26Uggjn4qYfgqkNDj2G5rLRycRVkawB2dq3xAAoN4QF8TU3FYnAiWFkkB34NfvJB2GcMQF4ELj1eyJXEMNfMlBYeKAT38hpAO5R95zExgswDANV4pdddoZ001KSaxBmfC2oiApaLInAvAtfn5LlYhfZ5RQOQDwXtRNoAaA/gRHwtD9z0CPz8Ctzw49pAqrj7WkVw1TZTk14ZwWrg8GD7h+Dv/TXNjoNfsdojFhqypNDUjrmPvZQCqmUUUJiVPVgpZHAbD2ClmdBLJFXRJBINcKu4MosCkj3Vi8CcazeSWeKgBUMBdUpCQSMCAtsDiJqlnerKNABQkUAXVhP+6+dWOLD1nHrR0Ku2BtAL+6+ThXpF0EtUslxRBD611GPLnMNWXTBwqR3kEu7S4zZd4iDr/NfrECYDPIBXfQhe8u6sH0FHcupcnCb2VfyIJCH1uIRUuQwXA1ekAShSQEupAXBKPQDbWldopqvsnAg8JpZbJSvqQWGgbjEMVK3sOmG/B2C0iVAMpoC8MZKt4oIHMKgUdBolZERgoOqOMABxXgMo82Qmhn4gTVu+1U5C0m3STur5SdVAn1dLlonAPieXeoSyQsXJr0pNUtjJc4oGSovB6UgtsMaJl8W2P/F0xIE9fhYqaHkApiBYqyNVo3PH0xrAgMxQLe6mBiBSRsbRkUjpMejtit5mtSLwXDUGez2oirZazLg+jgzpJYqrlnFIhKLD4p6iLMs8gGFNYUJZybXMJFrNl0tJz6k/DwCy5kBPPhNx+z7dwa2mk+dyeQDDDYAp0xDLfg3g1LmY3ds8arqv8Nmm39dQR+lc1qLK9P6OVXnqUgNQ+O52J+HkuaytZ83VFUH1dXNkSDKjgDYeqQdQoIBMElguCihcTQd9TgOglQqlphREWVjpIJQ2VxkVBlrUALr9GoAxAOUUUL8IPAiJm4XBquPNWuzld2r1H9bXzJQWHmoAvIwCaneTqfn/FPqBbFSNB5BAtEpH1qnULF7dQBsup2Y8AFsEVqte6QQlJSS0B7AUE8UqT86nq+vbgyOs89b3U0rVzCWX52A0ACtnotVN1GrRaEGFcswpdBSYoYBMIxHhV3KCrPEUiosNIQTzDYeVZo9Q97XouQ1wAhx6CBLinvEAAhIJz5xRK5xBiWBQTgH1G4Bmaae6Mg0A8rWhrtu2pHQVs/Iv5gEMKaFgCrXF0isVgXctutTdLj3psrQqSjyA1bznYkTguEM3GUABme/W7622E06c66X7rrjqmTIGwJUR8lKmgIQQdwshviuEOCqEeNeQ7X5MCCGFEIf0//uFEG0hxBH989vWtncIIb6h9/khITY+Dc42APakvWRTQDoTlKiZ9hQ1D7Zym1v0LA9ASugVPOA/+YsV7v/X5THhK6UegF4FmWMynKgblISBRnTChGqBOkkNAOOJwIMgDQUU5SmguT4KqN8DqIxDAdkeQCj7opkmRioCq+HTbCeISHkAQdVE1hRWokB1bl5lX9q1gBxfhXoWDTLqflUrguOn4rSQl6cNgBCCwNZqtEd31vQ6NnkOUmZ5AIEOme1J2h2pVotmNZwMMQAWBZToPADXt6KArFpAxnjbi42FusNKK0kbwvfcRvo9HroiaBKlq9WnTioDOSwKqIwCCpMKPtaEG64OoYD6NYAtcy7bt7g8f3/AXFJosuTYYaDRcA9APyeRzNf4kVJycqnHrm0eVbdLKAO1EHTzGsC5s8t852lr/1oElr0unSQY6gEYWvL/+PWTfPzPV5ibU2O/4uV7AjgyIrkIdYBgjCggIYQLfBh4DXAMeFAI8YCU8tuF7eaB+4EvF3bxmJTytpJd/xbwj/T2nwLuBj498RlMACMCR7H6e05PGkYT2DrvgOOAV1MUkPEANM0TxdoAuJkBAKUReJaQ+cj3Q77xWJcLq/lG4pBvWp3CrQIyG8ymP6kQaUXSuCfxHJWF2CnJAzCFvbqUhYGq36UaQAFpJrFe4ZtB2sfVpxTQXCqQVYwHMIgW6/VHAQ1bQY0FLQLbGoDTUyJwtWGFVhro87pm3yLRkz5hs0MD0jyAU+dixEJ/+KgQgttvqPKFr7fTRvUe3VTUzkdrqVXtibPqXu/dZUTLLN7cTKgrrYREKrEynQxHicD6PppaQE6gyoYLoe9XRU12WRnvbAwuNFyWmwlRzxrLxgCIiDhRYYlRagDUzRyUBwADPIAkYKFIAZV6ANbip7AG/KV/uF09J58/mQ+vTpsj6ZyJoSKwfkYLFNBKK6HTleze5uIkXSIqSgt08h5A3F7lTNPK7tetX5OwTSgb+VLQBdx8XYW3/W9b02zgl80twleg4hQMACGUeO6bgXGWXy8GjkopH5dShqjm7m8o2e5XgF8H+v25AoQQVwMLUsovSbUU/0/AG8c/7OmQ1osnLwSfX1EVE9NJTrt55kEzDaejGGpOi0RPkmWlIiCrAV5swQeKAgp8kXoXQDYpmknH4spzyWhugNSZwNUBFFCZBpBmfo5hAFy/oh4WPcGXNQQHSkXgCpNqAMnaNYBgDuIOjYr6zmY7we016VLPR9akx63O69YXbCeSPsdP6EiYJEI6KvLFDWqlvPSrX1TnzPkeD35bTbyuDLP7ZLfDdCvQCzl5Vt3/3Vo/sEt8pG05tfdZr4hMEB0lAvsFDyDQXogJGHAzCqgaiNzqfb5hPAB08cC5dNLzhRKCRRLieGpSPXZqiAcwRAPoJhVlINPrPkQEhtIyDbdeX1XeU7HPtqGAzBgcJgLrFXqY+DkR+JSOcNq9zYNelx5VdS8KFJCbNGnGjXQOwG9AEiO7y0RJdWgQg+8JfuxVC/zUPVv4qXu2cPAa/Zx4WUXQJJF4qLF3MTCOAdgLPGX9f0y/lkII8ULgGinlJ0s+f0AI8TUhxF8IIe6y9nls2D6tfd8nhDgshDh8+vTpsk3GRtNqVmLrAKoMhLVS126eaZ2YegCRzFXcNJRKVDAAJv272IEJdK2SIp3iFsRKK1wyV47C8ZG9ECnpo4BMkboua9MAXBc6sp4+XGEsVdOyYiJwCQVk4soH1gMqZIOuDwWkvrvhq0m52e7hyybSm0O4JRqAPq+dO7YgHJ+nT+pY+iSiJz06oVRZuSW89Et/oEatIvjUF3THNpl5NDmtRr92+qzazugHdklkYwBMQIKigAoawCAR2CSCWRQQqLFiZwKXjbX5usPyqvEA2iRePeXWPRESxxIhI1y/wkLDST2AQbWAoLwxfCcJCgZgkAhcItQX0WcA9GQZtbLrMgDGS1EGIFYeA1kS2C7dfztxAtUTpNBT2ZdNOrKW6ilpw5fuWUIZDPUA+mA0AOMBhAlhrAyA3X9hM7FmEVgI4QDvB95R8vYzwLVSytuBfwJ8VAixMMn+pZS/I6U8JKU8tHPnztEfGILVTpI+jHYk0NKyrgNkEJQ3hg81BZToQZBSQAXKI/MA+lc1KjW/aACKhcCycMk+D0DXDu+jgOJVukmFXtJ/SycxAJ4raCeNdII3hcD6JJoSEdiTE4aBrgsFpL67LpoIAe1mE4FUrTG9ksnFUFfBHF5Qod3q8MTTISQxYU+NDb9SK52QqoHDy2+t8d3vm9Vhdj4Vv6ABAEvnWszXnYwnthL8jGHPeQCmJMgoEdgwSmGHnnTwfTV5pMX4HKMB9GdwLzRsDUAZStsDiBPFSQsvYNc2dzwPoEAB9RKpPAAjpCc9NbbLKKD0Hg0gDqKm+rGLLJrJUof0DheBtQfQs3IHyJLAdm1TkVeJU/AAkpB2J6EqWrSTRkqnmfHmdJf6S0GPgt534GThtWEkVZOYIUZsIzHO0R8HrrH+36dfM5gHbgY+L4R4ErgTeEAIcUhK2ZVSngWQUn4VeAy4QX9+35B9bgiabck+zccWKaC8BzCXtYW0ShxHWjjDK2gARQpIewDFJtwwoLBa8SGwKaBCkS/TVLpIARneO84HOKnd9cYXgX0XOrKWNwAlD3+ZB2ByEQYbgLwGsC4UkP5uJ25Srwgi0/A9mCufXKzjrtQq+E7EZ7/SgiSiqyeJar1eSgEBvPrF2STmJJlHk8/X0AbgfDMtJQ3kEvyCggeQagBxd7QIbCigSLVJNDH6aWSRoYCa/WW85+uqgmero8ay9DINwCUmjiWuDHHcIO2EBuUGwHOVh1wsCBfFkkgGuMYDsBcLRRQXP0UUi7FBlgg2AQXU7eXDO08txfieDv2OO0i3aAAiTp7tEIiQdlK3DIC6/4JEdwOb3AMILA0gjCSuiBBldZI2AeMYgAeB64UQB4QQAfBm4AHzppTygpRyh5Ryv5RyP/Al4F4p5WEhxE4tIiOEOAhcDzwupXwGWBZC3Kmjf34a+JP1PbV+NNsJe3b6CFFCAS30U0CQf7CjSK0IZJ8HUE4BPflM1Fcoq7S0cpkG4OUNQFrjRQ/gMgqonTRKC7GFMVokHIcCErR7jYwCGmQA7DwAHTnlJZnRKEVRA1ivKCBIC8JFHU3PBHPlk4s1GblewK6FhD8/3EQmcZqqX62V1xACeOHzqqm3KJJuzlBn0Vrqe8+fb2f8P+QS/IoaQM3WAMYUgZNIZaOa+1MxOoTjA5JmK+oba+b/c8s9qqKVli0A1QQniiUuEY4fsHsxeyZKxwDKKypGAUWxCgP1pL6GUSGT10Zx7BfR1MXYbBHYLVBAw0RgvcBIDYC+tqfO9di9zVPPhPZMm22Zit/0Qs6eVvkHHVnPKCCLxlL9gCcYv/o4fW0AwlBVBfVFNPQcNhIjj15KGQNvB/4H8B3gD6WU3xJCvFcIce+Ij78C+LoQ4gjwR8A/llLqtD5+Dvj3wFGUZ7ChEUBSSpptRb8sNJy0B3AvkVxYTfIUkF9OAcXdFo6QGec9RAQ2DbOfOZvnh0yDjhxcqxIk5DSAXDkKK529SJ040SodWaNX4gH0NaAZAs8VtGUdGY7yAJoqWsrRzcO9Om6Sp4B6ieRXPnKGh580FS6j9LyiWNWpWTMFlFZvXWWu5hC3lQfgVOcyY1OSB4BfBzfgqsWEk+d6HD/R5vun1LkGtfLYdFAG8pV31AGJY1FAQQkFtHyhmfH/9nHkNABtAHJhoMNFYNcRuA7IWHsAel9BYHkAQLvV7aeA9NhbuhBRc9o5CsgTEb1EdQdz/SBNfjPnVwbVFCY//sNIEsoKTppMZQUMFDFKA2iVeQCO+hnDA3BdJYI/dFQ97+/8wDF+9l8+w5e/1c7uTdzB0fkpy22j14QsnV0GKFBAmRELZZAamLFgUW2QeQCeUJTbxcBYxeCklJ9ChWrar71nwLavtP7+OPDxAdsdRlFHm4JupIqaNWoOi/NuuvJ65kxMIkkbZQM5D6BiiXu9bn4lYxJyyiigFxyscOSRLo8fj1TRMo2VUg2gMFH1ugM8AB9hPIACBSR6rYEeQBSNbwB8V/XSleF5BIMrQfZnSDZwdb9kc73OXejxucMtej3JP/8H+uHX51XW1nIqpJnbygPoddWk4NcGaABRU3kswgHHZ3u9x996SYPK2ZiaH/CTdy8gvHINwODHf2RBCcDHyHkAF5p5AxCHndwkmivy5xQoIJMINkYmMOixF7dV1rLlAdgGoNXq5EJAARZ0WPLyBWUoRdBIV9S+iAjDGEdIXL+SNwADxs/2LS4nCoscZQCq6hpBPmS4iFEaQKtQjdPA8bKS5SP48ze/Zp75x6sQwY75Hr6jcgzufulc+t1uoBIDl9su2wF6IefPaQNQIgJDSUP4UXD7DUAUg0+EuEgi8BVTDdQ0C2lUBYsLTmoATKhmri3hABHYTC5C1wbJooCyj5rU+ZsOVPhfj3Z54umIu3QWRDdMCCM5mAKyNYBAaeVFEdgYgGL4mdAlkMs0gEk8ADcVgY+l31tWBqAvrC+Yw+m1cJ3MAzBht1/8RpvmqqPik4wBKGlsPxWsBj6NmiBcWoEqBLX5wRqA1bbPlRHv+vvb4T9Idl41xw/cswW+WNVlBuLSPq1Xbff4uTc24N+SZjbnw0C1URBhVgMI8kX+3IIIXJYHMEAEBj0uet2cB1DxBRdWEyuWPSrVAABWLyxn18/yAFotdYxeEKT1j8z5leHgXp+/OtJOq6RCpgE4MlICcEq7DcgDsK9NEUYDqBUCQBzfooCGG4B/8Pqt8O0d8Gn4xbcuwOKu/Aa9rgr9RReEA0hClvU1CukXgUH3A55CA7AbwysPIEw9kM3GFVMKwmQBN2qqw5Ip//D48RAhCk1J/EYmAlsaQNLV9EKlPxHMwAjAi/MOe3Z4uUig5ZLEHGBAHkCBAkoNgBaBCytnocsflHoAE1FAWgQ2eQCRzOcspDvt9wAIV3PVS43RjWL4ytd1zXd9Xu2SvsZTwerf0Kg5tFfUPQoa8wM0AOu4rQnVFIOzj3FoaKJF54CqlZMlgul7J7oFD8DSALQHZ6qL1sYtBWHCEz2B0BUpjYEOCh6AL/o1AON9tlZsDyDLBF5dVmGxnh+wezE79rJEMFB9jpebCWcvZCsPQwGl5xwN8QDKaDobrZOqGmdxhex4WRTQOBE0aZXP/sg84k5aN+p8y1BAEavGS6rMpQmc9piPCQZel1IUPQCtAXgivmgU0BVjAFYtA7A476bcq6JovPxK1GgAUuY8AKk9AEevIMs0ANMBqF51OLAn39x6YGXNPg0gH14ImQgsSHDo9dfQiVTyU5kHEMYDVvEl8DztAcSWCFz22bAQ161r8tgG0zR8cR344pHz+lzXmQKyOrg1qk7a6Lw6N1/OL9uei90lKrGEuNQgDzEAFp0D5RpAILpjaQAVX6iS2F6hFMQAEdh8n5PkNYCq0QCcLK6/LA8AoL2iJmVRmcutTFdW1Tn7lQpb553Uyx3kAVy3N9+9C9SCo9wADAsDHXCtmyfKmyw5fuZZjCOguplX1Ie4g6/7MZwzBiAJ6awqD8CrNNISLrkx71bHCqzIHTOq+JsjlAEIwx6eiHH9mQHYUBgPYK7msG1etWrrhglPPB3l6R/QE4SEuJ0LAzXCqNCN4035B1sDMEkxtarDwb0+T5+O0yzCgZU13QJVYYVL9onAqAe1GAVEtEpX1rO+rvZb8Xg5AOacOrKOiFZByuEicNED0CW0Mw9Ane/Lbq3x6BOactDnlV6ndaWAHBWmC9Tn5vs9K8jaWEJuRZ2je0bx0vY+3cF5AFW3q9puGlhF/oxX1erIjEYwNYhGiMCgxoUru30icFjwAIp6U70qcBwIdbisY3kAvohYTQ1AgOMIdmovYJABOGAMgBXyHEaKAkqv0zAReBwNoKzJkk0BjeMBuEM8gF4HL6hRrQjONdX5JnGXbks9725tPl285cZ8WX+DMY5BJFEq2EehOh5n5gFsLDIKSKgm28AzZ3s8fSbm4N7CxS+UhO6mBkA9NG5lsAicegAVwcG9qqLi904okSClgAblAZSVgrB7vZowMhH2icDKA2gMMACTUUDtpI6QPeiFhPGAh7+0SuJqLiPWdGC79xXzWVaoawzAOlFAXg0QWgQWKrQRqM9bFFCxFlDqAVjlAWwPYBQtARadk1F1WR6Aem37XJyVgYbMo7DCQCErG9wXBlqqAWgR2FMeRlED6Jp+AIAr4j4PQAjBQt0hbOvJrTKX8xiaTXXOQaDOwXgwgwzAQkMJqk9YVGeY8wA6w0XgURpA62S/AAzKWI8RBZRtnw8DzUF73IvzLudW1Hm2mt20tIlfncs8ANP0HVWGeyJYdYaMYB931ZhwZwZgY7GaisBOGvP/te92kJJ8uV7IN4a3V3Z6xeFViyJwvwZgKCCAx/TDUVoJFEoygYeEgQJVN8pP6FJCuEqXxppFYBUGmhnAMEyGeAB5EbjPA9DG8KYDAdddpQ9MT5jrRgEJkUZt2R5AY2Feh6h6/RqAJQKXUkBlhqOIogbgC10mWqav7Zgr0A297DOmeBtkseqmhlC679IooEwE9kVIVDQAJl8E8An7xxpq/JnCfU51Phee2GyqCSmoqmuwe5un6iMO6dp23V4/7wHYBiDujhCBR1FAQzyAMTKBs+8plHm2oTW3xXmHMytqbmg2O9SEOu5KYz4TgSEdP8KfULi1ylgbjzEKtQGYUUAbi5QCqjtpzP9DD6sH7WDRANiN4e0qj5rLdKt5DcCOArJXtnt2elR8wROaHy1tBwn9PGg8QAPQg3iuWpjldXvGSPSLwHFP8uQzETsXC8LzAHiuoJPU0vMd7gH0i8BFCsh11Dn8wAG1j57QBsBQQGvtCGZ991zNoSaahEmFLfP6gSqWdh4kApdRQJNoAPZY0K9taxQMgFUMzhRvA8sDMJOh9jT7IpAsgxV4QnkASSXdjzFCpr9s4EZ91WhBjT/jKbnVTANwiWnrKKCKNgB33lzj5beW99s1OLDH5/snojTjPIokYWIZ0WgVENpbK2BYIljUUp9dDwpokAhsSnS7Va7Z7fPdp9S4bDa7VB0liFcb81kYKKSVAEwNprEhRHoPTd2mOIr0KcyigDYUzU6CI9TEbCigI490qAaCq3cUHjQru9SOahFaGPVqxgMoE4EzD8B1BPuv9tOicMvNHr7XH8Of0wCkzGkAxssIrZXd9vlC8S2TtVviARz+TocLq4lOXhoNRQFlsfWmFlAfomaJCNxUBtMyAI2ao2iHqnrwWrFOUtKGsu9aTAPtfTRqDlWnRVvWM8+i2G1tEhF4qAeQlXYG0o5cYSSJtZFbrA3yAPKF/ur2sQJEK+pYigKj4+uEup5KWNMUkNmP0RXiRA2aPYvl3tt8PfOUXEsE9kVIu6XOq6q7vP/QC+v88380vAbXgb0BUQzHTukm8jFE2BqANrplgukwbyvNASgzAB5IPdjXIgJbkVk/fEed1bZqH9lpd1WtJOFQb9TodGXGBOhx7wTDDWMptJBvvDXT13nmAWwwmu2EelUVNTPCXLMj2W+36zOwhEU7qkVoD8CvDi4FkUUBqfcO7PXTUNDllqoD1Bc54FoPi6lYqI2CELoiqeUBbG8Uqs+Zuj2iPxHszx5sMl93ePFN4w1Wz1MisNrharkIrCmnMhG46ss+AwAwH6hrsBqpc1g3CghS/WFOU0BdGtk1NgXWDMpEYJnouvLa2o6lAZR7AN1IcnZV7WdLnwHo6gS0vLBatzUAUB5A2arW4pB9T+ALFQZqxqHxFk05g307yktyLDRcao5JmMtHARkDEFTGn5CySCB1j8M+D6BZLgDDcA/AlIEY5AEYrEUEtno03PH8KlvnHGLp0Wl3WQjaCH+Oee1FpTqAHj9uMKEHYI4jCVNPOYnU8XgzA7CxaLZlOhkFvqChJ+g++gfyFJBuyNLrSRxdcdMP1IAwJZJLo4A0tXFwr8/SSsK55Z6uzlhCxQihJ6pu3yrRHG9ohfctzhWW+cYDEPVcKYh2J+EL/6vND72wPpkGkCgDIMMVlQdQNACacuoTgZHUvU4mAreTtFNX3VcDvdnVBqCbIMTg+PKJkGoAgppoEtk9EWwPQCaKNy6KwEmc/Q9TawCgJr+Ty2qCn6+E/Z9xq1kDHd9QQJaxAugul09qVqEy4wHEooLrZBQQwHJHncfebeUGIEcBBXUruCBKo1ImKU52zW4fxyGlOvvCQAd1AwP93aJcA2gOyAKGfF7AWkRgi5YzZT66PZ/V1Q6L1Tb4jTRoI8sF0AvAyhQGwLEooEgSaw9glgi2wVi1VqNASgP1RQBBtlqJm2mkTxhJnF6LtsxWl2Z1nk8Ek7hORt0c1O0An3haNenuiwAyMBOVFSlioMpRkA70rbWCAdBRFrGYy3kAf/ONNp1Q8iMvGo/+AfAcUhE47mTZ0DmUVXfU16zhtdMmMs2OZE6vbhueFsK7GQVUDUrKTE8DTT81qg5Vp53vi2xrAIYzLnoAJhJojXkAoMbJqSVBTzrlBqBwX4GspHCqASyXC5tu3gMIRDfVVOz9fU/Pm1dv66/TDyoKrea06CQ1hOvlPABPDIhAGoLAF1y7OxOCc4lgJgy0TAAGZQyLNJ1BWR2g9HMWbbsWEbiXN+SvfnGDSAacv9BlS9CGYC7V7Iq5AF5lCgpIR3KZiK1eNPn1Xk9cMQagWTAAJhKoLwIIch5AKsLGUnWakvnJNPBEngLqJtSrGc1z0HKPl8sqgRqkdWDyAxIyD8C49lvrRQ9AGYDIySeCffYrqhjZLdeNv7rwvEwE7unM534DUJLYYxqzeK3UA2i2smte0wZguZtRQOtC/5jv1pnANdFMezarE7IKu5njtqOAktDyAAoU0AQagD1OTi31CGWFhl+iAdiendEAjAcwigKyaIzAg4rTJXEsg6L3d/SE+n3VYrkBMB5ASvWZUhBEaZbqpBOSTXWaUhCApQEM8ACgn6YzSA3Arv73JvYABhiAOG/Ib9wfkDg+vgiZ95W3aDL3TRBH2hCqOqUB6PVTQDMDsMFotpOU9gHSSKC+JDDIicB2HL5pNZjb1BP5KKCOzNUI3zrvsrjgZB7AIAOQegBmQFoThRZWVzqGWy5qAGpFHossD+D8So8Hv9PhVYfq/RrHENgicM94AGAcBb8AACAASURBVEX6qCyxxzRmcdupR7TaSdJm8jVPTZgX9Dl0usn6RACZ44ia1CqCqtWyEyCtsGkfty0CJ3F/+WXPWr0OQq+cAvqrIy2+9kiXmCBriJJ+plvqAaTXwbM9gJJxadEYpq1g4uSpQoCjx9T131ocJxoLDe0BmHBfbfh8J1LdqWC8VbWFg3tUO81mW3W5irAi2wb1AzYY5AE0T0J1W38ZCOuY1d8TiMDJABFYG2YhBEGlgici6m5LUUD6mTWRQLFeYFSq01BAeRE4iQcU/tskXFEGYM6iXw7s8dl/tV8aJmcngplEmmfOxnhJvwfg22GiqCigYpegg3sCHj9e3qIvRaoB5BOmIEsyWu6qY10oUkB6ZRu7mQfw9aNdkgTuum18+geyTGCAXkd7AMVInXCwB1B3m3kRWBvDwFED/UJbPayGAloXWC085/0WQc0yTPbkUjzuVHw34YSFRLBxagHpSXvHVnVvfv/Ty3z1YdVhqm9VW+iHkFJARQ1glAfQC6m56tiSEgrocb1wFsXJTmO+7lATLbroFawOTwycKC1UNmmLwuuvUcf2jce6hJFEumOKwNAfqmvQOlHO/8P6icCF+whQqwVUnIg5T3kA5pk1HkDkqOcjqE0vAlcCR0UBGQMwqwa6sWh2ZI4C+unXbeEtr91SvrHjqgFx6ggvuf5PeeXCOb7/1xVeGh/jhMiHxPm+KIjAsq9C4MG9Pn/8FytEcUkSmIFXhQtPwJN/mv2vYdzFlbYWF6t6ZXfya7D8PTj+BQBiJ9MATN5DrtHNGLBFYPf0V3lZfYE95+fhUWuwn/m6Pvl+D+BA9/Pc4X+f5JEd3O6c4cZeHR5t4Jz+XwAsaQNQ1th+avhzatX86B+zu3YBrtmavedWlagK/Z5LsbesKOQBnHiwUIdewL5XQHWxTwM4sCfg47++N22PuPCJkq5ihZ7IaRhoXx7A8oDQx2wVW9OJWYnbTwF14sJq9+zDcO7hdLs95yNa/lP5/tGOT8U2ABOuSG+7ocpcTfDnh1XUmTTUVNwZLgLDcA+gjP/XxwvoqKoxxvggEbiEcvUrFV52s4u7rERgUz7DGICQBg2gUp1scaWOw6KAQok0VOJF8gCuCAMgpWS1naSCJIDjCIaWoWnsgaOfoHL0E7xnJ6Db2DxSaGHgFzWATtLXJejAHj+liQZ6APXd8L3/CSe+ov/PeE9TXuGCblYxX+kp6uJjP5grMRyyJY0CyvIRJptkPVdVOQy9bTSe/AN+5eo/gG+jfopoXJ39PbcHgDuW3scdu4D/Bu+9CniatH/cSrKV5VbWSHzdKKC5PerBfuBNCIC5vdYJWSvx0CqBDNmqMC0poCcJ0+bym/9B/dh44f3wwx/oC+kEVFvReft7x6WAChpA3B4pAlcddaOlm/HQxTDQdLL7xI/ChcfT7fYCVODB6HW5fQfO9BpA4At+6IV1/uxwi5f/QA3hjSkCw3ANYPeh8s+kes2YxzlIBDbG305ScwJc4rTgoSmfYSigVuVanN5WgtoUBsASgTuhRMbTXe/1wlgGQAhxN/BBwAX+vZTyfQO2+zFU568X6ZaQrwHeBwRACLxTSvnnetvPA1cDbf3xvyWlPLWGcxmITihJdDOYsfGWL8Oqqol/5NE2H/4v56lWBMmWG/hBazPfK+QBdCU7thY9gOzmDvQA7v04nH9M77QBi9enbwW6zrspVTtXiaB1Wj1cL/lncMOPQ20nye/69KIkPQ5gspZ1oKpSAn9164Ps33KG9/3eWX7+7y5yy3UFd7eyBbYcyP7fehD+98f5088f5+OfW+G9P7uD9/y/Z/jp121Jaahf+Y8uQj9Ena5kcWGdPIDbfx6ufbVODBKw4wXWCVkaQDGqpGgA0jDQAP7ho9n2Bv/tx2H5++rvAp3TB/t7DQo9kYM+D8AS60eIwPO6lEPH3ZG+bTyA2DYAMoGV78PNPwO3vx1Qi4P7338Sd/sNvMh82AnwnTjTAKaYkF79ogaf/EKTL36jzUK9UA10lAdQSgGdLPeEILtX466cB3kAZUKziQ6zjnu+4aS1vJ6+6u/z3u+/gn9Zn2LSNpnAdUEvwaKALlEDoHv6fhh4DaoH0oNCiAeklN8ubDcP3A982Xr5DPC3pZRPCyFuRrWVtJZnvFV3BttQ2IXgxkZ9h/oBXrBNcvqPj7O8knDj9vyNCvpE4H4P4DlXeTgCEkl5HgBAMA+7bit/S4vAplmFL+Js4O6+I/2c555KNYB2J8H3htdwKYPJF2g6O1mu7+Gx8BS97btg1xh855YDtBZ28Fi4xClvl/rsjh2wSxkA0TiVPkTtUPaXtJ4Wjgs7byl/z+aXm4XMUjN5pDVlrMdh7mr1Y2Ph2uy6F0I6++AN0ACq29J/Mw2gIALDSBG4IU8D0PayicvsL8aa7DpLylvceUs6TqqJ5InoKQ56eR7dXwMFBHDLcyvs3Opy+nyPbVv8rGBb3B7hAZRQQFFbaSGjKKBxe+kKkS/+Z1AcE5BFh1mey3zdYUXnAbS6Ds1ky3SFDB0/zS8CiLpdqHBJi8AvBo5KKR+XUobAx4A3lGz3K8CvA+mdlFJ+TUr5tP73W0BNCLHpGQ9pIbhJPAALvif4odvr6d/F94oicHFgVAKHvbs0fz+IAhoCU45iqak/2wtLsyRdR6T1WFSZ4cm/yyS3xb2sxMWgSpBlMNsuLauHxY68Wmg4aSz1ukYBDYPNL7dOKle/jwIa3VwcUNfaXPcCnVP6vX0UUEEDMHX802Jw1v5GiMCNRDnLXS9PFQJs3aL3k4SlsfSOI5irO/j24sANCIRNAU0uSjqO4FWHrOfErUBHc6fDROAyYzksBwAmp4DMtmUegD0mIOs10Oumry80LAqom5V7mRhGBDYGILy4IvA4Z7AXeMr6/xj5VTxCiBcC10gpPzlkPz8GPCRlLjbuPwohjgghflkMyAgSQtwnhDgshDh8+vTpMQ63H3Y3sGnxqhcNNgCGApJS0uqWT7yGBhpIAQ2B8QDOrWbNKsoeENeFng79bnWTyRpWp/vQRduSrKTDoH6w5ceqfp9bzvovGMzXHZZXlWFor2cewDDY/LKpLW+GmpnwyzyAMtR3Z9e9MJn3f2/Jqjbu9on7UFILCIaXgkgiaj31LESVLCjBUEAH9laVPpFEA8spLDQcPPu+Oj6+E67JAwCVSAX63NwqtM+oN0blARSvlTnuUVFAkxgAx++PAiqOCbPPrm5gpD2AhYabisDtQrmXiWAygfW974UXVwRe8xJMCOEA7wfeMWSbF6C8g5+1Xn6rlPIW4C7981Nln5VS/o6U8pCU8tDOncOLUg2C3QxmWtxyXYWrtrt9K/iK1Qs2jJTWUDbx3nBtgOfClrkpDIAWgU2NGXpRqevquiLNA1D5CJN/l2+Vt0gNwARUTaCV9dQDsK7XQsNhtS3p9STd9YwCGgbbA2ie7Hf1YfzOUvXdatuoOZ4GUFzVFjSALXMuvkcWnmwblBEicK13mpXeQq4iZeAJqoHghmuDbLVbRnGgwlZzz4Mb4E+ZCWzj4F6fg3t89Zx4VeicVW+MooCK3tKwQnBgheyu0QNolvQbcAJFnUHqucxb3uvZCz2EWIsHEKXGemDzn03COCLwceAa6/99+jWDeeBm4PN6EX8V8IAQ4l4tBO8DPgH8tJTyMfMhKeVx/XtFCPFRFNX0n9ZyMoOwHh6A4wj+1f27+9ojbtvi8o3H1OA1wmvZxPt3XjnHoRurU9EeJg/g7KoDdTIPoOC6eg6pATAZyZPCaAa9HmvyAEyzczvyyhjPMxd6SLlOpaBHwa2qh0wmKq58y0HrvQkNgJmMmifH0wBKw0Czz9zzgw1+4LmVrB3pKA/AEoGr0UnO9Xbm6DnHEfzbd+7m6u0e/Ds92Q2gUt7109sR9uV3AjwR4xMhcRDjhFaWQAjB//1zO5EAn6hC2xiACcNAR1FAJmR3kpWzM4ACsscEqOtsDIChgOqqi2Dck/zVkRa3Prcydn2tvn1bHoA3ZdTVemGcJ/BB4HohxAEhRAC8mTSwD6SUF6SUO6SU+6WU+4EvAWby3wp8EniXlPIL5jNCCE8IsUP/7QOvB765bmdVgGlMMpEIXII9Ozx2bM1bgN2LLsvNhHYnGRp6WQmcNFlmUgS+qh1u2tWlD3bBdXVdkYrArY6cigJyHLXLuGd5AFNoAOeMB2BdcyOAn15S720KBWTX9Smu9szkEU1AAYG69r3ucApoUBio9Zlq4HDdPmtMOB4IPfGOygSOTrFUMACgqMZa1UkzTmmdVPutLua227XNY6c9llMPIEaucTLatc1j9zZPawDjeAAl3pLxXMrKQEDmAYwrAkO6+s5/z4l+L8MNAK3rGRFYU7eHv9Ph2KmYH3nxkPMZBpMJrD0Af40e11ox0gBIKWPg7agInu8Afyil/JYQ4r1CiHtHfPztwHOB92iu/4gQYhdK9/4fQoivA0dQHsW/W8uJDINpCD83jcs2Aru3q4fo1FIv5QbXe2Ub+AIpIUosA9Dsz5L0XJEmgrU7yVQTrBACz4VozSJwgufmP2sK4Z1aUmFTm0IBmQk3WlV8dL2EAorHFIHN9W6e6KNz+r+3ZFU76jP28Y4Qgf3wFEu9HYOrqZpIFpNMJUaMSTfAF6GigCaZVIfu0/IARonAZR5AdXHwxDitBmB7AEncPybsfUMWBqrH7h9/fgXfg1fcPkUOgDleXQ4asEpvXMKZwFLKTwGfKrz2ngHbvtL6+1eBXx2w2zvGO8S1o9lOcJyNWXGanqmnlmIrs3N9v8dQMAkuEqFS/FsnYct1ue1ch8wDGCBGjwOjJRgPYJKSzWbbpZVe2gzGYEHrH6fOqYPctCgggNXjgMw/7GkmcCERbBBsD6AQ0tmH4qpWytG6gTneuDVSBPbDUyzFLxtsnM1qt3V6MI2S27ePJ1bwRYRYr9WoV81W3ENF4BJvqXli+HFPGwVki8DtM/SNieI+UxFYjdWvfLvDy26tTRXNB/SJwJnofulGAV32UDVpShqxrAN2bVMD8eS5ntUMZn0vayoYIZCGxywKmuiJ2/IApqGAAHxXhZN2I6mq9U5ABwcFA2BjvugBbEoUkJ5wl7+nfpeKwIVSEINg6IjmycnDQM3Kc1Tdd7PPYSJwuIwbXWCpt2OwPmMEz2HJVIXt02qg62kADMYpBiet/gWG4hyEaTyAogg8qN+Afe2DLAzU4NUvmpL+McdgicCeiOmJku5vm4QrwgDYjUnWGzu2uDgOnDwX0+6YZjAb4wEAagDFrVLX1XWUeCulpN2dLgoIdDmImLQd5CSG0+6N2yh4QuYhOmU0gM2kgIwBKKOAxvUAXF+t+o0HME4YqJnUSor8DfycfWy59/RrKypDfam3Y7AHkC4URqykre1dEVHz19EDsK/P0GJwFUDm+flWSXSODWdKEbj4HTDCAzBRQGoV1KgKXnrLFGWg7X33MgrIFyFSXBz+H64QA2B3A1tvuK5gx1aXU+fiqcsvjIL9kAs3KKczyDSATihJ5PTH4WoPoLQd5ATHWrzmJuzw1DnlAWwqBbT8pD6oEhE4HtMDgCwXYBSfb1b6ZsVZKB43EGbSHCYCr6hyFOd6uyzvsGTbXhdap8YzANoDqLi99fMA3Ak8AMh7TMMKwcHkmcDQ7wEMCjUdQgHddXt94mciB52NXDF1B4lILqIBuCKKwb30llraqnEjsHvR49RSL9cQfj2RrhY81CpUrwD7RWClAaSJKlNTQCoKSMSTCcD2sUJ/3oXrCho1kXkAmxkFZGr4lHoAhXLQw9C4Sq2qR+YBWE1lPCvRaRwNwD623D7zHsA9rz7IbYPESDdQk38SDV9JW9tvqcXcuBOI14mPTo2dyBdb6/tuq3JoMK/LQAyoiGowrQhsvD0Y3HO4RASeqzm8463beNGNU5SAtqGPt+KpZ8ATEXJU9NkG4oowAK9/+RD3cx2wa5vLtx/v0u6ubeIdBDOpLs67CCeAFZ2YXaSAXBUttGqoqDV5AIpKWk8PAFQk0DNntQi8KRSQpQF4VTXBGBRF4HFWk/XdcPLB8TQAyFa1JY1+hh5v2cQmXECk9/+uHzwAA/tLBFlxwTFFYF9EbJvrwfI6ewB+Y3gUUrEx/KgcAJheBO4uZf83T/aPidw+Re4e/+jL1mEe0V5nxVFUlC9CpetdJFwRFNBGY/c25QE02wmBL9JyCusF2wDgBlaafIEC0ndzVWcsTmuIPEMBxetvAOxieJuTCGZpAGUp/zB+KQhQ17x5crxSEJBNauNqAMZAlE0KunFLtnIdECMPQ8fJwO17ofpZNxFYn8sw+gey69ibxACsgwjcOgn1q/oFWHPtg7n1F2f18fpOpAIsRDwzAJc7di269BI4dipe99U/ZMLq4oKTT1IpPCCONjym4ua0VJTn6WJwkezLfB4F1xFp1NBcifBuR1NsKgXULgmHnDQTGHQ5iNXRFFCxreTYGsAQDyB9Xapy3MP25QweJwO3TyL1s94awDABGPq9pQHlK3KYtBy02bZPaC75DnP+w0JXp4Xet0giAk+oMNCZAbi8YUJBn3wmmpp2GYa0yuO8mw2WEtfVTLzGA6hNmY/gWSJwZWjXnOHHW+4BOOmxTlqqeirYk+QgAzBuIlhxH6MSwaCfAhpXAxh0LOb1UZO6/fkxReD19wAsCmjodw+igMaJAlqjCFx2bVIDsIZwz0Gws7kDgc86GtxpDueiffOzCLu3qZn3xNl43ZPAIEuuUhSQmQD6XVfXKXgAU1IsnpUHMKkHAJnH0igxhiYbeFPoH8hPuIPivcctBVHcx6hSEJCt/AvNxwdiLA+A0cKu2c7xoDYkYc3ePgnVz7plAhsKaEwPoM8ADKO41iETeFCkkTn/DfQATEnodc28ngIzA7AO2LWoJg4pp590hyHVABacbNIqcV2NB2CqFk5rjEw00TRhoPbxDvMANiUHAPITbvGamQl/EgqoMaEHYCa1kubjpfCGlIKA7P6PWtWbz9d3jS4DATo8MVbHuV6UhDuuB1DQAJonoLJ1uGA+rQZgMoGTnqIFh1JAG+EBZOU8KoGigNYt72Kaw7lo3/wsQqPmpHz3tLTLMOxadHntnQ3uvLlmPdj9A9d4ACuttUUBea4gjiXhFGGgkH1mriRCxWQDbwr/D8MpoGKXqHHCQHNhpCPKQcP0GsCgSXjI/Z9qu+L2g8pQTIOUAppQAxiVBQxrbwjTPqMqxJbRTLYIvN5IPYCIwBd4IkZ4MwNw2cPoABvhAbiu4Bd/ejv7dvlDH+zUA2iaWjtr8QCmSwQDywMoMYZGBN40CmiYAYB8yN84K2WblpgmDHQteQD266Mie8b1FIrbR831NwCjJtKit1RS5qQPaxWBh/Ub2AQR2NQD8kU48wCeDTBF4TZCA8hhCAVkwk9XWgnVQKQewaTwXJH2A1h3Cqh+CVFAkD2Q47bkc4OstPJGagDrJQKPEwIK2XUIV9cxCmgNYaDjegDTisDNIaGmmyUC+wKPaOYBPBtgykJvRBRQDu7gCcA2AGuhojxXEBkPYIqmF6kIXJYIpvMANo0Csmvslwp++uEbpwyEgdnPRmgAw8pB26+PKwJPSgFFq+tbDhomEIEtCmjU+U3dEjJSYt2wXINNEoEDrQE4F6kfMMwMwLph96KhgDbLA+h/QFwrEWwtVNRaRWBTn6asBeemU0CQTTBlk0o6kUzwEJr9bIQGMIoCmlQEHqcMBGTXQSbrJwKPGwZqe0txB7oXxvdwJtUAIN8ruez6bJYI7AtVfntUdvgGYmYA1gm7dCjoxnsAwzQAHQa6Vg/AMyKwnKgXgEHgCXyvXEDe9CggUBO1W4FgoeQ9Ey45gQEYxwMoagDjUkDDykHD+BrAtB5A8e+1YFwR2PaWxskChulFYMjKZJeVgYBNE4FVGGiEc6lTQEKIu4UQ3xVCHBVCvGvIdj8mhJBCiEPWa+/Wn/uuEOK1k+7zcsGuzfIAxhCB1+4BCDqhRMrpo4DKcgDgIkQBgQonLJaBMLDj5ceFufaTaABxBxCjDc24FNDICXJKEXjYd08Kcy4jRWBLAxgnCximE4FtD6CkpWrfdhssAgeBWN/+C1Ng5KgXQrjAh4HXAMeAB4UQD0gpv13Ybh64H/iy9dpNqB7CLwD2AJ8VQtyg3x65z8sJ+/f4XLPbm7rv79gYIu4Z0TeK1yZGuy40dUG5aQzA8/cPvgaeK7j9eRVufM4mDnq3CrXtA96bwgNoTKkBeNXRtWXGEYGDhdFU0rQicPHvtWDsPAD9fZ2l8QvYTUPdmc80T6iS6oO+I9UANlYEfv5zKtROXOIGAHgxcFRK+TiAEOJjwBuA4mT9K8CvA++0XnsD8DEpZRd4QghxVO+PMfd52WCu5vB7/9eejf+iYF6tTEroDNfq3LUWKsp3BYmunj2NCPzjP1JCtVj41/ePOSmtF4IFmNtX/p4zhQEw+yqjD9L9eoCwwkDboydtgIq+doNWzcE8zA84l+J2CGhcPXpbyE9C6yUCm3OpLA7fTgg1pg//q+y1uRHPkpmcJ1mlm8/87k3q93PfWL6dua/VEcc9DSxv5/Uvn4Mj8UXNBB7HAOwFnrL+Pwa8xN5ACPFC4Bop5SeFEO8sfPZLhc/u1X8P3ae17/uA+wCuvfbavvejKOLYsWN0Op2+955NqFar7Nu3D/+OX1ADt2QlaYd9roWKsltABpvJ1W8U7v7dwZN1SiVMQAE97+9CbQcsPGfwNkLkm523z0B1gBdi47p74U2fhK3Xlb//8l+D7vLo/dz0U7Dt+YM9nyLsSWi9RODtL4A3PgAH7h697b3/Fc49rP6eu3q0kdt2A7zpv8Nz/tb4x3P931H3w4SC7h/w2a0H1T14zqvH3/e4MH2k22fV7154UYvBrbkfgBDCAd4P/IM1H00JpJS/A/wOwKFDh2Tx/WPHjjE/P8/+/fs3pOfvpQApJWfPnuXYsWMcOHBgYGSHPXGvpSmNXc56Gg/gksOuWwe/Nw0F5FXg4OvG2K46WWy7OZ5h+95yYLxjrCzAc35kvG3N95b9vRYIAdf97fG23f8a9TMJDv7oZNsH83Drz4657zHu7zSobFHX14jd61l9dQqMM0scB66x/t+nXzOYB24GPi+EeBK4E3hAC8GDPjtqn2Oj0+mwffv2Z+3kDyCEYPv27SO9HHviXktfYt+a9NfU/u5ywDQi8Nj7tjyA5onx+fiLgY0QgWfohxCq/ETrpMpHuAwMwIPA9UKIA0KIACXqPmDelFJekFLukFLul1LuR1E+90opD+vt3iyEqAghDgDXA18Ztc9J8Wye/A3GOcf18gA866NXjgHYAB7WrRTq24wZk38xsBEewAzlaOxWC4K0BtUlTAFJKWMhxNuB/wG4wEeklN8SQrwXOCylHDhx6+3+ECXuxsDbpJQ9gLJ9rv10rmzkNIB1ooCmyQO4rDCNCDwujAbQi6Bz7tL2ADZCBJ6hHPXdqq+z0SIu9XLQUspPSSlvkFJeJ6X8Nf3ae8omfynlK/Xq3/z/a/pzz5NSfnrYPi9HnD9/nt/8zd+c+HOve93rOH/+/LoeSy4KaEYBjYdpROBx4WoNoHVK/T9uTP7FgD0JzTyAjUV9t/IIjQG4xCmgGYZgkAGI43jo5z71qU+xdevWdT2W9fMAsr+fFSLwMExaDG4SeJoCGje79WIi5wHMDMCGorFbLQoMPXg5RwFdSvi3/2WJx46FozecANftC3j7jw+OB37Xu97FY489xm233Ybv+1SrVRYXF3n44Yd55JFHeOMb38hTTz1Fp9Ph/vvv57777gNg//79HD58mNXVVe655x5e/vKX8zd/8zfs3buXP/mTP6FWq018rDkNYE1hoFeQB7ChGoCmgCZpzn6xMBOBNw/13SB72biYeQCXL973vvdx3XXXceTIEX7jN36Dhx56iA9+8IM88sgjAHzkIx/hq1/9KocPH+ZDH/oQZ8+e7dvHo48+ytve9ja+9a1vsXXrVj7+8Y9PdSz2xL22RLDs7yvHAGzAWsiEgaa152ci8Axk42Dl++r3pSwCX04YtlLfLLz4xS9WsfoaH/rQh/jEJz4BwFNPPcWjjz7K9u355JwDBw5w2223AXDHHXfw5JNPTvXdtni7tlIQV5AHsJEicOoBXG4U0EwE3lCYcbCic2Ev8UzgGSZAo5HVD/n85z/PZz/7Wb74xS9Sr9d55StfWRrLX6lkRcVc16Xdbk/13Xb45lqLwRk8+w3ARorAlgbgz4FfX//vWC/MRODNQ2oAjqnfMwro8sX8/DwrKyul7124cIHFxUXq9ToPP/wwX/rSl0q3Wy/kEsHWVA46+/uKEYE3Mgz0Uk8Cg5kIvJloFD2AGQV02WL79u287GUv4+abb6ZWq7F7d/ag33333fz2b/82N954I8973vO48847N/RYTPSOI9ZWb994AEKA/2wfIRttAIwGcCnTPzDzADYTla3qGhsDMNMALm989KMfLX29Uqnw6U9/uvQ9w/Pv2LGDb37zm+nr//Sf/tOpj8NEgdYqYk3Z0cYABN7a9nNZYKNLQRgKaPF567//9YQQWcvEmQHYWAgBtV2XhAg8o4CeRRBC4Llr70pmwkmf9fw/WBrABpWCMCLwpRwBZLCR12KGPBpXqZ4EcOlnAs9w+cB1xJq7kqUewJVgADZcA2hD5+ylTwGBlRQ38wA2HI3dkOhk0ZkHMMN6YeYBTAhng/MADC51ERgsYzgzABsOe0FwEa/3zAA8y+C6Yk05ADDzANZv35YBuBw8AGfmAWwa7PEw8wBmWC+47tpyAMAWgdfjiC5xbGQtILtp/OVgAGYU0OahMTMAM2wAPEesKQcAsjyAK8IDMCt/MaOAZiLwJiJHAc1E4MsW05aDBvjABz5Aq9Va1+O5701bedMPDWlWPgaMB/Cs7wUAG1wN9DKjgGYewObBjgq71D0AIcTdQojvCiGOCiHeVfL+PxZCMfqufwAACctJREFUfEMIcUQI8ddCiJv062/Vr5mfRAhxm37v83qf5r1d63tqm4NLzQD8yIsa3HigMnrDIbiiNADDe2+EB2A0AL8Bwdz673+94QaAAOGO3HSGNeISEYFHjnohhAt8GHgNcAx4UAjxgJTy29ZmH5VS/rbe/l5Uk/i7pZT/GfjP+vVbgD+WUh6xPvdWu3nMmvG5/xNOHRm93STYdRv88AcGvm2Xg37Na17Drl27+MM//EO63S5vetOb+Bf/4l/QbDb5iZ/4CY4dO0av1+OXf/mXOXnyJE8//TQ//MM/zI4dO/jc5z63vse9BlxRUUCboQFcDqt/UBORG6hEpRk2FpeICDzOsufFwFEp5eMAQoiPAW9AtXkEQEq5bG3fAGTJfv4e8LHpD/XSxPve9z6++c1vcuTIET7zmc/wR3/0R3zlK19BSsm9997LX/7lX3L69Gn27NnDJz/5SUDVCNqyZQvvf//7+dznPseOHTsu8lnkcUV5ABudBwCXjwFwgxn9s1moLl4SmdfjGIC9wFPW/8eAlxQ3EkK8DfgnQAC8qmQ/fxdlOGz8RyFED/g48KtSyj7DIYS4D7gP4Nprrx1+pENW6puBz3zmM3zmM5/h9ttvB2B1dZVHH32Uu+66i3e84x384i/+Iq9//eu56667LupxjsIV5QFsdEtIuDwEYFDXYiYAbw6EgPoulQ38bBCBpZQfllJeB/wi8Ev2e0KIlwAtKeU3rZffKqW8BbhL//zUgP3+jpTykJTy0M6dO9frcDcEUkre/e53c+TIEY4cOcLRo0f5mZ/5GW644QYeeughbrnlFn7pl36J9773vRf7UIfC87JaQM96bIYHcDmUgYCZB7DZaFylFh4XkXIbxwAcB66x/t+nXxuEjwFvLLz2ZuAP7BeklMf17xXgoyiq6bKDXQ76ta99LR/5yEdYXV0F4Pjx45w6dYqnn36aer3OT/7kT/LOd76Thx56qO+zlxJcRyDEleIBbGQi2GWmAbjBLAt4M1HffdGv9zh+74PA9UKIA6iJ/83AW+wNhBDXSykf1f/+KPCo9Z4D/ARqlW9e84CtUsozQggfeD3w2bWcyMWCXQ76nnvu4S1veQsvfelLAZibm+P3f//3OXr0KO985ztxHAff9/mt3/otAO677z7uvvtu9uzZc0mJwAD3/GCDO55fHb3h5Y6NbgkJl48BcGYewKaivntjgg8mgCih3fs3EuJ1wAcAF/iIlPLXhBDvBQ5LKR8QQnwQeDUQAUvA26WU39KffSXwPinlndb+GsBfAr7e52eBfyKl7A07jkOHDsnDh/NBQ9/5zne48cYbxzzdyxtX0rluGpIefOGX4Y5fgPo6U4wygb/+JXjhz18eNND3Pwerx+CmUjZ2hvXGM1+Gk1+F235uw79KCPFVKeWhvtfHMQCXCmYG4Mo51xlmmGH9MMgAzDKBZ5hhhhmuUDwrDMDl5MVMiyvhHGeYYYbNxWVvAKrVKmfPnn1WT5BSSs6ePUu1egWIsjPMMMOm4bIv+Ltv3z6OHTvG6dOnL/ahbCiq1Sr79u272IcxwwwzPItw2RsA3/c5cODAxT6MGWaYYYbLDpc9BTTDDDPMMMN0mBmAGWaYYYYrFDMDMMMMM8xwheKySgQTQpwGvjflx3cAZ9bxcC4mZudy6eLZdD6zc7k0Mc25PEdK2ZfqflkZgLVACHG4LBPucsTsXC5dPJvOZ3YulybW81xmFNAMM8wwwxWKmQGYYYYZZrhCcSUZgN+52Aewjpidy6WLZ9P5zM7l0sS6ncsVowHMMMMMM8yQx5XkAcwwwwwzzGBhZgBmmGGGGa5QXBEGQAhxtxDiu0KIo0KId13s45kEQohrhBCfE0J8WwjxLSHE/fr1bUKI/ymEeFT/XrzYxzouhBCuEOJrQoj/rv8/IIT4sr4//58Q4rLoSyiE2CqE+CMhxMNCiO8IIV56ud4XIcQv6PH1TSHEHwghqpfLfRFCfEQIcUoI8U3rtdL7IBQ+pM/p60KIF168Iy/HgPP5DT3Ovi6E+IQQYqv13rv1+XxXCPHaSb7rWW8AhBAu8GHgHuAm4O8JIW66uEc1EWLgHVLKm4A7gbfp438X8GdSyuuBP9P/Xy64H/iO9f+vA/9GSvlcVEvRn7koRzU5Pgj8qZTy+cCtqHO67O6LEGIv8PPAISnlzag2rW/m8rkvvwvcXXht0H24B7he/9wH/NYmHeMk+F36z+d/AjdLKX8AeAR4N4CeC94MvEB/5jf1nDcWnvUGAHgxcFRK+biUMgQ+BrzhIh/T2JBSPiOlfEj/vYKaZPaizuH39Ga/B7zx4hzhZBBC7AN+FPj3+n8BvAr4I73JZXEuQogtwCuA/wAgpQyllOe5TO8LqjJwTQjhAXXgGS6T+yKl/EvgXOHlQffhDcB/kgpfArYKIa7enCMdD2XnI6X8jJQy1v9+CTC14d8AfExK2ZVSPgEcRc15Y+FKMAD/fztn7xpFEIbx3wvqgbEwWgQ0Qk4QW2MV0ELUQkNIZSEEjOg/YCXIVfYidlooFhIsjEEPwcaPOmpAVPzABMVcMCaNEbQJ+FjMHC7qwS0Jbub2/cFxOzPL3vvyLPPePjN324HZTLsR+5LDzPqAfmAS6JH0OQ7NAz0FhZWXS8BZ4GdsbwW+Zm7uVPSpAovA9WhnXTWzLhLURdIccAH4RJj4l4Ap0tSlSSsdOmE+OAXcj8cryqcMBaAjMLNNwG3gjKRv2TGFvbxrfj+vmQ0BC5Kmio5lFVgH7AUuS+oHvvOH3ZOQLt2Eb5JVYBvQxd8WRLKkokM7mFmNYAuPrcb1ylAA5oAdmXZv7EsGM1tPmPzHJE3E7i/NR9f4vlBUfDnYBwyb2UeCFXeQ4KNvjtYDpKNPA2hImoztcUJBSFGXw8AHSYuSloEJglYp6tKklQ7JzgdmdhIYAkb0+wdcK8qnDAXgKbAr7mjYQFgwqRccU9tEj/wa8EbSxcxQHRiNx6PA3f8dW14knZPUK6mPoMMjSSPAY+BYPC2VXOaBWTPbHbsOAa9JUBeC9TNgZhvj/dbMJTldMrTSoQ6ciLuBBoCljFW0ZjGzIwTrdFjSj8xQHThuZhUzqxIWt5+0fWFJHf8CBgkr5zNAreh4csa+n/D4+gJ4Hl+DBO/8IfAeeABsKTrWnHkdAO7F453xpp0GbgGVouNrM4c9wLOozR2gO1VdgPPAW+AVcAOopKILcJOwdrFMeDI73UoHwAi7AmeAl4SdT4Xn0EY+0wSvvzkHXMmcX4v5vAOO5vks/ysIx3GcklIGC8hxHMf5B14AHMdxSooXAMdxnJLiBcBxHKekeAFwHMcpKV4AHMdxSooXAMdxnJLyC4K4iA5k+9BHAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"-_mPLpqzdx1t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613859279386,"user_tz":480,"elapsed":35150,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}},"outputId":"6b39b317-17fe-4352-da9a-83ed0defa151"},"source":["# tload = torch.utils.data.TensorDataset(X_train, X_actual)\n","# tloader = torch.utils.data.DataLoader(tload, batch_size = X_train.shape[0], shuffle = True)\n","# _, _, _, _ = test(CNNPoor, device, tloader)\n","_, _, _, _ = test(CNNPoor, device, test_loader)"],"execution_count":132,"outputs":[{"output_type":"stream","text":["1:  torch.Size([35, 8, 7, 500])\n","torch.Size([35, 8, 7, 500])\n","2:  torch.Size([35, 16, 1, 500])\n","3:  torch.Size([35, 16, 1, 125])\n","\n","Test set: Total loss: 0.712696, Accuracy: 0.485714\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VhKZjhrrqjRi","executionInfo":{"status":"ok","timestamp":1613859279387,"user_tz":480,"elapsed":35144,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}}},"source":["# torch.save(CNNPoor.state_dict(), '/content/drive/Shared drives/NeuroTech ML/my_model.pt')"],"execution_count":133,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHq8V99wHiqC","executionInfo":{"status":"ok","timestamp":1613859279388,"user_tz":480,"elapsed":35141,"user":{"displayName":"Jessalyn Wang","photoUrl":"","userId":"06368548378593206238"}}},"source":["# import pickle\r\n","\r\n","# pickle.dump(CNNPoor, open('model.pkl', 'wb'))\r\n","# # model = pickle.load(open('model.pkl', 'rb'))\r\n"],"execution_count":134,"outputs":[]}]}