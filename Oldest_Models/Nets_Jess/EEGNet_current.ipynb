{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEGNet_current.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D415xY3P1PCN",
        "colab_type": "text"
      },
      "source": [
        "# Loose EEGNet\n",
        "This notebook is a neural network that is based as much off of the EEGNet paper as I could understand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sdi7BvnG2eiJ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VIVsTD-24Dj",
        "colab_type": "text"
      },
      "source": [
        "# Import/Install all necessary packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKZ_PXcuvZIx",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1d2c0e35-0108-4be7-e5ac-3fa449a856f0"
      },
      "source": [
        "!pip install mne"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.6/dist-packages (0.20.8)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anVJZVW0sUwY",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable, gradcheck\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot\n",
        "\n",
        "import mne\n",
        "from mne.io import concatenate_raws, read_raw_fif\n",
        "import mne.viz\n",
        "\n",
        "import math\n",
        "\n",
        "from os import walk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4ou4gyC4dQu",
        "colab_type": "text"
      },
      "source": [
        "# Check for GPU availability and set device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_rTCb13APF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6t-hO2E4mHe",
        "colab_type": "text"
      },
      "source": [
        "# Load and format the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PrZ39Hzvbcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "700405db-56fd-4f24-f213-f1cff65e3bc3"
      },
      "source": [
        "data_file = '/content/drive/My Drive/data/P_01.fif'\n",
        "\n",
        "epochs = mne.read_epochs(data_file, verbose='error')\n",
        "print(epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<EpochsFIF  |   484 events (all good), 0 - 1.49609 sec, baseline off, ~90.9 MB, data loaded,\n",
            " 'FN': 126\n",
            " 'FP': 133\n",
            " 'FU': 123\n",
            " 'NN': 37\n",
            " 'NP': 36\n",
            " 'NU': 29>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FDYPc5GvwTv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "f0a8df92-e363-4e97-e868-c7ba3dd1ec4f"
      },
      "source": [
        "epochs_UN = epochs['FU', 'FN'] # Unpleasant vs. Neutral\n",
        "epochs_UP = epochs['FU', 'FP'] # Unpleasant vs. Pleasant\n",
        "epochs_NP = epochs['FN', 'FP'] # Neutral vs. Pleasant\n",
        "\n",
        "# Dataset with unpleasant and neutral events\n",
        "print(epochs_UN)\n",
        "data_UN = epochs_UN.get_data() #we will classify between unpleasant and neutral\n",
        "labels_UN = epochs_UN.events[:,-1]\n",
        "print(len(labels_UN))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<EpochsFIF  |   249 events (all good), 0 - 1.49609 sec, baseline off, ~46.9 MB, data loaded,\n",
            " 'FN': 126\n",
            " 'FU': 123>\n",
            "249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PzcJwNMv4QU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(3)\n",
        "torch.cuda.manual_seed(3)\n",
        "train_data_UN, test_data_UN, labels_train_UN, labels_test_UN = train_test_split(data_UN, labels_UN, test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnIbNDuBv917",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e01d67fd-1d59-49eb-cae5-db430eac5953"
      },
      "source": [
        "print(labels_train_UN.shape, labels_test_UN.shape, train_data_UN.shape[-1])\n",
        "chunk_train = labels_train_UN.shape[0]\n",
        "chunk_test = labels_test_UN.shape[0]\n",
        "channels = train_data_UN.shape[1]\n",
        "timepoints = train_data_UN.shape[2]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(174,) (75,) 384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f6NOpVZwDwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d165aa73-3dd7-4ccf-8e1d-ab531597ea55"
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "BATCH_SIZE2 = chunk_test\n",
        "\n",
        "eeg_data_scaler = StandardScaler()\n",
        "\n",
        "X_train = eeg_data_scaler.fit_transform(train_data_UN.reshape(-1, train_data_UN.shape[-1])).reshape(train_data_UN.shape)\n",
        "X_test = eeg_data_scaler.fit_transform(test_data_UN.reshape(-1, test_data_UN.shape[-1])).reshape(test_data_UN.shape)\n",
        "\n",
        "labels_train_UN = np.array([1 if x > 0 else 0 for x in labels_train_UN])\n",
        "labels_test_UN = np.array([1 if x > 0 else 0 for x in labels_test_UN])\n",
        "\n",
        "labels_train_UN = labels_train_UN.reshape((chunk_train, 1))\n",
        "labels_train_UN = labels_train_UN.astype(np.float32)\n",
        "X_actual = torch.from_numpy(labels_train_UN)\n",
        "\n",
        "labels_test_UN = labels_test_UN.reshape((chunk_test, 1))\n",
        "labels_test_UN = labels_test_UN.astype(np.float32)\n",
        "X_test_actual = torch.from_numpy(labels_test_UN)\n",
        "\n",
        "X_train = torch.from_numpy(X_train)\n",
        "X_train = X_train.unsqueeze(1)\n",
        "X_test = torch.from_numpy(X_test)\n",
        "X_test = X_test.unsqueeze(1)\n",
        "\n",
        "train_batches = math.ceil(chunk_train / BATCH_SIZE)\n",
        "test_batches = math.ceil(chunk_test / BATCH_SIZE2)\n",
        "print(X_train.shape, X_actual.shape, X_test.shape, train_batches, test_batches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([174, 1, 64, 384]) torch.Size([174, 1]) torch.Size([75, 1, 64, 384]) 22 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz3MXsZebdIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = TensorDataset(X_train, X_actual)\n",
        "test_set = TensorDataset(X_test, X_test_actual)\n",
        "\n",
        "train_set_loader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle=False)\n",
        "test_set_loader = DataLoader(test_set, batch_size = BATCH_SIZE2, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCqJTTUu4xuf",
        "colab_type": "text"
      },
      "source": [
        "# Build the model and train\n",
        "A short breakdown of the paper:\n",
        "> EEGNet is a CNN for classification and interpretation of EEG-based BCI's\n",
        "\n",
        "> Benefits of EEGNet:\n",
        "> 1. Can be applied to different BCI paradagims (MI, ERP, SSVEP)\n",
        "> 2. Can be trained with very limited data\n",
        "> 3. Can produce neurophysiologically interpretable features\n",
        "\n",
        "> The model architecture:\n",
        "> 1. Fit *conv1_neurons* 2D convolutional filters of size (1, sampling rate//2)\n",
        "> 2. Use a depthwise convolution of size (# of channels, 1)\n",
        "> 3. Add a separable convolution of size (1, 16)\n",
        "> 4. Flatten the data and feed it through a classification layer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQpyCFRxx24X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hyperparameters\n",
        "freq, avg1stride, avg2stride = 256, (1, 4), (1, 8)\n",
        "convstride = 1 # stride for each conv2D\n",
        "conv1_neurons = 4\n",
        "conv2_neurons = 8\n",
        "conv3_neurons = 12\n",
        "flat1_out = 12\n",
        "kern1size = freq // 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpvKD47DQ8FS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv1outx, conv1outy = (channels, (timepoints - kern1size)/convstride + 1)\n",
        "\n",
        "conv2outx, conv2outy = ((conv1outx - channels)/convstride + 1, conv1outy)\n",
        "conv2outx, conv2outy = conv2outx // avg1stride[0], conv2outy // avg1stride[1]\n",
        "\n",
        "conv3outx, conv3outy = (conv2outx, (conv2outy - 16)/convstride + 1)\n",
        "conv3outx, conv3outy = (conv3outx // avg2stride[0], conv3outy // avg2stride[1])\n",
        "flat1_in = int(conv3outx * conv3outy * conv3_neurons)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCNgBinI_3Oq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "ecaece6f-cdd5-43f4-f770-c43a87a819da"
      },
      "source": [
        "CNNPoor = nn.Sequential(\n",
        "    nn.Conv2d(1, conv1_neurons, (1, kern1size), bias=False),\n",
        "    nn.ELU(),\n",
        "    nn.BatchNorm2d(conv1_neurons),\n",
        "    \n",
        "    nn.Conv2d(conv1_neurons, conv2_neurons, (channels, 1), bias=False),\n",
        "    nn.ELU(),\n",
        "    nn.BatchNorm2d(conv2_neurons),\n",
        "    nn.AvgPool2d(avg1stride),\n",
        "    nn.Dropout(),\n",
        "    \n",
        "    nn.Conv2d(conv2_neurons, conv3_neurons, (1, 16), bias=False),\n",
        "    nn.ELU(),\n",
        "    nn.BatchNorm2d(conv3_neurons),\n",
        "    nn.AvgPool2d(avg2stride),\n",
        "    nn.Dropout(),\n",
        "    \n",
        "    nn.Flatten(),\n",
        "\n",
        "    nn.Linear(flat1_in, 1),\n",
        "    nn.Sigmoid(),\n",
        ")\n",
        "\n",
        "CNNPoor.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(1, 4, kernel_size=(1, 128), stride=(1, 1), bias=False)\n",
              "  (1): ELU(alpha=1.0)\n",
              "  (2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (3): Conv2d(4, 8, kernel_size=(64, 1), stride=(1, 1), bias=False)\n",
              "  (4): ELU(alpha=1.0)\n",
              "  (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (6): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
              "  (7): Dropout(p=0.5, inplace=False)\n",
              "  (8): Conv2d(8, 12, kernel_size=(1, 16), stride=(1, 1), bias=False)\n",
              "  (9): ELU(alpha=1.0)\n",
              "  (10): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (11): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
              "  (12): Dropout(p=0.5, inplace=False)\n",
              "  (13): Flatten()\n",
              "  (14): Linear(in_features=72, out_features=1, bias=True)\n",
              "  (15): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRsayVFf_66T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.Adam(CNNPoor.parameters(), lr = 0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFBd1M29CFmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, device, test_loader):\n",
        "    \n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    tot_loss = 0\n",
        "    acc_score, prec_score, rec_score = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for (data, labels) in test_loader:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            \n",
        "            classification = model(data.float())\n",
        "            loss = loss_function(classification, labels)\n",
        "\n",
        "            pred = torch.round(classification)\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "            tot_loss += loss.item()\n",
        "\n",
        "            acc_score += accuracy_score(labels, pred)\n",
        "            prec_score += precision_score(labels, pred)\n",
        "            rec_score += recall_score(labels, pred)\n",
        "\n",
        "        print(\"\\nTest set: Average loss: {:.6f}, Accuracy: {:.6f}\".format(tot_loss / test_batches, \n",
        "                                                                          correct / len(test_loader.dataset)))\n",
        "        print(\"sklearn accuracy: {:.6f} precision: {:.6f} recall: {:.6f}\\n\".format(acc_score / test_batches,\n",
        "                                                                                   prec_score / test_batches,\n",
        "                                                                                   rec_score / test_batches))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fm36EBCCJ1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    batch = 0\n",
        "    tot_loss = 0\n",
        "    for (data, labels) in train_loader:\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        classification = model(data.float())\n",
        "        loss = loss_function(classification, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = torch.round(classification)\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        tot_loss += loss.item()\n",
        "\n",
        "        batch += 1\n",
        "\n",
        "        if batch == train_batches:\n",
        "            print(\"Epoch: {}\".format(epoch))\n",
        "            print(\"\\tAverage loss: {:.6f}\".format(tot_loss / batch))\n",
        "            print(\"\\tAccuracy: {:.6f}\".format(correct / len(train_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxLzxLHdCYKM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30e19587-179d-4083-bd3e-7ee272cabb9b"
      },
      "source": [
        "for epoch in range(13):\n",
        "    train(CNNPoor, device, train_set_loader, optimizer, epoch)\n",
        "    test(CNNPoor, device, test_set_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "\tAverage loss: 0.719555\n",
            "\tAccuracy: 0.494253\n",
            "\n",
            "Test set: Average loss: 0.686913, Accuracy: 0.506667\n",
            "sklearn accuracy: 0.506667 precision: 0.529412 recall: 0.461538\n",
            "\n",
            "Epoch: 1\n",
            "\tAverage loss: 0.653402\n",
            "\tAccuracy: 0.643678\n",
            "\n",
            "Test set: Average loss: 0.647121, Accuracy: 0.626667\n",
            "sklearn accuracy: 0.626667 precision: 0.627907 recall: 0.692308\n",
            "\n",
            "Epoch: 2\n",
            "\tAverage loss: 0.646683\n",
            "\tAccuracy: 0.597701\n",
            "\n",
            "Test set: Average loss: 0.630558, Accuracy: 0.666667\n",
            "sklearn accuracy: 0.666667 precision: 0.645833 recall: 0.794872\n",
            "\n",
            "Epoch: 3\n",
            "\tAverage loss: 0.573064\n",
            "\tAccuracy: 0.695402\n",
            "\n",
            "Test set: Average loss: 0.607657, Accuracy: 0.613333\n",
            "sklearn accuracy: 0.613333 precision: 0.631579 recall: 0.615385\n",
            "\n",
            "Epoch: 4\n",
            "\tAverage loss: 0.489218\n",
            "\tAccuracy: 0.787356\n",
            "\n",
            "Test set: Average loss: 0.573788, Accuracy: 0.680000\n",
            "sklearn accuracy: 0.680000 precision: 0.666667 recall: 0.769231\n",
            "\n",
            "Epoch: 5\n",
            "\tAverage loss: 0.448292\n",
            "\tAccuracy: 0.804598\n",
            "\n",
            "Test set: Average loss: 0.556812, Accuracy: 0.706667\n",
            "sklearn accuracy: 0.706667 precision: 0.688889 recall: 0.794872\n",
            "\n",
            "Epoch: 6\n",
            "\tAverage loss: 0.397607\n",
            "\tAccuracy: 0.821839\n",
            "\n",
            "Test set: Average loss: 0.556903, Accuracy: 0.733333\n",
            "sklearn accuracy: 0.733333 precision: 0.711111 recall: 0.820513\n",
            "\n",
            "Epoch: 7\n",
            "\tAverage loss: 0.351431\n",
            "\tAccuracy: 0.867816\n",
            "\n",
            "Test set: Average loss: 0.575730, Accuracy: 0.720000\n",
            "sklearn accuracy: 0.720000 precision: 0.695652 recall: 0.820513\n",
            "\n",
            "Epoch: 8\n",
            "\tAverage loss: 0.360226\n",
            "\tAccuracy: 0.867816\n",
            "\n",
            "Test set: Average loss: 0.566187, Accuracy: 0.773333\n",
            "sklearn accuracy: 0.773333 precision: 0.761905 recall: 0.820513\n",
            "\n",
            "Epoch: 9\n",
            "\tAverage loss: 0.309626\n",
            "\tAccuracy: 0.873563\n",
            "\n",
            "Test set: Average loss: 0.551925, Accuracy: 0.746667\n",
            "sklearn accuracy: 0.746667 precision: 0.727273 recall: 0.820513\n",
            "\n",
            "Epoch: 10\n",
            "\tAverage loss: 0.252829\n",
            "\tAccuracy: 0.896552\n",
            "\n",
            "Test set: Average loss: 0.644129, Accuracy: 0.746667\n",
            "sklearn accuracy: 0.746667 precision: 0.738095 recall: 0.794872\n",
            "\n",
            "Epoch: 11\n",
            "\tAverage loss: 0.249431\n",
            "\tAccuracy: 0.913793\n",
            "\n",
            "Test set: Average loss: 0.669507, Accuracy: 0.706667\n",
            "sklearn accuracy: 0.706667 precision: 0.697674 recall: 0.769231\n",
            "\n",
            "Epoch: 12\n",
            "\tAverage loss: 0.203076\n",
            "\tAccuracy: 0.931034\n",
            "\n",
            "Test set: Average loss: 0.579129, Accuracy: 0.760000\n",
            "sklearn accuracy: 0.760000 precision: 0.744186 recall: 0.820513\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZSSbDW4hQwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}