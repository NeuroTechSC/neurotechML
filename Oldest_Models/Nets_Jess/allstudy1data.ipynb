{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable, gradcheck\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import mne\n",
    "from mne.io import concatenate_raws, read_raw_fif\n",
    "import mne.viz\n",
    "\n",
    "import math\n",
    "\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-0.698</th>\n",
       "      <th>-0.762</th>\n",
       "      <th>-0.944</th>\n",
       "      <th>-1.122</th>\n",
       "      <th>-1.108</th>\n",
       "      <th>-0.723</th>\n",
       "      <th>0.07</th>\n",
       "      <th>1.125</th>\n",
       "      <th>2.155</th>\n",
       "      <th>2.898</th>\n",
       "      <th>...</th>\n",
       "      <th>20.833</th>\n",
       "      <th>20.093</th>\n",
       "      <th>19.654</th>\n",
       "      <th>19.536</th>\n",
       "      <th>19.697</th>\n",
       "      <th>20.011</th>\n",
       "      <th>20.335</th>\n",
       "      <th>20.588</th>\n",
       "      <th>20.827</th>\n",
       "      <th>21.199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-3.356</td>\n",
       "      <td>-3.230</td>\n",
       "      <td>-2.968</td>\n",
       "      <td>-2.780</td>\n",
       "      <td>-2.813</td>\n",
       "      <td>-3.067</td>\n",
       "      <td>-3.422</td>\n",
       "      <td>-3.729</td>\n",
       "      <td>-3.881</td>\n",
       "      <td>-3.842</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.171</td>\n",
       "      <td>-5.669</td>\n",
       "      <td>-6.558</td>\n",
       "      <td>-7.532</td>\n",
       "      <td>-8.214</td>\n",
       "      <td>-8.319</td>\n",
       "      <td>-7.755</td>\n",
       "      <td>-6.610</td>\n",
       "      <td>-5.066</td>\n",
       "      <td>-3.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-0.936</td>\n",
       "      <td>-1.833</td>\n",
       "      <td>-2.833</td>\n",
       "      <td>-3.619</td>\n",
       "      <td>-3.919</td>\n",
       "      <td>-3.637</td>\n",
       "      <td>-2.916</td>\n",
       "      <td>-2.085</td>\n",
       "      <td>-1.501</td>\n",
       "      <td>-1.373</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.416</td>\n",
       "      <td>-2.966</td>\n",
       "      <td>-2.921</td>\n",
       "      <td>-3.143</td>\n",
       "      <td>-3.330</td>\n",
       "      <td>-3.237</td>\n",
       "      <td>-2.777</td>\n",
       "      <td>-1.950</td>\n",
       "      <td>-0.725</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.232</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.805</td>\n",
       "      <td>-1.356</td>\n",
       "      <td>-1.463</td>\n",
       "      <td>-1.185</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.963</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.272</td>\n",
       "      <td>-2.243</td>\n",
       "      <td>-3.477</td>\n",
       "      <td>-4.764</td>\n",
       "      <td>-5.790</td>\n",
       "      <td>-6.248</td>\n",
       "      <td>-5.933</td>\n",
       "      <td>-4.799</td>\n",
       "      <td>-2.954</td>\n",
       "      <td>-0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.278</td>\n",
       "      <td>-0.293</td>\n",
       "      <td>-0.810</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.846</td>\n",
       "      <td>-7.245</td>\n",
       "      <td>-6.739</td>\n",
       "      <td>-6.557</td>\n",
       "      <td>-6.794</td>\n",
       "      <td>-7.355</td>\n",
       "      <td>-8.004</td>\n",
       "      <td>-8.513</td>\n",
       "      <td>-8.786</td>\n",
       "      <td>-8.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4.899</td>\n",
       "      <td>5.001</td>\n",
       "      <td>4.836</td>\n",
       "      <td>4.464</td>\n",
       "      <td>3.933</td>\n",
       "      <td>3.295</td>\n",
       "      <td>2.640</td>\n",
       "      <td>2.102</td>\n",
       "      <td>1.814</td>\n",
       "      <td>1.850</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.848</td>\n",
       "      <td>-2.510</td>\n",
       "      <td>-2.391</td>\n",
       "      <td>-2.514</td>\n",
       "      <td>-2.775</td>\n",
       "      <td>-2.982</td>\n",
       "      <td>-2.920</td>\n",
       "      <td>-2.431</td>\n",
       "      <td>-1.453</td>\n",
       "      <td>-0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    -0.698  -0.762  -0.944  -1.122  -1.108  -0.723   0.07  1.125  2.155  \\\n",
       "58  -3.356  -3.230  -2.968  -2.780  -2.813  -3.067 -3.422 -3.729 -3.881   \n",
       "59  -0.936  -1.833  -2.833  -3.619  -3.919  -3.637 -2.916 -2.085 -1.501   \n",
       "60   1.232   0.121  -0.805  -1.356  -1.463  -1.185 -0.671 -0.093  0.447   \n",
       "61   0.585   0.034  -0.144   0.065   0.452   0.721  0.667  0.278 -0.293   \n",
       "62   4.899   5.001   4.836   4.464   3.933   3.295  2.640  2.102  1.814   \n",
       "\n",
       "    2.898  ...  20.833  20.093  19.654  19.536  19.697  20.011  20.335  \\\n",
       "58 -3.842  ...  -5.171  -5.669  -6.558  -7.532  -8.214  -8.319  -7.755   \n",
       "59 -1.373  ...  -3.416  -2.966  -2.921  -3.143  -3.330  -3.237  -2.777   \n",
       "60  0.963  ...  -1.272  -2.243  -3.477  -4.764  -5.790  -6.248  -5.933   \n",
       "61 -0.810  ...  -7.846  -7.245  -6.739  -6.557  -6.794  -7.355  -8.004   \n",
       "62  1.850  ...  -2.848  -2.510  -2.391  -2.514  -2.775  -2.982  -2.920   \n",
       "\n",
       "    20.588  20.827  21.199  \n",
       "58  -6.610  -5.066  -3.331  \n",
       "59  -1.950  -0.725   0.973  \n",
       "60  -4.799  -2.954  -0.630  \n",
       "61  -8.513  -8.786  -8.876  \n",
       "62  -2.431  -1.453  -0.030  \n",
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at some of the data\n",
    "data_file = 'study1_eeg/study1_EEG_P-01_FN_Trial-001.csv'\n",
    "\n",
    "data_P_09 = pd.read_csv(data_file)\n",
    "data_P_09.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<EpochsFIF  |   16666 events (all good), 0 - 1.49609 sec, baseline off, ~3.05 GB, data loaded,\n",
      " 'FN': 4336\n",
      " 'FP': 4371\n",
      " 'FU': 4239\n",
      " 'NN': 1238\n",
      " 'NP': 1264\n",
      " 'NU': 1218>\n"
     ]
    }
   ],
   "source": [
    "# take some data that was already formatted, from this link: https://neuro.inf.unibe.ch/AlgorithmsNeuroscience/Tutorial_files/DatasetConstruction.html\n",
    "data_file = 'study1_eeg/epochdata/master'\n",
    "\n",
    "# Read the EEG epochs:\n",
    "epochs = mne.read_epochs(data_file + '.fif', verbose='error')\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<EpochsFIF  |   8575 events (all good), 0 - 1.49609 sec, baseline off, ~1.57 GB, data loaded,\n",
      " 'FN': 4336\n",
      " 'FU': 4239>\n",
      "8575\n"
     ]
    }
   ],
   "source": [
    "epochs_UN = epochs['FU', 'FN'] # Unpleasant vs. Neutral\n",
    "epochs_UP = epochs['FU', 'FP'] # Unpleasant vs. Pleasant\n",
    "epochs_NP = epochs['FN', 'FP'] # Neutral vs. Pleasant\n",
    "\n",
    "# Dataset with unpleasant and neutral events\n",
    "print(epochs_UN)\n",
    "data_UN = epochs_UN.get_data() #we will classify between unpleasant and neutral\n",
    "labels_UN = epochs_UN.events[:,-1]\n",
    "print(len(labels_UN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3)\n",
    "torch.cuda.manual_seed(3)\n",
    "train_data_UN, test_data_UN, labels_train_UN, labels_test_UN = train_test_split(data_UN, labels_UN, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6002,) (2573,)\n",
      "(6002,) (2573,) 384\n"
     ]
    }
   ],
   "source": [
    "print(labels_train_UN.shape, labels_test_UN.shape)\n",
    "print(labels_train_UN.shape, labels_test_UN.shape, train_data_UN.shape[-1])\n",
    "chunk_train = labels_train_UN.shape[0]\n",
    "chunk_test = labels_test_UN.shape[0]\n",
    "channels = train_data_UN.shape[1]\n",
    "timepoints = train_data_UN.shape[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6002, 1, 64, 384]) torch.Size([6002, 1]) torch.Size([2573, 1, 64, 384]) 12 6\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 512\n",
    "BATCH_SIZE2 = 512\n",
    "\n",
    "eeg_data_scaler = StandardScaler()\n",
    "\n",
    "X_train = eeg_data_scaler.fit_transform(train_data_UN.reshape(-1, train_data_UN.shape[-1])).reshape(train_data_UN.shape)\n",
    "X_test = eeg_data_scaler.fit_transform(test_data_UN.reshape(-1, test_data_UN.shape[-1])).reshape(test_data_UN.shape)\n",
    "\n",
    "labels_train_UN = np.array([1 if x > 0 else 0 for x in labels_train_UN])\n",
    "labels_test_UN = np.array([1 if x > 0 else 0 for x in labels_test_UN])\n",
    "\n",
    "labels_train_UN = labels_train_UN.reshape((chunk_train, 1))\n",
    "labels_train_UN = labels_train_UN.astype(np.float32)\n",
    "X_actual = torch.from_numpy(labels_train_UN)\n",
    "\n",
    "labels_test_UN = labels_test_UN.reshape((chunk_test, 1))\n",
    "labels_test_UN = labels_test_UN.astype(np.float32)\n",
    "X_test_actual = torch.from_numpy(labels_test_UN)\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_train = X_train.unsqueeze(1)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "X_test = X_test.unsqueeze(1)\n",
    "\n",
    "train_batches = math.ceil(chunk_train / BATCH_SIZE)\n",
    "test_batches = math.ceil(chunk_test / BATCH_SIZE2)\n",
    "print(X_train.shape, X_actual.shape, X_test.shape, train_batches, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(X_train, X_actual)\n",
    "test_set = TensorDataset(X_test, X_test_actual)\n",
    "\n",
    "train_set_loader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle=False)\n",
    "test_set_loader = DataLoader(test_set, batch_size = BATCH_SIZE2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "freq, avg1stride, avg2stride = 256, (1, 4), (1, 8)\n",
    "convstride = 1 # stride for each conv2D\n",
    "conv1_neurons = 8\n",
    "conv2_neurons = 16\n",
    "conv3_neurons = 32\n",
    "conv4_neurons = 16\n",
    "flat1_out = 12\n",
    "kern1size = freq // 2\n",
    "kern3size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_needed = (kern1size - 1) / 2\n",
    "conv1outx, conv1outy = (channels, (timepoints + (2 * padding_needed) - kern1size)/convstride + 1)\n",
    "\n",
    "conv2outx, conv2outy = ((conv1outx - channels)/convstride + 1, conv1outy)\n",
    "conv2outx, conv2outy = conv2outx // avg1stride[0], conv2outy // avg1stride[1]\n",
    "\n",
    "conv3outx, conv3outy = (conv2outx, (conv2outy - kern3size)/convstride + 1)\n",
    "\n",
    "conv4outx, conv4outy = (conv3outx, conv3outy)\n",
    "conv4outx, conv4outy = (conv4outx // avg2stride[0], conv4outy // avg2stride[1])\n",
    "flat1_in = int(conv4outx * conv4outy * conv4_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ZeroPad2d(padding=(63, 64, 0, 0), value=0.0)\n",
       "  (1): Conv2d(1, 8, kernel_size=(1, 128), stride=(1, 1), bias=False)\n",
       "  (2): ELU(alpha=1.0)\n",
       "  (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Conv2d(8, 16, kernel_size=(64, 1), stride=(1, 1), groups=8, bias=False)\n",
       "  (5): ELU(alpha=1.0)\n",
       "  (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
       "  (8): Dropout(p=0.25, inplace=False)\n",
       "  (9): Conv2d(16, 32, kernel_size=(1, 32), stride=(1, 1), groups=16, bias=False)\n",
       "  (10): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (11): ELU(alpha=1.0)\n",
       "  (12): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
       "  (14): Dropout(p=0.25, inplace=False)\n",
       "  (15): Flatten()\n",
       "  (16): Linear(in_features=128, out_features=12, bias=True)\n",
       "  (17): Linear(in_features=12, out_features=1, bias=True)\n",
       "  (18): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNNPoor = nn.Sequential(\n",
    "    nn.ZeroPad2d((math.floor(padding_needed), math.ceil(padding_needed), 0, 0)),\n",
    "    nn.Conv2d(1, conv1_neurons, (1, kern1size), bias=False),\n",
    "    nn.ELU(),\n",
    "    nn.BatchNorm2d(conv1_neurons),\n",
    "    \n",
    "    nn.Conv2d(conv1_neurons, conv2_neurons, (channels, 1), bias=False, groups = conv1_neurons),\n",
    "    nn.ELU(),\n",
    "    nn.BatchNorm2d(conv2_neurons),\n",
    "    nn.AvgPool2d(avg1stride),\n",
    "    nn.Dropout(p = 0.25),\n",
    "    \n",
    "    nn.Conv2d(conv2_neurons, conv3_neurons, (1, kern3size), bias=False, groups = conv2_neurons),\n",
    "    nn.Conv2d(conv3_neurons, conv4_neurons, kernel_size=1, bias=False),\n",
    "    nn.ELU(),\n",
    "    nn.BatchNorm2d(conv4_neurons),\n",
    "    nn.AvgPool2d(avg2stride),\n",
    "    nn.Dropout(p = 0.25),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "\n",
    "    nn.Linear(flat1_in, flat1_out),\n",
    "    nn.Linear(flat1_out, 1),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "\n",
    "CNNPoor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adam(CNNPoor.parameters(), lr = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    tot_loss = 0\n",
    "    acc_score, prec_score, rec_score = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for (data, labels) in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            \n",
    "            classification = model(data.float())\n",
    "            loss = loss_function(classification, labels)\n",
    "\n",
    "            pred = torch.round(classification)\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "            tot_loss += loss.item()\n",
    "\n",
    "            acc_score += accuracy_score(labels.cpu(), pred.cpu())\n",
    "            prec_score += precision_score(labels.cpu(), pred.cpu())\n",
    "            rec_score += recall_score(labels.cpu(), pred.cpu())\n",
    "\n",
    "        print(\"\\nTest set: Average loss: {:.6f}, Accuracy: {:.6f}\".format(tot_loss / test_batches, \n",
    "                                                                          correct / len(test_loader.dataset)))\n",
    "        print(\"sklearn accuracy: {:.6f} precision: {:.6f} recall: {:.6f}\\n\".format(acc_score / test_batches,\n",
    "                                                                                   prec_score / test_batches,\n",
    "                                                                                   rec_score / test_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    batch = 0\n",
    "    tot_loss = 0\n",
    "    for (data, labels) in train_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        classification = model(data.float())\n",
    "        loss = loss_function(classification, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = torch.round(classification)\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        tot_loss += loss.item()\n",
    "\n",
    "        batch += 1\n",
    "\n",
    "        if batch == train_batches:\n",
    "            print(\"Epoch: {}\".format(epoch))\n",
    "            print(\"\\tAverage loss: {:.6f}\".format(tot_loss / batch))\n",
    "            print(\"\\tAccuracy: {:.6f}\".format(correct / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\tAverage loss: 0.701715\n",
      "\tAccuracy: 0.512829\n",
      "\n",
      "Test set: Average loss: 0.693126, Accuracy: 0.524291\n",
      "sklearn accuracy: 0.514098 precision: 0.503505 recall: 0.498959\n",
      "\n",
      "Epoch: 1\n",
      "\tAverage loss: 0.695039\n",
      "\tAccuracy: 0.529324\n",
      "\n",
      "Test set: Average loss: 0.699401, Accuracy: 0.530509\n",
      "sklearn accuracy: 0.519306 precision: 0.508677 recall: 0.503194\n",
      "\n",
      "Epoch: 2\n",
      "\tAverage loss: 0.685619\n",
      "\tAccuracy: 0.553149\n",
      "\n",
      "Test set: Average loss: 0.684726, Accuracy: 0.551108\n",
      "sklearn accuracy: 0.574043 precision: 0.577953 recall: 0.500385\n",
      "\n",
      "Epoch: 3\n",
      "\tAverage loss: 0.674006\n",
      "\tAccuracy: 0.579807\n",
      "\n",
      "Test set: Average loss: 0.683235, Accuracy: 0.556937\n",
      "sklearn accuracy: 0.566431 precision: 0.558929 recall: 0.571830\n",
      "\n",
      "Epoch: 4\n",
      "\tAverage loss: 0.665798\n",
      "\tAccuracy: 0.593469\n",
      "\n",
      "Test set: Average loss: 0.678056, Accuracy: 0.561601\n",
      "sklearn accuracy: 0.595328 precision: 0.606513 recall: 0.526064\n",
      "\n",
      "Epoch: 5\n",
      "\tAverage loss: 0.660601\n",
      "\tAccuracy: 0.606131\n",
      "\n",
      "Test set: Average loss: 0.674534, Accuracy: 0.565099\n",
      "sklearn accuracy: 0.610752 precision: 0.643531 recall: 0.527893\n",
      "\n",
      "Epoch: 6\n",
      "\tAverage loss: 0.656010\n",
      "\tAccuracy: 0.606131\n",
      "\n",
      "Test set: Average loss: 0.669835, Accuracy: 0.564710\n",
      "sklearn accuracy: 0.610427 precision: 0.639692 recall: 0.550670\n",
      "\n",
      "Epoch: 7\n",
      "\tAverage loss: 0.649127\n",
      "\tAccuracy: 0.615128\n",
      "\n",
      "Test set: Average loss: 0.673921, Accuracy: 0.566654\n",
      "sklearn accuracy: 0.612054 precision: 0.649375 recall: 0.506518\n",
      "\n",
      "Epoch: 8\n",
      "\tAverage loss: 0.635491\n",
      "\tAccuracy: 0.629623\n",
      "\n",
      "Test set: Average loss: 0.679305, Accuracy: 0.561213\n",
      "sklearn accuracy: 0.595002 precision: 0.641284 recall: 0.493194\n",
      "\n",
      "Epoch: 9\n",
      "\tAverage loss: 0.630605\n",
      "\tAccuracy: 0.644452\n",
      "\n",
      "Test set: Average loss: 0.675014, Accuracy: 0.565488\n",
      "sklearn accuracy: 0.598583 precision: 0.637430 recall: 0.548362\n",
      "\n",
      "Epoch: 10\n",
      "\tAverage loss: 0.621966\n",
      "\tAccuracy: 0.656948\n",
      "\n",
      "Test set: Average loss: 0.682968, Accuracy: 0.569763\n",
      "sklearn accuracy: 0.602163 precision: 0.637674 recall: 0.577147\n",
      "\n",
      "Epoch: 11\n",
      "\tAverage loss: 0.618238\n",
      "\tAccuracy: 0.660447\n",
      "\n",
      "Test set: Average loss: 0.680674, Accuracy: 0.573261\n",
      "sklearn accuracy: 0.605093 precision: 0.645105 recall: 0.546159\n",
      "\n",
      "Epoch: 12\n",
      "\tAverage loss: 0.610690\n",
      "\tAccuracy: 0.667278\n",
      "\n",
      "Test set: Average loss: 0.681452, Accuracy: 0.575593\n",
      "sklearn accuracy: 0.594551 precision: 0.650786 recall: 0.499986\n",
      "\n",
      "Epoch: 13\n",
      "\tAverage loss: 0.602616\n",
      "\tAccuracy: 0.672609\n",
      "\n",
      "Test set: Average loss: 0.687883, Accuracy: 0.572483\n",
      "sklearn accuracy: 0.604442 precision: 0.650397 recall: 0.511270\n",
      "\n",
      "Epoch: 14\n",
      "\tAverage loss: 0.598402\n",
      "\tAccuracy: 0.675108\n",
      "\n",
      "Test set: Average loss: 0.683872, Accuracy: 0.576759\n",
      "sklearn accuracy: 0.595528 precision: 0.650724 recall: 0.508869\n",
      "\n",
      "Epoch: 15\n",
      "\tAverage loss: 0.593527\n",
      "\tAccuracy: 0.683106\n",
      "\n",
      "Test set: Average loss: 0.687150, Accuracy: 0.574038\n",
      "sklearn accuracy: 0.593249 precision: 0.654292 recall: 0.470809\n",
      "\n",
      "Epoch: 16\n",
      "\tAverage loss: 0.584162\n",
      "\tAccuracy: 0.687937\n",
      "\n",
      "Test set: Average loss: 0.678308, Accuracy: 0.582977\n",
      "sklearn accuracy: 0.638221 precision: 0.660226 recall: 0.568420\n",
      "\n",
      "Epoch: 17\n",
      "\tAverage loss: 0.578989\n",
      "\tAccuracy: 0.694935\n",
      "\n",
      "Test set: Average loss: 0.687238, Accuracy: 0.584532\n",
      "sklearn accuracy: 0.614533 precision: 0.662598 recall: 0.513506\n",
      "\n",
      "Epoch: 18\n",
      "\tAverage loss: 0.578385\n",
      "\tAccuracy: 0.689770\n",
      "\n",
      "Test set: Average loss: 0.684145, Accuracy: 0.584143\n",
      "sklearn accuracy: 0.639198 precision: 0.662475 recall: 0.565254\n",
      "\n",
      "Epoch: 19\n",
      "\tAverage loss: 0.576291\n",
      "\tAccuracy: 0.696934\n",
      "\n",
      "Test set: Average loss: 0.686607, Accuracy: 0.582200\n",
      "sklearn accuracy: 0.625075 precision: 0.663290 recall: 0.525868\n",
      "\n",
      "Epoch: 20\n",
      "\tAverage loss: 0.570329\n",
      "\tAccuracy: 0.698267\n",
      "\n",
      "Test set: Average loss: 0.687279, Accuracy: 0.579091\n",
      "sklearn accuracy: 0.622471 precision: 0.655993 recall: 0.543946\n",
      "\n",
      "Epoch: 21\n",
      "\tAverage loss: 0.561263\n",
      "\tAccuracy: 0.706431\n",
      "\n",
      "Test set: Average loss: 0.705339, Accuracy: 0.574427\n",
      "sklearn accuracy: 0.606070 precision: 0.599820 recall: 0.594195\n",
      "\n",
      "Epoch: 22\n",
      "\tAverage loss: 0.562328\n",
      "\tAccuracy: 0.702932\n",
      "\n",
      "Test set: Average loss: 0.699028, Accuracy: 0.562767\n",
      "sklearn accuracy: 0.621294 precision: 0.636058 recall: 0.590933\n",
      "\n",
      "Epoch: 23\n",
      "\tAverage loss: 0.559285\n",
      "\tAccuracy: 0.706598\n",
      "\n",
      "Test set: Average loss: 0.692436, Accuracy: 0.579091\n",
      "sklearn accuracy: 0.634966 precision: 0.654271 recall: 0.584617\n",
      "\n",
      "Epoch: 24\n",
      "\tAverage loss: 0.556731\n",
      "\tAccuracy: 0.711263\n",
      "\n",
      "Test set: Average loss: 0.701702, Accuracy: 0.576759\n",
      "sklearn accuracy: 0.633013 precision: 0.658787 recall: 0.545237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(25):\n",
    "    train(CNNPoor, device, train_set_loader, optimizer, epoch)\n",
    "    test(CNNPoor, device, test_set_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
